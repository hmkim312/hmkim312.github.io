<!DOCTYPE html><html lang="ko" mode="light" > <!-- The Head v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Mnist Fashion으로 알아보는 Deep Learning | Data Include Me</title><meta name="generator" content="Jekyll v3.9.3" /><meta property="og:title" content="Mnist Fashion으로 알아보는 Deep Learning" /><meta name="author" content="HyunMin Kim" /><meta property="og:locale" content="ko" /><meta name="description" content="Mnist Fashion으로 알아보는 Deep Learning" /><meta property="og:description" content="Mnist Fashion으로 알아보는 Deep Learning" /><link rel="canonical" href="https://datainclude.me/posts/Mnist_Fashion%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_Deep_Learning/" /><meta property="og:url" content="https://datainclude.me/posts/Mnist_Fashion%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_Deep_Learning/" /><meta property="og:site_name" content="Data Include Me" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-05-10T00:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Mnist Fashion으로 알아보는 Deep Learning" /><meta name="twitter:site" content="@" /><meta name="twitter:creator" content="@HyunMin Kim" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"HyunMin Kim"},"dateModified":"2021-05-10T00:00:00+09:00","datePublished":"2021-05-10T00:00:00+09:00","description":"Mnist Fashion으로 알아보는 Deep Learning","headline":"Mnist Fashion으로 알아보는 Deep Learning","mainEntityOfPage":{"@type":"WebPage","@id":"https://datainclude.me/posts/Mnist_Fashion%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_Deep_Learning/"},"url":"https://datainclude.me/posts/Mnist_Fashion%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_Deep_Learning/"}</script><meta property="og:image" content="https://datainclude.me/assets/img/sample/avatar.jpg" /> <!-- The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps Generated by: https://www.favicon-generator.org/ v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT license --><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="36x36" href="/assets/img/favicons/android-icon-36x36.png"><link rel="icon" type="image/png" sizes="48x48" href="/assets/img/favicons/android-icon-48x48.png"><link rel="icon" type="image/png" sizes="72x72" href="/assets/img/favicons/android-icon-72x72.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/android-icon-96x96.png"><link rel="icon" type="image/png" sizes="144x144" href="/assets/img/favicons/android-icon-144x144.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="70x70" href="/assets/img/favicons/ms-icon-70x70.png"><link rel="icon" type="image/png" sizes="144x144" href="/assets/img/favicons/ms-icon-144x144.png"><link rel="icon" type="image/png" sizes="150x150" href="/assets/img/favicons/ms-icon-150x150.png"><link rel="icon" type="image/png" sizes="310x310" href="/assets/img/favicons/ms-icon-310x310.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preload" href="https://www.googletagmanager.com/gtm.js?id=GTM-MW9VRMW9" as="script"> <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src= 'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f); })(window,document,'script','dataLayer','GTM-MW9VRMW9');</script><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="preload" as="style" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous" media="print" onload="this.media='all'"> <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"> </noscript> <!-- CSS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --><link rel="preload" as="style" href="/assets/css/post.css"><link rel="stylesheet" href="/assets/css/post.css"><link rel="preload" as="style" href="/assets/css/lib/bootstrap-toc.min.css"><link rel="stylesheet" href="/assets/css/lib/bootstrap-toc.min.css" /><link rel="preload" as="script" href="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" async></script> <!-- JS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --> <script src="/assets/js/post.min.js" async></script> <script src="/app.js" defer></script><body data-spy="scroll" data-target="#toc"> <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MW9VRMW9" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="sidebar" class="d-flex flex-column"> <!-- The Side Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="nav-wrapper"><div id="profile-wrapper" class="d-flex flex-column"><div id="avatar" class="d-flex justify-content-center"> <a href="/" alt="avatar"> <img src="/assets/img/sample/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="profile-text mt-3"><div class="site-title"> <a href="/">Data Include Me</a></div><div class="site-subtitle font-italic">Data Science Blog</div></div></div><ul class="nav flex-column"><li class="nav-item d-flex justify-content-center "> <a href="/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/categories/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/tags/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/archives/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/about/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></li></ul></div><div class="sidebar-bottom d-flex flex-wrap justify-content-around mt-4"> <a href="https://github.com/hmkim312" target="_blank"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/" target="_blank"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:window.open('mailto:' + ['sanarial312','gmail.com'].join('@'))" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" > <i class="fas fa-rss"></i> </a></div></div><!-- The Top Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Mnist Fashion으로 알아보는 Deep Learning</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"> <!-- Refactor the HTML structure. --> <!-- Suroundding the markdown table with '<div class="table-wrapper">. and '</div>' --> <!-- Fixed kramdown code highlight rendering: https://github.com/penibelst/jekyll-compress-html/issues/101 https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901 --><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"> <script type="text/javascript"> var lazyloadads = false; function loadAds() { if (!lazyloadads) { var script = document.createElement("script"); script.type = "text/javascript"; script.async = true; script.src = "https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7594406644928408"; document.body.appendChild(script); lazyloadads = true; } } window.addEventListener("mousemove", loadAds, { once: true }); window.addEventListener('touchstart', loadAds, { once: true }); </script><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Mnist Fashion으로 알아보는 Deep Learning</h1><div class="post-meta text-muted d-flex flex-column"><div> Posted <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Mon, May 10, 2021, 12:00 AM +0900" > May 10, 2021 <i class="unloaded">2021-05-10T00:00:00+09:00</i> </span> by <span class="author"> HyunMin Kim </span></div><a href="https://hits.seeyoufarm.com"> <img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https://datainclude.me/posts/Mnist_Fashion%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_Deep_Learning/%2F&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=views&edge_flat=false" alt="페이지 조회수 뱃지", width: 100%;, height: 100%;/> </a></div><div class="post-content"><h1 id="mnist-fashion으로-알아보는-deep-learning">Mnist Fashion으로 알아보는 Deep Learning</h1><hr /><h2 id="목차">목차</h2><ol><li>개요</li><li>패키지 목록</li><li>데이터 로드</li><li>데이터 라벨링</li><li>데이터 시각화</li><li>머신러닝, 딥러닝을 위한 데이터 처리</li><li>Machine Learning</li><li>Deep Learning</li><li>결과 및 회고</li></ol><hr /><h3 id="0-개요---mnist-fashoin-image">0. 개요 - Mnist Fashoin Image</h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/117663987-35e42e00-b1dc-11eb-88c7-64db3b4fbff0.png" /></p><ul><li>Mnist Fashion Image는 운동화, 셔츠, 샌들과 같은 의류 이미지들의 모음입니다.</li><li>총 10 가지의 Class로 이루어져 있으며, 이미지는 28×28 픽셀이며 총 70,000 장으로로 이루어져 있습니다.</li><li>그 중 60,000장의 데이터는 Train 데이터이고, 10,000장은 Test 데이터입니다.</li></ul><hr /><h3 id="0-개요---계획">0. 개요 - 계획</h3><ul><li>실제 이미지 데이터를 불러오고, 시각화하고 머신러닝과 딥러닝의 알고리즘으로 예측 모델을 생성합니다.</li><li>머신러닝은 Decision Tree와 RandomForest를 사용합니다.</li><li>딥러닝의 Multi Layer Perceptron와 Convolution Neural Network를 사용합니다.</li><li>마지막으로 가장 성능이 좋은 모델로 Test 데이터를 예측하여 결과를 CSV파일로 저장합니다.</li></ul><hr /><h3 id="1-패키지-목록">1. 패키지 목록</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.callbacks</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="n">EarlyStopping</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">StratifiedKFold</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.image</span> <span class="k">as</span> <span class="n">mpimg</span>

<span class="n">np</span><span class="p">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></table></code></div></div><h2 id="1-데이터-로드">1. 데이터 로드</h2><hr /><h3 id="11-데이터-로드---label-data">1.1 데이터 로드 - Label Data</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'Fashion_MNIST/train.csv'</span><span class="p">)[</span><span class="s">'class'</span><span class="p">])</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'./Fashion_MNIST/test_sample.csv'</span><span class="p">)</span>
</pre></table></code></div></div><ul><li>Data는 <a href="https://github.com/hmkim312/datas/tree/main/mnist_fashion">https://github.com/hmkim312/datas/tree/main/mnist_fashion</a>에 있습니다.</li><li>y label은 train.csv파일에 class라는 컬럼에 있습니다.</li><li>y값은 id값의 순서대로 들어가져 있습니다.</li></ul><h3 id="12-데이터-로드---train-data">1.2 데이터 로드 - Train Data</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre><td class="rouge-code"><pre><span class="n">train_path</span> <span class="o">=</span> <span class="s">'./Fashion_MNIST/images/train/'</span>
<span class="n">test_path</span> <span class="o">=</span> <span class="s">'./Fashion_MNIST/images/test/'</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">mpimg</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">train_path</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s">'.png'</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">60000</span><span class="p">)])</span>
<span class="c1"># for i in range(0,60000):
#     image_path = str(i) + '.png'
#     image = mpimg.imread(train_path + str(i) + '.png')
#     train_images.append(image)
</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">mpimg</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">test_path</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s">'.png'</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10000</span><span class="p">)])</span>
<span class="c1"># for i in range(0,10000):
#     image_path = str(i) + '.png'
#     image = mpimg.imread(test_path + str(i) + '.png')
#     test_images.append(image)
</span></pre></table></code></div></div><ul><li>Train 데이터는 한장 한장 실제 이미지로 있습니다.</li><li>따라서 이미지를 불러오는데 별도의 전처리를 해야합니다.</li><li>matplotlib의 image를 사용하여 불러왔고, 파일명이 곧 id이 이므로, 순서대로 가져오면 0번 ~ 6만번, 0번 ~ 1만번의 데이터를 가져옵니다.</li></ul><h3 id="13-데이터-로드---data-shape">1.3 데이터 로드 - Data Shape</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test</span><span class="p">.</span><span class="n">shape</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>((60000, 28, 28), (60000,), (10000, 28, 28))
</pre></table></code></div></div><ul><li>X_train 데이터는 60,000장에 28 by 28 데이터로 Chanel은 1개로 Gray 스케일이며, Chanel에 대한 정보는 생략되어 있습니다.</li><li>y_train 데이터는 X_train의 라벨입니다. 총 6만개의 데이터의 라벨로 구성되어 있습니다.</li><li>Test 데이터는 10,000장의 28 by 28로 Train 데이터와 이미지 크기는 똑같습니다.</li></ul><h2 id="2-데이터-라벨링">2. 데이터 라벨링</h2><hr /><h3 id="21-데이터-라벨링---종류">2.1 데이터 라벨링 - 종류</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">mnist_fashion_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s">'T-shirt/top'</span><span class="p">,</span> <span class="s">'Trouser'</span><span class="p">,</span> <span class="s">'Pullover'</span><span class="p">,</span> <span class="s">'Dress'</span><span class="p">,</span> <span class="s">'Coat'</span><span class="p">,</span> <span class="s">'Sandal'</span><span class="p">,</span> <span class="s">'Shirt'</span><span class="p">,</span> <span class="s">'Sneaker'</span><span class="p">,</span> <span class="s">'Bag'</span><span class="p">,</span><span class="s">'Ankle Boot'</span><span class="p">]</span>
</pre></table></code></div></div><ul><li>Mnist Fashion Image의 라벨은 총 10가지로 0 ~ 9까지 구성되어 있으며, 각각의 숫자는 다음의 클래스를 의미합니다.</li></ul><h3 id="22-데이터-라벨링---종류">2.2 데이터 라벨링 - 종류</h3><div class="table-wrapper"><table><thead><tr><th style="text-align: center">Label<th>Class<th style="text-align: center">Label<th>Class<tbody><tr><td style="text-align: center">0<td>T-shirt/top(티셔츠)<td style="text-align: center">1<td>Trouser(바지)<tr><td style="text-align: center">2<td>Pullover(풀오버스웨터)<td style="text-align: center">3<td>Dress(드레스)<tr><td style="text-align: center">4<td>Coat(코드)<td style="text-align: center">5<td>Sandal(샌들)<tr><td style="text-align: center">6<td>Shirt(셔츠)<td style="text-align: center">7<td>Sneaker(운동화)<tr><td style="text-align: center">8<td>Bag(가방)<td style="text-align: center">9<td>Ankle boot(발목 부츠)</table></div><h2 id="3-데이터-시각화">3. 데이터 시각화</h2><hr /><h3 id="31-데이터-시각화---코드">3.1 데이터 시각화 - 코드</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">figure</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">15</span><span class="p">)):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">figure</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">xticks</span><span class="o">=</span><span class="p">[],</span> <span class="n">yticks</span><span class="o">=</span><span class="p">[])</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">cmap</span> <span class="o">=</span> <span class="s">'gray'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">y_train</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s"> : </span><span class="si">{</span><span class="n">mnist_fashion_labels</span><span class="p">[</span><span class="n">y_train</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><h3 id="32-데이터-시각화">3.2 데이터 시각화</h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/117663990-37155b00-b1dc-11eb-8bd5-b2fd0bb28dc9.png" /></p><ul><li>Train 데이터에서 랜덤하게 15개 데이터를 골라 시각화 하였습니다.</li><li>28 by 28의 1채널이라 화질이 그렇게 좋은 이미지는 아니지만, 눈으로 보아도 어떤 의류 사진인지 알수 있는것도 있으나, 아닌것도 있습니다.</li></ul><h4 id="33-데이터-시각화---코드">3.3 데이터 시각화 - 코드</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">8703</span><span class="p">],</span> <span class="n">cmap</span> <span class="o">=</span><span class="s">'gray'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">y_train</span><span class="p">[</span><span class="mi">8703</span><span class="p">]</span><span class="si">}</span><span class="s"> : </span><span class="si">{</span><span class="n">mnist_fashion_labels</span><span class="p">[</span><span class="n">y_train</span><span class="p">[</span><span class="mi">8703</span><span class="p">]]</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">yticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><h4 id="34-데이터-시각화">3.4 데이터 시각화</h4><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/117663993-37adf180-b1dc-11eb-882a-d3933c5667de.png" /></p><ul><li>Train Data를 하나 골라 시각화 해보았습니다.</li><li>이미지는 6번 Shirt(셔츠) 입니다.</li></ul><h4 id="35-데이터-시각화---array">3.5 데이터 시각화 - Array</h4><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
</pre><td class="rouge-code"><pre>[[  0.   0.   0.   0.   0.   0.   3.   5.   0.   0.   0. 137. 172. 139. 183. 142.   0.   0.   2.   1.   0.   0.   1.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   3.   0.   0.   0.   0.   0. 224. 171. 169. 208. 229.   0.   0.   0.   0.   5.   2.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.   0.  33.  76. 179. 199. 173. 213. 201. 150. 169.  89.  12.   0.   0.   0.   0.   0.   0.   0.   0.   0.]
 [  0.   0.   1.   0.   0.  73. 163. 189. 211. 191. 168. 168. 199. 192. 192. 167. 180. 197. 186. 155.  79.  10.   0.   0.   1.   0.   0.   0.]
 [  0.   0.   0.   0. 105. 197. 183. 187. 184. 167. 152. 171. 162. 159. 147. 166. 170. 162. 152. 167. 180. 174. 100.   0.   1.   0.   0.   0.]
 [  0.   0.   0.   4. 190. 179. 177. 160. 166. 171. 169. 166. 165. 171. 165. 162. 161. 162. 157. 156. 160. 168. 175.  14.   0.   3.   0.   0.]
 [  0.   0.   0.  73. 192. 178. 176. 188. 166. 172. 182. 166. 169. 186. 171. 168. 167. 147. 184. 168. 162. 157. 186.  76.   0.   2.   0.   0.]
 [  0.   0.   0. 125. 199. 193. 192. 167. 180. 161. 158. 166. 157. 159. 169. 153. 159. 157. 148. 168. 164. 170. 185. 125.   0.   0.   0.   0.]
 [  0.   0.   0. 163. 181. 187. 230. 179. 177. 159. 157. 165. 157. 170. 168. 155. 162. 167. 134. 148. 177. 184. 177. 152.   0.   0.   0.   0.]
 [  0.   0.   0. 190. 183. 154. 228. 204. 195. 183. 173. 182. 175. 179. 155. 174. 189. 178. 162. 161. 219. 171. 171. 168.   0.   0.   0.   0.]
 [  0.   0.   0. 197. 185. 163. 216. 206. 185. 181. 165. 187. 171. 155. 167. 168. 161. 171. 173. 151. 141. 190. 169. 202.   0.   0.   0.   0.]
 [  0.   0.   0. 206. 172. 182. 179. 195. 194. 180. 198. 175. 182. 203. 181. 174. 176. 153. 197. 153.  71. 211. 169. 168.  24.   0.   0.   0.]
 [  0.   0.  27. 215. 175. 194. 172. 186. 194. 169. 196. 190. 171. 190. 183. 178. 182. 158. 208. 164.  50. 230. 171. 183.  57.   0.   0.   0.]
 [  0.   0.  39. 225. 187. 212. 126. 155. 218. 158. 164. 179. 175. 162. 160. 168. 179. 155. 173. 159.  53. 253. 179. 187.  78.   0.   0.   0.]
 [  0.   0.  59. 219. 177. 234.  98. 100. 224. 168. 172. 177. 174. 165. 162. 161. 179. 160. 168. 146.  33. 235. 182. 184. 120.   0.   0.   0.]
 [  0.   0.  87. 216. 178. 241.  53.  99. 242. 178. 174. 187. 189. 190. 160. 172. 201. 166. 173. 145.  15. 225. 177. 181. 153.   0.   0.   0.]
 [  0.   0. 115. 209. 176. 238.   1. 107. 226. 173. 170. 180. 164. 162. 169. 167. 172. 171. 160. 162.   0. 223. 185. 176. 176.   0.   0.   0.]
 [  0.   0. 128. 190. 174. 236.   0. 143. 217. 172. 197. 188. 180. 196. 173. 169. 179. 169. 179. 189.   0. 203. 194. 171. 176.   0.   0.   0.]
 [  0.   0. 145. 191. 186. 220.   0. 162. 221. 166. 197. 193. 173. 185. 206. 171. 174. 171. 173. 202.   0. 187. 210. 173. 186.  21.   0.   0.]
 [  0.   0. 160. 183. 192. 200.   0. 167. 213. 176. 159. 189. 172. 159. 168. 187. 161. 170. 149. 192.   0. 140. 222. 170. 192.  51.   0.   0.]
 [  0.   0. 160. 184. 189. 164.   0. 170. 215. 173. 170. 179. 168. 174. 150. 186. 181. 174. 149. 194.   0.  66. 223. 160. 188.  63.   0.   0.]
 [  0.   0. 151. 186. 201. 106.   0. 181. 208. 186. 178. 185. 180. 184. 146. 194. 209. 170. 166. 202.   0.   0. 255. 168. 204.  58.   0.   0.]
 [  0.   0. 141. 188. 230.  61.   0. 191. 201. 182. 179. 184. 173. 156. 175. 169. 187. 179. 159. 175.   0.   0. 218. 187. 171.  56.   0.   0.]
 [  0.   0. 118. 186. 214.   0.   0. 197. 200. 178. 196. 181. 181. 192. 177. 181. 184. 181. 179. 191.   8.   0. 123. 200. 170.  50.   0.   0.]
 [  0.   0. 124. 185. 196.   0.   0. 205. 203. 185. 202. 203. 175. 204. 190. 178. 189. 177. 189. 210.  20.   0.  48. 194. 171.  62.   0.   0.]
 [  0.   0. 166. 208. 186.   0.   0. 221. 201. 183. 172. 196. 179. 169. 163. 163. 187. 173. 167. 175.  34.   0.  10. 186. 176. 130.   0.   0.]
 [  0.   0. 142. 156. 167.   0.   0. 178. 211. 200. 201. 207. 197. 187. 178. 181. 219. 202. 176. 224.  32.   0.   0. 186. 140. 101.   0.   0.]
 [  0.   0.   0.   0.   0.   0.   0.   0.  53.  93.  98. 119. 132. 135. 121. 123. 126. 108.  79.  24.   0.   0.   0.   0.   0.   0.   0.   0.]]
</pre></table></code></div></div><ul><li>검은곳은 0이고 색깔이 있는 부분에 숫자가 있는것을 알수 있습니다.</li><li>이러한 숫자의 패턴으로 알고리즘들이 패턴을 찾고, 어떤 이미지인지 예측할수 있습니다.</li></ul><h2 id="4-머신러닝-딥러닝을-위한-데이터-처리">4. 머신러닝, 딥러닝을 위한 데이터 처리</h2><hr /><h4 id="41-머신러닝-딥러닝을-위한-데이터-처리---validation-data-split">4.1 머신러닝, 딥러닝을 위한 데이터 처리 - Validation Data Split</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">stratify</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">87</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">.</span><span class="n">shape</span>
</pre></table></code></div></div><p>((48000, 28, 28), (12000, 28, 28), (48000,), (12000,))</p><ul><li>Train 데이터 6만장을 실제 모델 학습 데이터와 모델의 검증 데이터로 나누겠습니다.</li><li>학습 데이터를 나누는 이유는 생성된 모델의 성능이 과적합인지, 성능은 제대로 나오는지 등을 확인하기 위해서 입니다.</li><li>Train 데이터에서 검증용 데이터와 학습용 데이터로 한번더 나누어서 모델 학습은 학습용 데이터로 진행합니다.</li><li>생성된 모델을 검증용 데이터로 모델의 성능을 확인합니다.</li><li>모델 성능이 확인되면 마지막으로 제출해야할 실제 y값이 없는 테스트 데이터를 예측 후 해당 결과를 csv파일로 저장하여 제출합니다.</li><li>즉, 6만장 데이터를 4만8천장의 모델 학습용 데이터와, 1만 2천장의 모델 검증용 데이터로 나누어 모델을 생성 한 후 생성된 모델을 1만장의 test 데이터를 예측합니다.</li></ul><h4 id="42-머신러닝-딥러닝을-위한-데이터-처리---stratify">4.2 머신러닝, 딥러닝을 위한 데이터 처리 - Stratify</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">unique</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">unique</span><span class="p">,</span> <span class="n">counts</span><span class="p">))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre>{0: 4800,
 1: 4800,
 2: 4800,
 3: 4800,
 4: 4800,
 5: 4800,
 6: 4800,
 7: 4800,
 8: 4800,
 9: 4800}
</pre></table></code></div></div><ul><li>또한 split 과정에서 stratify 옵션을 넣어 label의 class가 모두 동일한 비율로 들어가게 만들었습니다.</li></ul><h4 id="43-머신러닝-딥러닝을-위한-데이터-처리---scale">4.3 머신러닝, 딥러닝을 위한 데이터 처리 - Scale</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">X_train</span><span class="p">.</span><span class="nb">min</span><span class="p">(),</span>  <span class="n">X_train</span><span class="p">.</span><span class="nb">max</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>(0.0, 1.0)
</pre></table></code></div></div><ul><li>제공받은 데이터는 최소값이 0, 최대값이 1이므로 MinMax Scaler가 적용되어 있어, 따로 Scale을 하지 않습니다.</li></ul><h2 id="5-machine-learning">5. Machine Learning</h2><hr /><h3 id="51-machine-learning---데이터-처리">5.1 Machine Learning - 데이터 처리</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">skfold</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">87</span><span class="p">)</span>
<span class="n">X_train_reshape</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">)</span> <span class="c1"># 48000, 784
</span><span class="n">X_valid_reshape</span> <span class="o">=</span> <span class="n">X_valid</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_valid</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">)</span> <span class="c1"># 12000, 784
</span><span class="n">X_test_reshape</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">)</span> <span class="c1"># 10000, 784
</span></pre></table></code></div></div><ul><li>머신러닝을 하기전에 28 by 28의 데이터를 flatten하게 48000 * 784와 12000 * 28형식으로 reshape 해주었습니다.</li><li>즉, 6만개의 데이터가 있고 총 784개의 특성이 있는 형식입니다.</li><li>또한 학습에 Cross Validation을 위해 StratifiedKFold를 생성합니다.</li></ul><h3 id="52-machine-learning---decisiontree-학습">5.2 Machine Learning - DecisionTree 학습</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">87</span><span class="p">)</span>
<span class="n">cv_score</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X_train_reshape</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="n">skfold</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">Accuracy: {:.4f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">cv_score</span><span class="p">.</span><span class="n">mean</span><span class="p">()))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>Accuracy: 0.7900
</pre></table></code></div></div><ul><li>가장 먼저 DecisionTree로 학습해보았습니다.</li><li>KFold로 검증한 평균 Accuracy는 0.79정도가 나옵니다.</li></ul><h3 id="53-machine-learning---decisiontree-검증">5.3 Machine Learning - DecisionTree 검증</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_reshape</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">Accuracy: {:.4f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">clf</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_valid_reshape</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>Accuracy: 0.7896
</pre></table></code></div></div><ul><li>Decision Tree를 사용하여 만든 모델의 검증결과는 Accuracy 0.7896 입니다.</li><li>모델의 성능이 좋은편은 아닌듯 합니다.</li></ul><h3 id="54-machine-learning--randomforest-학습">5.4 Machine Learning- RandomForest 학습</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">87</span><span class="p">)</span>
<span class="n">cv_score</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">rf</span><span class="p">,</span> <span class="n">X_train_reshape</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="n">skfold</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">Accuracy: {:.4f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">cv_score</span><span class="p">.</span><span class="n">mean</span><span class="p">()))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>Accuracy: 0.8799
</pre></table></code></div></div><ul><li>RandomForest는 Decision Tree들이 모인 앙상블 기법입니다.</li><li>보통 Decision Tree보다 성능이 좋은것으로 알려져 있습니다.</li><li>KFold를 진행하여, 평균 Accuracy를 확인해보니 0.8799가 나옵니다. 확실히 Decision Tree보다 성능이 좋습니다.</li></ul><h3 id="54-machine-learning---randomforest-검증">5.4 Machine Learning - RandomForest 검증</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">rf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_reshape</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">Accuracy: {:.4f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">rf</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_valid_reshape</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>Accuracy: 0.8805
</pre></table></code></div></div><ul><li>RandomForest를 사용하여 생성한 모델의 검증 결과는 Accuracy 0.8805 입니다.</li><li>어느정도 준수한 성능을 보여줍니다.</li></ul><h2 id="6-deep-learning">6. Deep Learning</h2><hr /><h3 id="61-deep-learning---데이터-처리">6.1 Deep Learning - 데이터 처리</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">y_train_one_hot</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">y_valid_one_hot</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</pre></table></code></div></div><ul><li>keras의 유틸을 사용하여, y 라벨을 one-hot encoding 해줍니다.</li><li>One-Hot encodig이란 <em>9</em> 라고 표현된 라벨을 [0,0,0,0,0,0,0,0,0,1]의 벡터로 바꾸어주는 것입니다.</li><li>Deep Learning은 각 클래스별로 확률을 출력해주기 때문에 꼭 필요한 작업 입니다.</li></ul><h3 id="62-deep-learning---multi-layer-perceptron-model">6.2 Deep Learning - Multi Layer Perceptron Model</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre><span class="n">mlp_model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">'relu'</span><span class="p">),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">800</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">'relu'</span><span class="p">),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">'relu'</span><span class="p">),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">'relu'</span><span class="p">),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">'relu'</span><span class="p">),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">'relu'</span><span class="p">),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">'relu'</span><span class="p">),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">'softmax'</span><span class="p">),</span>
<span class="p">])</span>
</pre></table></code></div></div><h3 id="62-deep-learning---multi-layer-perceptron-model-1">6.2 Deep Learning - Multi Layer Perceptron Model</h3><ul><li>처음 input size는 train 데이터인 (48000, 28, 28)입니다.</li><li>위의 28, 28 데이터를 평평하게 (flatten) 784로 바꾸어 줍니다.</li><li>히든 레이어에서 1000 -&gt; 800 -&gt; 500 -&gt; 300 -&gt; 200 -&gt; 100 -&gt; 50 개의 노드가 출력되고 마지막 레이어에서 10개의 노드를 출력합니다. 10개는 y라벨의 갯수 즉, class 입니다.</li><li>마지막 layer에 softmax 활성화 함수를 사용하여 10개의 노드에 대한 확률을 출력하고, 가장 높은값을 예측값으로 사용합니다.</li></ul><h3 id="63-deep-learning---multi-layer-perceptron-summary">6.3 Deep Learning - Multi Layer Perceptron Summary</h3><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
</pre><td class="rouge-code"><pre>Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_3 (Flatten)          (None, 784)               0         
_________________________________________________________________
dense_20 (Dense)             (None, 1000)              785000    
_________________________________________________________________
dropout_17 (Dropout)         (None, 1000)              0         
_________________________________________________________________
dense_21 (Dense)             (None, 800)               800800    
_________________________________________________________________
dropout_18 (Dropout)         (None, 800)               0         
_________________________________________________________________
dense_22 (Dense)             (None, 500)               400500    
_________________________________________________________________
dropout_19 (Dropout)         (None, 500)               0         
_________________________________________________________________
dense_23 (Dense)             (None, 300)               150300    
_________________________________________________________________
dropout_20 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_24 (Dense)             (None, 200)               60200     
_________________________________________________________________
dropout_21 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_25 (Dense)             (None, 100)               20100     
_________________________________________________________________
dropout_22 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_26 (Dense)             (None, 50)                5050      
_________________________________________________________________
dense_27 (Dense)             (None, 10)                510       
=================================================================
Total params: 2,222,460
Trainable params: 2,222,460
Non-trainable params: 0
_________________________________________________________________
</pre></table></code></div></div><h3 id="63-deep-learning---multi-layer-perceptron-summary-1">6.3 Deep Learning - Multi Layer Perceptron Summary</h3><ul><li>layer는 각 층에서 행하는 type이고, output shape는 해당 층을 거치면 나오게 되는 output에 대한 size 입니다.</li><li>Param은 해당 layer에서 가치는 파라미터 수이며,</li><li>파라미터의 수는 (입력 데이터 차원 + 1) * 뉴런 수로 계산합니다.</li><li>ex : dense = (784 +1) * 392 = 307720개</li></ul><h3 id="64-deep-learning---multi-layer-perceptron-compile">6.4 Deep Learning - Multi Layer Perceptron compile</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">mlp_model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="s">'Adam'</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">'categorical_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
</pre></table></code></div></div><ul><li>loss : 손실함수, 모델의 최적화에 사용되는 목적함수입니다. 모델과 데이터 분류종류에 따라 MSE, categorical_crossentropy, sparse_categorical_crossentropy, binary_crossentropy 등 이 있습니다.</li><li>optimizer : 최적의 가중치를 검색하는 데 사용되는 최적화 알고리즘. adam이 대표적입니다.</li><li>metrics : 모델의 성능을 저장하는 지표를 의미하며, 이번에는 Accuracy를 사용합니다. 리스트 형태로 여러개도 저장가능합니다.</li></ul><h3 id="65-deep-learning---multi-layer-perceptron-학습">6.5 Deep Learning - Multi Layer Perceptron 학습</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">checkpoint</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="s">'model.weights.best.mlp.develop.hdf5'</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">earlystopping</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s">'val_loss'</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">mlp_history</span> <span class="o">=</span> <span class="n">mlp_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_one_hot</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
                            <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">earlystopping</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></table></code></div></div><ul><li>batch : 전체 데이터셋 중 batch의 크기만큼 학습시키것을 의미합니다.</li><li>epochs : 전체 데이터셋을 학습시키는 수입니다.</li><li>ModelCheckpoint : epoch마다 성능이 좋아지면 모델을 저장합니다.(model.weights.best.mlp.develop.hdf5 라는 이름으로 저장됨)</li><li>EarlyStopping : epoch 마다 설정한 성능이 좋아지지 않으면 자동으로 학습을 종료시킵니다. 위에서는 val_loss 이며, epoch 20회동안 나아지지 않으면 멈춥니다.</li><li>validation_split : 입력받은 데이터의 20%를 사용하여 매 epochs 마다 검증을 실행합니다.</li></ul><h3 id="66-deep-learning---multi-layer-perceptron-학습시각화-코드">6.6 Deep Learning - Multi Layer Perceptron 학습시각화 코드</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre><td class="rouge-code"><pre><span class="n">fig</span><span class="p">,</span> <span class="n">loss_ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="n">acc_ax</span> <span class="o">=</span> <span class="n">loss_ax</span><span class="p">.</span><span class="n">twinx</span><span class="p">()</span>

<span class="n">loss_ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mlp_history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">],</span> <span class="s">'y'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'train loss'</span><span class="p">)</span>
<span class="n">loss_ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mlp_history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">],</span> <span class="s">'r'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'val loss'</span><span class="p">)</span>
<span class="n">loss_ax</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'epoch'</span><span class="p">)</span>
<span class="n">loss_ax</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'loss'</span><span class="p">)</span>
<span class="n">loss_ax</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'upper right'</span><span class="p">)</span>

<span class="n">acc_ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mlp_history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">],</span> <span class="s">'b'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'train acc'</span><span class="p">)</span>
<span class="n">acc_ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mlp_history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_accuracy'</span><span class="p">],</span> <span class="s">'g'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'val acc'</span><span class="p">)</span>
<span class="n">acc_ax</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'accuracy'</span><span class="p">)</span>
<span class="n">acc_ax</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'upper left'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><h3 id="66-deep-learning---multi-layer-perceptron-학습시각화">6.6 Deep Learning - Multi Layer Perceptron 학습시각화</h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/117663994-37adf180-b1dc-11eb-9caa-4f57bb0899a9.png" /></p><ul><li>epoch가 늘어날때마다 학습 데이터의 loss는 줄어드는데, 검증 데이터의 loss는 점점 늘어나고 있습니다.</li><li>이는 학습이 진행될수록 점점 train 데이터에 과적합되어 다른 데이터는 잘 예측하지 못한다고 볼수 있습니다.</li><li>검증 loss가 줄지 않아 early stopping이 적용되어 약 80 epoch전에 학습이 종료된것으로 보입니다.</li></ul><h3 id="67-deep-learning---multi-layer-perceptron-예측">6.7 Deep Learning - Multi Layer Perceptron 예측</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">mlp_model</span><span class="p">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s">'model.weights.best.mlp.develop.hdf5'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">Accuracy: {:.4f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">mlp_model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid_one_hot</span><span class="p">)[</span><span class="mi">1</span><span class="p">]))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>375/375 [==============================] - 0s 885us/step - loss: 0.3000 - accuracy: 0.8953

Accuracy: 0.8953
</pre></table></code></div></div><ul><li>load_weights로 가장 학습이 잘된 모델의 가중치를 가져와서 검증을 해봅니다.</li><li>Accuracy는 0.8953로 사실 RandomForest보다는 나은 성능을 보여줍니다.</li></ul><h3 id="68-deep-learning---convolution-neural-network-데이터-전처리">6.8 Deep Learning - Convolution Neural Network 데이터 전처리</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">X_train_cnn</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">X_valid_cnn</span> <span class="o">=</span> <span class="n">X_valid</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_valid</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">X_test_cnn</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></table></code></div></div><ul><li>cnn 모델에 넣기 위해 data를 reshape 해줍니다.</li><li>사진이미지를 넣을때 마지막에 1인 chanel입니다. Mnist Fashion image는 gray scale이므로 1채널이라, 마지막에 1을 붙여줍니다.</li></ul><h3 id="69-deep-learning---convolution-neural-network-model">6.9 Deep Learning - Convolution Neural Network Model</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
</pre><td class="rouge-code"><pre><span class="n">cnn_model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="s">'same'</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">'relu'</span><span class="p">,</span> <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span> <span class="o">=</span> <span class="mi">2</span><span class="p">),</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">),</span>
    
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="s">'same'</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">'relu'</span><span class="p">),</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span> <span class="o">=</span> <span class="mi">2</span><span class="p">),</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">),</span>
    
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="s">'same'</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">'relu'</span><span class="p">),</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span> <span class="o">=</span> <span class="mi">2</span><span class="p">),</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">),</span>
    
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="s">'same'</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">'relu'</span><span class="p">),</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span> <span class="o">=</span> <span class="mi">2</span><span class="p">),</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">),</span>
    
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">(),</span> <span class="c1"># Flaatten으로 이미지를 일차원으로 바꿔줌
</span>    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">'relu'</span><span class="p">),</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">'relu'</span><span class="p">),</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">'relu'</span><span class="p">),</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">'softmax'</span><span class="p">)</span>
<span class="p">])</span>
</pre></table></code></div></div><h3 id="69-deep-learning---convolution-neural-network-model-1">6.9 Deep Learning - Convolution Neural Network Model</h3><ul><li><strong>input_shape</strong> : 샘플 수를 제외한 입력 형태를 정의 합니다. 모델에서 첫 레이어일 때만 정의하면 됩니다. (행, 열, 채널 수)로 정의합니다. 흑백영상인 경우에는 채널이 1이고, 컬러(RGB)영상인 경우에는 채널을 3으로 설정합니다.</li><li><strong>activation</strong> : 활성화 함수를 설정<ul><li>linear : 디폴트 값, 입력뉴런과 가중치로 계산된 결과값이 그대로 출력으로 나옵니다.</li><li>relu : rectifier 함수, 은익층에 주로 쓰입니다. 0이하는 0으로 만들고 그 이상은 그대로 출력합니다.</li><li>sigmoid : 시그모이드 함수, 이진 분류 문제에서 출력층에 주로 쓰입니다. 0 혹은 1로 출력합니다.</li><li>softmax : 소프트맥스 함수, 다중 클래스 분류 문제에서 출력층에 주로 쓰입니다. 0과 1사이의 값으로 출력되며, 모두 더한값은 1이 되므로, 확률처럼 사용합니다.</li></ul></li><li><strong>filter(kernel)</strong> : 이미지의 특징을 찾기위한 파라미터, 해당 filter가 이미지를 움직이며 특징을 잡아냄, 해당 특징이 featuremap, filter의 종류에 따라 가로선 filter, 세로선 filter등이 있는데 cnn에선 해당 필터를 자동으로 생성함</li><li><strong>featuremap</strong> : input 이미지에서 filter로 만들어진 해당 이미지의 특성을 가진 map</li><li><strong>filters</strong> : input 이미지에서 featuremap을 생성 하는 filter의 갯수</li><li><strong>padding</strong> : 외곽의 값을 0으로 채워넣어서 filter들로 만들어진 featuremap 기존의 이미지의 크기와 같게 할지의 여부 same은 같게, valid는 다르게, same으로 하면 filter가 이미지 사이즈에 맞게 featuremap을 만듬.</li><li><strong>pooling</strong> : 계속 filter가 이미지를 움직이며 featuremap을 만들고 paddind이 same이라면 계속 같은 크기의 featuremap이 생성되게 됨. 이를 방지하기 위해 pooling 레이어를 거쳐 이미지 사이즈를 줄임, pool_size는 이미지에서 줄여지는 값<ul><li>maxpooling : pooling 영역에서 가장 큰 값만 남기는것</li><li>averagepoolig : pooling 영역의 모든 데이터의 평균값을 구하여 남김</li></ul></li><li><strong>dropout</strong> : 이미지의 일부분을 drop시켜 학습하는데 어려움을 줌, 이로 인해 과적함을 막을 수 있습니다.</li><li><strong>flatten</strong> : 앞에서 만든 (7, 7, 64)의 배열을 7 * 7 * 64하여 3136의 1줄의 배열로 평평하게 만드는것 입니다.<ul><li>(2번의 pooling으로 이미지 사이즈가 작아짐, 28, 28, 64 -&gt; 14, 14, 64 -&gt; 7, 7, 64)</li></ul></li><li><strong>dense</strong> : 평평한 데이터가 들어오면, 해당 데이터를 dense레이어를 지나 맨앞의 사이즈로 줄여줌, 마지막은 10개 사이즈가 나오고, 이를 softmax함수로 활성화하여 0 ~ 9까지의 클래스를 예측할수 있게 해줍니다.</li></ul><h3 id="69-deep-learning---convolution-neural-network-summary">6.9 Deep Learning - Convolution Neural Network summary</h3><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
</pre><td class="rouge-code"><pre>Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 28, 28, 64)        320       
_________________________________________________________________
batch_normalization_4 (Batch (None, 28, 28, 64)        256       
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 14, 14, 64)        0         
_________________________________________________________________
dropout_23 (Dropout)         (None, 14, 14, 64)        0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 14, 14, 64)        16448     
_________________________________________________________________
batch_normalization_5 (Batch (None, 14, 14, 64)        256       
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         
_________________________________________________________________
dropout_24 (Dropout)         (None, 7, 7, 64)          0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 7, 7, 128)         32896     
_________________________________________________________________
batch_normalization_6 (Batch (None, 7, 7, 128)         512       
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 3, 3, 128)         0         
_________________________________________________________________
dropout_25 (Dropout)         (None, 3, 3, 128)         0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 3, 3, 128)         65664     
_________________________________________________________________
batch_normalization_7 (Batch (None, 3, 3, 128)         512       
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 1, 1, 128)         0         
_________________________________________________________________
dropout_26 (Dropout)         (None, 1, 1, 128)         0         
_________________________________________________________________
flatten_4 (Flatten)          (None, 128)               0         
_________________________________________________________________
dense_28 (Dense)             (None, 1024)              132096    
_________________________________________________________________
dense_29 (Dense)             (None, 512)               524800    
_________________________________________________________________
dense_30 (Dense)             (None, 256)               131328    
_________________________________________________________________
dropout_27 (Dropout)         (None, 256)               0         
_________________________________________________________________
dense_31 (Dense)             (None, 10)                2570      
=================================================================
Total params: 907,658
Trainable params: 906,890
Non-trainable params: 768
_________________________________________________________________
</pre></table></code></div></div><h3 id="69-deep-learning---convolution-neural-network-compile">6.9 Deep Learning - Convolution Neural Network compile</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">cnn_model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span> <span class="o">=</span> <span class="s">'categorical_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="s">'adam'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
</pre></table></code></div></div><ul><li>loss, optimizer, metrics는 MLP때와 동일 합니다.</li></ul><h3 id="69-deep-learning---convolution-neural-network-학습">6.9 Deep Learning - Convolution Neural Network 학습</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">checkpointer</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="s">'model.weights.best.cnn.hdf5'</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">earlystopping</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s">'val_loss'</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">cnn_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_cnn</span><span class="p">,</span> <span class="n">y_train_one_hot</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpointer</span><span class="p">,</span> <span class="n">earlystopping</span><span class="p">])</span>
</pre></table></code></div></div><ul><li>Epochs와 Batch_size를 지정해주고 CNN 모델을 학습시켰습니다.</li><li>MLP 떄와 마찬가지로 Early Stopping 기능과 checkpoint 기능으로 성능이 개선되지않으면 학습을 멈추고, 가장 베스트 모델을 저장 시킵니다.</li></ul><h3 id="610-deep-learning---convolution-neural-network-학습-시각화-코드">6.10 Deep Learning - Convolution Neural Network 학습 시각화 코드</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre><td class="rouge-code"><pre><span class="n">fig</span><span class="p">,</span> <span class="n">loss_ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="n">acc_ax</span> <span class="o">=</span> <span class="n">loss_ax</span><span class="p">.</span><span class="n">twinx</span><span class="p">()</span>

<span class="n">loss_ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">],</span> <span class="s">'y'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'train loss'</span><span class="p">)</span>
<span class="n">loss_ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">],</span> <span class="s">'r'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'val loss'</span><span class="p">)</span>
<span class="n">loss_ax</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'epoch'</span><span class="p">)</span>
<span class="n">loss_ax</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'loss'</span><span class="p">)</span>
<span class="n">loss_ax</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'upper right'</span><span class="p">)</span>

<span class="n">acc_ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">],</span> <span class="s">'b'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'train acc'</span><span class="p">)</span>
<span class="n">acc_ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_accuracy'</span><span class="p">],</span> <span class="s">'g'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'val acc'</span><span class="p">)</span>
<span class="n">acc_ax</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'accuracy'</span><span class="p">)</span>
<span class="n">acc_ax</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'upper left'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><h3 id="610-deep-learning---convolution-neural-network-학습-시각">6.10 Deep Learning - Convolution Neural Network 학습 시각</h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/117663996-38468800-b1dc-11eb-9042-a617940e4bb6.png" /></p><ul><li>앞에서 학습했던 MLP 모델과 비교하여 loss도 굉장히 잘 떨어지고, train과 valid간의 차이도 많이 없어보입니다.</li><li>accuracy도 train과 valid간에 오르는것이 보입니다.</li></ul><h3 id="611-deep-learning---convolution-neural-network-검증">6.11 Deep Learning - Convolution Neural Network 검증</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">cnn_model</span><span class="p">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s">'model.weights.best.cnn.hdf5'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">Accuracy: {:.4f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">cnn_model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_valid_cnn</span><span class="p">,</span> <span class="n">y_valid_one_hot</span><span class="p">)[</span><span class="mi">1</span><span class="p">]))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>375/375 [==============================] - 0s 1ms/step - loss: 0.2169 - accuracy: 0.9252

Accuracy: 0.9252
</pre></table></code></div></div><ul><li>CNN의 성능이 여태까지의 모델중에 좋게나왔습니다.</li><li>MLP도 Accuracy가 0.9를 넘지못했는데, CNN은 0.9252로 0.9의 Acuuracy를 넘었습니다.</li><li>확실히 이미지쪽은 CNN이 좋은듯 합니다.</li></ul><h3 id="610-deep-learning---convolution-neural-network-예측-후-저장">6.10 Deep Learning - Convolution Neural Network 예측 후 저장</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">cnn_predict</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">cnn_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_cnn</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_test_cnn</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">y_test_cnn</span><span class="p">[</span><span class="s">'class'</span><span class="p">]</span> <span class="o">=</span> <span class="n">cnn_predict</span>
<span class="n">y_test_cnn</span><span class="p">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s">'./Fashion_MNIST/cnn_test.csv'</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
</pre></table></code></div></div><ul><li>마지막으로 CNN의 모델로 X_test 데이터를 예측 한뒤 cnn_test.csv에 저장합니다.</li></ul><h2 id="7-결과-정리-및-회고">7. 결과 정리 및 회고</h2><hr /><h3 id="71-결과-정리-및-회고---결과-정리">7.1 결과 정리 및 회고 - 결과 정리</h3><ul><li>Decision Tree - Accuracy : 0.7898</li><li>RandomForest - Accuracy : 0.8805</li><li>Multi Layer Perceptron(MLP) - Accuracy : 0.8953</li><li>Convolution Neural Network(CNN) - Accuracy : 0.9252</li><li>위 결과에서 알수 있듯이 CNN이 가장 좋은 성능을 보였으며 Loss, Accuracy 그래프도 굉장히 안정적으로 보여서 만족합니다.</li><li>저희는 CNN의 모델을 사용하여 예측한 결과를 제출할 예정이고, Test Accuracy도 검증 Accuracy와 비슷한 0.92 정도의 Accuracy를 예상합니다.</li><li>ML 알고리즘 중 다른 (XGBoost, LGBM 등)도 사용하여 모델을 만들어보고 싶고, MLP, CNN도 Layer를 더 효율적으로 쌓아 성능 개선을 해보고 싶습니다.</li></ul><h3 id="72-결과-정리-및-회고---회고">7.2 결과 정리 및 회고 - 회고</h3><ul><li>Mnist Fashion Image는 ML, DL을 공부하신다면 한번씩 해보길 추천하는 기초적인 이미지 데이터입니다.</li><li>머릿속에서 잘 정리가 되지않았던 ML, DL 관련 알고리즘과 명령어들을 한번씩 더 볼수 있고, 정리가 되었던 기회였습니다.</li><li>향후 ML, DL 관련 프로젝트를 진행할때 이번에 공부한 기초적인 내용이 많은 도움이 될수 있을듯 합니다.</li></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/data-science/'>Data Science</a>, <a href='/categories/deep-learning/'>Deep Learning</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/mlp/" class="post-tag no-text-decoration" >MLP</a> <a href="/tags/cnn/" class="post-tag no-text-decoration" >CNN</a> <a href="/tags/decision-tree/" class="post-tag no-text-decoration" >Decision Tree</a> <a href="/tags/random-forest/" class="post-tag no-text-decoration" >Random Forest</a> <a href="/tags/mnist-fashion/" class="post-tag no-text-decoration" >Mnist Fashion</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><!-- Post sharing snippet v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Mnist Fashion으로 알아보는 Deep Learning - Data Include Me&url=https://datainclude.me/posts/Mnist_Fashion%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_Deep_Learning/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Mnist Fashion으로 알아보는 Deep Learning - Data Include Me&u=https://datainclude.me/posts/Mnist_Fashion%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_Deep_Learning/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Mnist Fashion으로 알아보는 Deep Learning - Data Include Me&url=https://datainclude.me/posts/Mnist_Fashion%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_Deep_Learning/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><!-- The Panel on right side (Desktop views) v2.3 © 2024 Your Name MIT License --><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><h3 data-toc-skip>Recent Update</h3><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li class="recent-item"> <a href="/posts/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C_%EC%BB%B4%ED%93%A8%ED%8C%85_%EA%B0%80%EC%83%81%ED%99%94/">클라우드 컴퓨팅 - 가상화</a> <span class="text-muted small">2024-10-28</span></li><li class="recent-item"> <a href="/posts/gemini_api_%EC%82%AC%EC%9A%A9%ED%95%B4%EB%B3%B4%EA%B8%B0/">Gemini API 사용해보기</a> <span class="text-muted small">2024-03-12</span></li><li class="recent-item"> <a href="/posts/Ollama%EC%99%80_Python_%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC_LLaMa2%EB%A5%BC_%EB%A1%9C%EC%BB%AC%EC%97%90%EC%84%9C_%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/">Ollama와 Python 라이브러리를 이용하여 LLaMa2를 로컬에서 사용하기</a> <span class="text-muted small">2024-02-13</span></li><li class="recent-item"> <a href="/posts/Mistral_7B_Fine_Tuning/">Mistral 7B 파인튜닝(Fine Tuning)하기</a> <span class="text-muted small">2023-10-25</span></li><li class="recent-item"> <a href="/posts/Penn_Fudan%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EA%B0%9D%EC%B2%B4_%ED%83%90%EC%A7%80_%EB%B6%84%ED%95%A0/">Penn-Fudan으로 알아보는 객체 탐지(Object Detection), 분할(Segmentation) with FasterRCNN</a> <span class="text-muted small">2023-10-23</span></li></ul></div><div id="access-tags"><h3 data-toc-skip>Trending Tags</h3><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/tensorflow/">Tensorflow</a> <a class="post-tag" href="/tags/sklearn/">Sklearn</a> <a class="post-tag" href="/tags/round/">Round</a> <a class="post-tag" href="/tags/python-lv0/">Python Lv0</a> <a class="post-tag" href="/tags/pca/">PCA</a> <a class="post-tag" href="/tags/eda/">EDA</a> <a class="post-tag" href="/tags/distinct/">Distinct</a> <a class="post-tag" href="/tags/random-forest/">Random Forest</a> <a class="post-tag" href="/tags/beautifulsoup/">Beautifulsoup</a> <a class="post-tag" href="/tags/baekjoon/">Baekjoon</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><h3 data-toc-skip class="pl-3 pt-2 mb-2">Contents</h3><nav id="toc" data-toggle="toc"></nav></div></div><style> .recent-item { margin-bottom: 0.5rem; } .recent-item a { color: var(--link-color); } .recent-item .small { font-size: 0.75rem; margin-left: 0.5rem; }</style></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"> <!-- Recommend the other 3 posts according to the tags and categories of the current post, if the number is not enough, use the other latest posts to supplement. v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%EC%9D%84_%EC%9D%B4%EC%9A%A9%ED%95%9C_%ED%83%80%EC%9D%B4%ED%83%80%EB%8B%89_%EC%83%9D%EC%A1%B4%EC%9E%90_%EC%98%88%EC%B8%A1/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Oct 17, 2020 <i class="unloaded">2020-10-17T09:10:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>머신러닝을 이용한 타이타닉 생존자 예측</h3><div class="text-muted small"><p> 1. 타이타닉 EDA 1.1 데이터 로드 import pandas as pd titanic = pd.read_excel('https://github.com/hmkim312/datas/blob/main/titanic/titanic.xls?raw=true') titanic.head() pclass ...</p></div></div></a></div><div class="card"> <a href="/posts/IBM_HR_Data%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_%ED%87%B4%EC%82%AC%EC%9E%90_%EC%98%88%EC%B8%A1/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Jun 2, 2021 <i class="unloaded">2021-06-02T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>IBM HR Data로 해보는 퇴사자 예측</h3><div class="text-muted small"><p> Predicting Employee Attrition IBM 데이터 과학자들이 만든 가상의 HR 데이터셋입니다. 1,470명에 대한 35개의 변수가 기록되어 있고, 종속변수는 Attrition, 즉 0 또는 1의 퇴사 여부입니다. Data Source: https://www.kaggle.com/pavansubhasht/ibm-hr-an...</p></div></div></a></div><div class="card"> <a href="/posts/MNIST_%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_CNN(Convolution_Neral_Network)/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Oct 29, 2020 <i class="unloaded">2020-10-29T11:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>MNIST 데이터로 해보는 CNN (Convolution Neral Network)</h3><div class="text-muted small"><p> 1. CNN (Convolution Neral Network) 1.1 CNN 이미지 영상인식의 혁명같은 CNN CNN은 이미지의 특징을 검출하여, 분류하는 것 CNN은 특징을 찾는 레이어와 분류를 하는 레이어로 구성됨 1.2 Convolutional Filter Convolution : 특정 패턴이 ...</p></div></div></a></div></div></div><!-- Navigation buttons at the bottom of the post. v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --><div class="post-navigation d-flex justify-content-between"> <a href="/posts/%EC%B5%9C%EC%86%9F%EA%B0%92_%EB%A7%8C%EB%93%A4%EA%B8%B0/" class="btn btn-outline-primary"><p>최솟값 만들기 [Python]</p></a> <a href="/posts/%EC%BF%BC%EB%93%9C_%EC%95%95%EC%B6%95_%ED%9B%84_%EA%B0%9C%EC%88%98_%EC%84%B8%EA%B8%B0/" class="btn btn-outline-primary"><p>쿼드 압축 후 개수 세기[Python]</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('#post-wrapper img'); const observer = lozad(imgs); observer.observe(); </script></div><!-- The Search results v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/tensorflow/">Tensorflow</a> <a class="post-tag" href="/tags/sklearn/">Sklearn</a> <a class="post-tag" href="/tags/round/">Round</a> <a class="post-tag" href="/tags/python-lv0/">Python Lv0</a> <a class="post-tag" href="/tags/pca/">PCA</a> <a class="post-tag" href="/tags/eda/">EDA</a> <a class="post-tag" href="/tags/distinct/">Distinct</a> <a class="post-tag" href="/tags/random-forest/">Random Forest</a> <a class="post-tag" href="/tags/beautifulsoup/">Beautifulsoup</a> <a class="post-tag" href="/tags/baekjoon/">Baekjoon</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <!-- The GA snippet v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <!-- Jekyll Simple Search loader v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://datainclude.me{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script>
