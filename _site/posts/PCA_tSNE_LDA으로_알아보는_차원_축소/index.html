<!DOCTYPE html><html lang="ko" mode="light" > <!-- The Head v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>PCA, t-SNE, LDA으로 알아보는 차원 축소 | Data Include Me</title><meta name="generator" content="Jekyll v3.9.3" /><meta property="og:title" content="PCA, t-SNE, LDA으로 알아보는 차원 축소" /><meta name="author" content="HyunMin Kim" /><meta property="og:locale" content="ko" /><meta name="description" content="차원 축소는 데이터의 차원을 줄여서 데이터를 간결하게 만드는 기술이다. 시각화, 데이터 축소, 노이즈 제거, 성능 향상 및 계산 시간 감소를 위해 사용한다. 대표적인 차원 축소 알고리즘으로는 PCA, t-SNE, LDA가 있으며, 각 알고리즘은 장점과 단점이 있다. 차원 축소는 머신 러닝 모델의 성능에 긍부적 적인 영향을 미치며, 특성 선택과 차원 축소는 정보 유지와 계산 효율성 측면에서 차이가 있다." /><meta property="og:description" content="차원 축소는 데이터의 차원을 줄여서 데이터를 간결하게 만드는 기술이다. 시각화, 데이터 축소, 노이즈 제거, 성능 향상 및 계산 시간 감소를 위해 사용한다. 대표적인 차원 축소 알고리즘으로는 PCA, t-SNE, LDA가 있으며, 각 알고리즘은 장점과 단점이 있다. 차원 축소는 머신 러닝 모델의 성능에 긍부적 적인 영향을 미치며, 특성 선택과 차원 축소는 정보 유지와 계산 효율성 측면에서 차이가 있다." /><link rel="canonical" href="https://datainclude.me/posts/PCA_tSNE_LDA%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EC%B0%A8%EC%9B%90_%EC%B6%95%EC%86%8C/" /><meta property="og:url" content="https://datainclude.me/posts/PCA_tSNE_LDA%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EC%B0%A8%EC%9B%90_%EC%B6%95%EC%86%8C/" /><meta property="og:site_name" content="Data Include Me" /><meta property="og:image" content="https://github.com/hmkim312/datas/assets/60168331/c0589161-1276-4546-9a03-6788ca0b1618" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2023-09-08T00:00:00+09:00" /><meta name="twitter:card" content="summary_large_image" /><meta property="twitter:image" content="https://github.com/hmkim312/datas/assets/60168331/c0589161-1276-4546-9a03-6788ca0b1618" /><meta property="twitter:title" content="PCA, t-SNE, LDA으로 알아보는 차원 축소" /><meta name="twitter:site" content="@" /><meta name="twitter:creator" content="@HyunMin Kim" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"HyunMin Kim"},"dateModified":"2023-09-08T00:00:00+09:00","datePublished":"2023-09-08T00:00:00+09:00","description":"차원 축소는 데이터의 차원을 줄여서 데이터를 간결하게 만드는 기술이다. 시각화, 데이터 축소, 노이즈 제거, 성능 향상 및 계산 시간 감소를 위해 사용한다. 대표적인 차원 축소 알고리즘으로는 PCA, t-SNE, LDA가 있으며, 각 알고리즘은 장점과 단점이 있다. 차원 축소는 머신 러닝 모델의 성능에 긍부적 적인 영향을 미치며, 특성 선택과 차원 축소는 정보 유지와 계산 효율성 측면에서 차이가 있다.","headline":"PCA, t-SNE, LDA으로 알아보는 차원 축소","image":"https://github.com/hmkim312/datas/assets/60168331/c0589161-1276-4546-9a03-6788ca0b1618","mainEntityOfPage":{"@type":"WebPage","@id":"https://datainclude.me/posts/PCA_tSNE_LDA%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EC%B0%A8%EC%9B%90_%EC%B6%95%EC%86%8C/"},"url":"https://datainclude.me/posts/PCA_tSNE_LDA%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EC%B0%A8%EC%9B%90_%EC%B6%95%EC%86%8C/"}</script> <!-- The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps Generated by: https://www.favicon-generator.org/ v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT license --><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="36x36" href="/assets/img/favicons/android-icon-36x36.png"><link rel="icon" type="image/png" sizes="48x48" href="/assets/img/favicons/android-icon-48x48.png"><link rel="icon" type="image/png" sizes="72x72" href="/assets/img/favicons/android-icon-72x72.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/android-icon-96x96.png"><link rel="icon" type="image/png" sizes="144x144" href="/assets/img/favicons/android-icon-144x144.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="70x70" href="/assets/img/favicons/ms-icon-70x70.png"><link rel="icon" type="image/png" sizes="144x144" href="/assets/img/favicons/ms-icon-144x144.png"><link rel="icon" type="image/png" sizes="150x150" href="/assets/img/favicons/ms-icon-150x150.png"><link rel="icon" type="image/png" sizes="310x310" href="/assets/img/favicons/ms-icon-310x310.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preload" href="https://www.googletagmanager.com/gtm.js?id=GTM-MW9VRMW9" as="script"> <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src= 'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f); })(window,document,'script','dataLayer','GTM-MW9VRMW9');</script><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="preload" as="style" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous" media="print" onload="this.media='all'"> <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"> </noscript> <!-- CSS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --><link rel="preload" as="style" href="/assets/css/post.css"><link rel="stylesheet" href="/assets/css/post.css"><link rel="preload" as="style" href="/assets/css/lib/bootstrap-toc.min.css"><link rel="stylesheet" href="/assets/css/lib/bootstrap-toc.min.css" /><link rel="preload" as="script" href="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" async></script> <!-- JS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --> <script src="/assets/js/post.min.js" async></script> <script src="/app.js" defer></script><body data-spy="scroll" data-target="#toc"> <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MW9VRMW9" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="sidebar" class="d-flex flex-column"> <!-- The Side Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="nav-wrapper"><div id="profile-wrapper" class="d-flex flex-column"><div id="avatar" class="d-flex justify-content-center"> <a href="/" alt="avatar"> <img src="/assets/img/sample/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="profile-text mt-3"><div class="site-title"> <a href="/">Data Include Me</a></div><div class="site-subtitle font-italic">Data Science Blog</div></div></div><ul class="nav flex-column"><li class="nav-item d-flex justify-content-center "> <a href="/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/categories/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/tags/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/archives/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/about/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></li></ul></div><div class="sidebar-bottom d-flex flex-wrap justify-content-around mt-4"> <a href="https://github.com/hmkim312" target="_blank"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/" target="_blank"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:window.open('mailto:' + ['sanarial312','gmail.com'].join('@'))" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" > <i class="fas fa-rss"></i> </a></div></div><!-- The Top Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>PCA, t-SNE, LDA으로 알아보는 차원 축소</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"> <!-- Refactor the HTML structure. --> <!-- Suroundding the markdown table with '<div class="table-wrapper">. and '</div>' --> <!-- Fixed kramdown code highlight rendering: https://github.com/penibelst/jekyll-compress-html/issues/101 https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901 --><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"> <script type="text/javascript"> var lazyloadads = false; function loadAds() { if (!lazyloadads) { var script = document.createElement("script"); script.type = "text/javascript"; script.async = true; script.src = "https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7594406644928408"; document.body.appendChild(script); lazyloadads = true; } } window.addEventListener("mousemove", loadAds, { once: true }); window.addEventListener('touchstart', loadAds, { once: true }); </script><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>PCA, t-SNE, LDA으로 알아보는 차원 축소</h1><div class="post-meta text-muted d-flex flex-column"><div> Posted <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Fri, Sep 8, 2023, 12:00 AM +0900" > Sep 8, 2023 <i class="unloaded">2023-09-08T00:00:00+09:00</i> </span> by <span class="author"> HyunMin Kim </span></div><a href="https://hits.seeyoufarm.com"> <img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https://datainclude.me/posts/PCA_tSNE_LDA%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EC%B0%A8%EC%9B%90_%EC%B6%95%EC%86%8C/%2F&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=views&edge_flat=false" alt="페이지 조회수 뱃지", width: 100%;, height: 100%;/> </a></div><div class="post-content"><p>차원 축소는 데이터의 차원을 줄여서 데이터를 간결하게 만드는 기술이다. 시각화, 데이터 축소, 노이즈 제거, 성능 향상 및 계산 시간 감소를 위해 사용한다. 대표적인 차원 축소 알고리즘으로는 PCA, t-SNE, LDA가 있으며, 각 알고리즘은 장점과 단점이 있다. 차원 축소는 머신 러닝 모델의 성능에 긍부적 적인 영향을 미치며, 특성 선택과 차원 축소는 정보 유지와 계산 효율성 측면에서 차이가 있다.</p><h2 id="1-서론">1. 서론</h2><hr /><h3 id="1-차원의-저주-curse-of-dimensionality">1) 차원의 저주 (Curse of Dimensionality)</h3><p>보통 우리가 생각하는 데이터는 여러 가지 정보로 이루어져 있다. 온라인 쇼핑 사이트에서 상품을 구매할 때를 예를 들자면 상품의 가격, 색상, 브랜드, 평점 및 후기 등 여러 정보가 있다. 이러한 정보를 <strong>차원</strong>이라고 한다. 하지만 데이터의 차원(정보)이 많아질수록 데이터가 복잡해져 분석하거나 활용하는 것이 어려워진다. 이런 문제를 <strong>차원의 저주</strong>라고 한다.</p><h3 id="2-차원-축소demension-reduce의-중요성-및-응용-분야">2) 차원 축소(Demension Reduce)의 중요성 및 응용 분야</h3><p>차원의 저주와 같은 문제를 해결하기 위해서는 데이터의 차원, 즉 정보의 양을 효과적으로 줄이는 방법이 필요하다. 중요한 것은 정보의 양을 줄이면서도 데이터의 핵심 특징을 잃지 않는 것이다. 이렇게 데이터를 간결하게 만드는 과정을 <strong>차원 축소</strong>라고 한다.</p><p>차원 축소는 다양한 분야에서 사용된다. 예를 들면, 복잡한 데이터를 간단한 그래프로 시각화하거나 대량의 데이터를 빠르게 처리해야 할 때 차원 축소 기법이 활용된다. 이 글에서는 차원 축소의 기본 개념과 주요한 세 가지 방법을 소개하려 한다.</p><h2 id="2-기본-개념">2. 기본 개념</h2><hr /><h3 id="1-차원이란-무엇인가">1) 차원이란 무엇인가?</h3><p>차원을 간단히 정의하면 어떤 정보나 특성을 나타내는 축이다. 예를 들어, 평면 위의 점을 나타낼 때 가로 축과 세로 축, 두 가지 정보가 필요하다. 이렇게 두 가지 정보를 나타내는 축을 두 개의 차원이라고 한다. 공간에서는 높이라는 세 번째 축이 추가되어 총 세 개의 차원으로 된다. 또한, 시간의 개념이 추가되면 4차원이되며 더 많은 차원이 추가되어 4차원 이상이되면 그때부터는 사람의 머리로는 상상하기 어려워 진다.</p><h3 id="2-데이터의-차원과-특성">2) 데이터의 차원과 특성</h3><p>데이터에서의 차원도 비슷한 개념이다. 데이터가 여러 가지 특성을 가지고 있을 때, 각 특성은 하나의 차원으로 생각할 수 있다. 예를 들어, 자동차와 관련된 데이터가 있다고 하면 자동차의 색깔, 크기, 브랜드, 연비 등 다양한 특성이 있을 것이다. 여기서 이야기하는 특성이 데이터의 차원이라고 할 수 있다. 따라서 데이터의 차원은 그 데이터가 얼마나 많은 <strong>특성</strong>을 가지고 있는지를 나타낸다.</p><h2 id="3-주성분-분석-pca-principal-component-analysis">3. 주성분 분석 (PCA, Principal Component Analysis)</h2><hr /><h3 id="1-기본-원리-및-수학적-배경">1) 기본 원리 및 수학적 배경</h3><p><strong>주성분 분석</strong>은 데이터의 주요 특성을 찾아내는 방법이다. 데이터에 내재된 패턴이나 구조를 찾아서 데이터를 더 간단한 형태로 표현하려는 것이 목표다.</p><p>수학적으로 보면, PCA는 데이터의 분산이 최대가 되는 방향을 찾는다. 이 방향은 <strong>주성분</strong>이라고 불리며, 데이터의 핵심 정보를 가장 잘 나타낸다. 처음 찾은 주성분과 직교하는 방향 중에서 다음으로 분산이 큰 방향을 두 번째 주성분으로, 그 다음 방향을 세 번째 주성분으로 정하며 이런식으로 설정한 수만큼 주성분을 찾게 된다.</p><h3 id="2-장점-및-한계">2) 장점 및 한계</h3><p>PCA의 큰 장점 중 하나는 복잡한 데이터를 몇 개의 주성분만으로 간단하게 표현할 수 있다는 점이다. 이로 인해 데이터의 시각화나 분석이 훨씬 간단해 진다. 그러나 PCA에도 한계가 있다. PCA는 선형 관계만을 판단하므로, 데이터가 비선형 구조를 가질 때는 그 특성을 제대로 파악하기 어렵다. 또한, 모든 주성분이 데이터의 중요한 특성을 반드시 반영한다는 보장이 없다. 따라서 PCA 결과를 해석할 때는 주의가 필요하다.</p><h3 id="3-실습">3) 실습</h3><blockquote><p>iris 데이터셋을 사용하여 실습한다. 이 데이터셋에는 3개의 꽃 종류(setosa, versicolor, virgnica)에 대한 4개의 특성(꽃받침 길이, 꽃받침 너비, 꽃잎 길이, 꽃잎 너비)이 포함되어 있다.</p></blockquote><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">TSNE</span>
<span class="kn">from</span> <span class="nn">sklearn.discriminant_analysis</span> <span class="kn">import</span> <span class="n">LinearDiscriminantAnalysis</span> <span class="k">as</span> <span class="n">LDA</span>

<span class="c1"># 데이터셋 로드
</span><span class="n">iris</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">data</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">target</span>
<span class="n">target_names</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">target_names</span>

<span class="c1"># 시각화 설정
</span><span class="n">sns</span><span class="p">.</span><span class="n">set_style</span><span class="p">(</span><span class="s">"whitegrid"</span><span class="p">)</span>

<span class="c1"># 주성분을 2개로 한 PCA 객체 생성
</span><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="c1"># 데이터를 PCA로 변환
</span><span class="n">X_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s">'navy'</span><span class="p">,</span> <span class="s">'turquoise'</span><span class="p">,</span> <span class="s">'darkorange'</span><span class="p">]</span>
<span class="k">for</span> <span class="n">color</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">target_name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">colors</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">target_names</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_pca</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_pca</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">8</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">label</span><span class="o">=</span><span class="n">target_name</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'best'</span><span class="p">,</span> <span class="n">shadow</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">scatterpoints</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'PCA'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://github.com/hmkim312/datas/assets/60168331/c0589161-1276-4546-9a03-6788ca0b1618" alt="PCA" style="max-width: 100%; height: auto;" /></p><p>4개의 특성을 2개로 PCA 한 결과이다. iris 3개의 종 중 setosa와 나머지 2개는 잘 구분하겠으나, versicolor와 virginica는 구분선이 모호한것으로 보인다.</p><h2 id="4-t-sne-t-distributed-stochastic-neighbor-embedding">4. t-SNE (t-Distributed Stochastic Neighbor Embedding)</h2><hr /><h3 id="1-기본-원리-및-수학적-배경-1">1) 기본 원리 및 수학적 배경</h3><p>t-SNE는 고차원 데이터를 저차원(주로 2차원이나 3차원)으로 시각화하기 위한 기법 중 하나다. 원리는 간단하게 말하자면, 고차원에서의 데이터 포인트 간의 유사성과 저차원에서의 유사성이 최대한 비슷하도록 데이터를 변환한다.</p><p>고차원에서의 유사성은 가우시안 분포를 사용하여 측정하고, 저차원에서는 t-분포를 사용한다. 이렇게 두 분포를 사용하는 이유는 저차원에서 데이터 포인트들이 서로 너무 뭉치지 않게 하기 위해서이다.</p><h3 id="2-장점-및-한계-1">2) 장점 및 한계</h3><p>t-SNE의 가장 큰 장점은 복잡한 데이터 구조 (e.g 비선형)를 잘 표현한다는 것이다. 그로 인해 많은 데이터 시각화에서 t-SNE를 활용하여 데이터의 구조를 이해하기 쉽게 만든다.</p><p>그렇지만 t-SNE에도 몇 가지 한계가 있다. 첫째, 학습률이나 초기 설정 값에 따라 결과가 변한다. 이것은 여러 번 시도하여 최적의 결과를 얻어야 함을 의미한다. 둘째, 저차원으로 변환된 결과가 원래의 고차원 데이터와 얼마나 유사한지를 정량적으로 평가하기 어렵다. 마지막으로, 대규모 데이터에 t-SNE를 적용하려면 계산 시간이 많이 필요하다.</p><h3 id="3-실습-1">3) 실습</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="c1"># 주성분을 2개로 한 t-SNE 객체 생성
</span><span class="n">tsne</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># 데이터를 t-SNE 변환
</span><span class="n">X_tsne</span> <span class="o">=</span> <span class="n">tsne</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">color</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">target_name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">colors</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">target_names</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_tsne</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_tsne</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">8</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">label</span><span class="o">=</span><span class="n">target_name</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'best'</span><span class="p">,</span> <span class="n">shadow</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">scatterpoints</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'t-SNE'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://github.com/hmkim312/datas/assets/60168331/52cca270-b58d-4c42-b24d-b92103afc63a" alt="t-SNE" style="max-width: 100%; height: auto;" /></p><p>4개의 특성을 2개로 t-SNE 한 결과이다. 결과는 PCA와 마찬가지로 iris 3개의 종 중 setosa와 나머지 2개는 잘 구분하겠으나, versicolor와 virginica는 구분선이 모호한것으로 보인다.</p><h2 id="5-선형-판별-분석-lda-linear-discriminant-analysis">5. 선형 판별 분석 (LDA, Linear Discriminant Analysis)</h2><hr /><h3 id="1-기본-원리-및-수학적-배경-2">1) 기본 원리 및 수학적 배경</h3><p>선형 판별 분석 (LDA)은 주로 분류 문제에서 사용되는 방법으로, 데이터의 클래스 간 분산을 최대화하고 클래스 내 분산을 최소화하여 데이터를 선형적으로 분리하는 방법이다.</p><p>수학적으로, LDA는 클래스 간의 분산과 클래스 내의 분산의 비율을 최대화하는 방향을 찾는다. 이러한 방향은 데이터가 속한 클래스를 가장 잘 구분할 수 있는 방향을 찾는것이다. 따라서 방향을 찾는것이 LDA의 주요 목적이다. LDA는 주로 두 개의 클래스를 가진 문제에서 사용하지만 3개 이상인 다중 클래스 문제에도 사용 할 수 있다.</p><h3 id="2-장점-및-한계-2">2) 장점 및 한계</h3><p>LDA의 주된 장점은 클래스 간 분리를 최적화하여 분류 문제에서 뛰어난 성능을 보인다는 점이다. 또한, 차원 축소 기법으로 사용될 때, 클래스 정보를 유지하면서 데이터를 저차원으로 표현하는 능력이 있다.</p><p>그러나 LDA의 한계도 존재한다. 데이터의 클래스 분포가 균일하지 않다면 LDA는 제대로 동잗하지 않을 수 있다. 또한, LDA는 선형적인 클래스의 구분만을 고려하므로, 데이터의 클래스 경계가 비선형일 경우 클래스간 구분선을 제대로 파악하기 어려울 수 있다. 마지막으로, LDA는 모든 클래스에 공통적인 공분산을 가정하는데, 이 가정이 항상 맞는것은 아니다. 따라서 LDA를 사용할 때 이러한 한계점들을 고려하고 사용하는 것이 중요하다.</p><h3 id="3-실습-2">3) 실습</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="n">lda</span> <span class="o">=</span> <span class="n">LDA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="c1"># 데이터를 LDA로 변환. LDA는 지도 학습이므로 타겟 레이블도 함께 제공.
</span><span class="n">X_lda</span> <span class="o">=</span> <span class="n">lda</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="k">for</span> <span class="n">color</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">target_name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">colors</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">target_names</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_lda</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_lda</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">8</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span>
                <span class="n">label</span><span class="o">=</span><span class="n">target_name</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'best'</span><span class="p">,</span> <span class="n">shadow</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">scatterpoints</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'LDA'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://github.com/hmkim312/datas/assets/60168331/3b1a6f14-df9c-4809-8a1a-35f6915437f5" alt="LDA" style="max-width: 100%; height: auto;" /></p><p>4개의 특성을 2개로 LDA 한 결과이다. 결과는 PCA, t-SNE 마찬가지로 iris 3개의 종 중 setosa와 나머지 2개는 잘 구분하겠으나, versicolor와 virginica는 구분선이 선형이 아니라 모호한것으로 보인다.</p><h2 id="6-차원-축소의-응용-분야">6. 차원 축소의 응용 분야</h2><hr /><h3 id="1-시각화">1) 시각화</h3><p>차원 축소는 고차원 데이터를 2차원이나나 3차원으로 변환하여 시각적으로 표현할 수 있게 해준다. 이를 통해 데이터의 구조나 패턴을 직관적으로 이해하게 되며, 숨겨진 그룹이나 이상치 같은 특징을 쉽게 파악할 수 있다.</p><h3 id="2-데이터-압축">2) 데이터 압축</h3><p>차원 축소는 데이터의 크기를 줄여준다. 이것은 메모리나 하드디스크, 데이터 베이스에 저장 공간을 절약하는데 도움이 된다. 더욱이, 압축된 데이터는 원래 데이터의 중요한 특성을 유지하면서 크기가 줄어들기 때문에, 계산 비용이나 저장 비용을 절약할 수 있다.</p><h3 id="3-노이즈-제거">3) 노이즈 제거</h3><p>데이터에는 종종 노이즈나 불필요한 정보가 포함되어 있다. 차원 축소를 사용하면 이러한 노이즈나 불필요한 정보를 제거하면서 데이터의 주요 특성만을 추출할 수 있다. 이로 인해 데이터 분석 결과의 정확성이 향상될 수 있다.</p><h2 id="7-차원-축소와-머신-러닝">7. 차원 축소와 머신 러닝</h2><hr /><h3 id="1-특성-선택feature-selection과-차원-축소">1) 특성 선택(Feature Selection)과 차원 축소</h3><p>데이터에서 중요한 정보를 추출하는 방법에는 크게 <strong>특성 선택</strong>과 <strong>차원 축소</strong> 두 가지 방식이 있다 특성 선택은 데이터의 원래 특성 중에서 가장 정보가 많은 특성만을 선택하는 방법이다. 예를 들면, 100개의 특성 중에서 중요한 특성 10개만을 선택하여 사용할 수 있다. 이 방식은 해석이 비교적 쉽고 원래 데이터의 의미를 그대로 유지한다는 장점이 있다. 반면 차원 축소는 기존 특성을 새로운 특성으로 변환하는 것이다. 예를 들어, PCA를 사용하면 100개의 특성이 10개의 주성분으로 변환된다. 변환된 특성은 원래의 특성과는 다른 의미를 가질 수 있지만, 데이터가 가지고 있는 중요한 정보는 최대한 유지하려고 한다.</p><h3 id="2-머신-러닝에서의-차원-축소의-영향">2) 머신 러닝에서의 차원 축소의 영향</h3><p>차원 축소는 머신 러닝 모델의 성능에 크게 영향을 미치는 요소 중 하나다. 차원 축소의 영향으로는 계산량의 감소와 과적합의 방지가 있다. 특성의 수를 줄임으로써, 모델은 학습을 더 빠르게 수행할 수 있게 된다. 또한, 데이터에 많은 특성이 있는 경우 머신 러닝 모델은 학습 데이터에 과하게 맞춰지는 <strong>과적합</strong>의 위험이 증가하는데, 차원 축소를 통해 불필요한 특성들을 제거함으로써 과적합을 방지할 수 있다.</p><p>그러나 차원 축소에도 중요한 정보의 손실과 같은 단점이 있다. 차원 축소의 방법을 잘못 선택하면 기존 데이터에서 중요한 정보가 사라지게 되는데, 이 결과로 머신 러닝 모델의 성능이 저하될 가능성이 있다. 또한, 차원이 축소된 데이터는 기존의 데이터와는 다른 의미를 가지게 될 수 있기 때문에, 그 결과를 해석하는 것이 더 복잡하고 어려워질 수 있다.</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/data-science/'>Data Science</a>, <a href='/categories/machine-learning/'>Machine Learning</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/pca/" class="post-tag no-text-decoration" >PCA</a> <a href="/tags/t-sne/" class="post-tag no-text-decoration" >t-SNE</a> <a href="/tags/lda/" class="post-tag no-text-decoration" >LDA</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><!-- Post sharing snippet v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=PCA, t-SNE, LDA으로 알아보는 차원 축소 - Data Include Me&url=https://datainclude.me/posts/PCA_tSNE_LDA%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EC%B0%A8%EC%9B%90_%EC%B6%95%EC%86%8C/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=PCA, t-SNE, LDA으로 알아보는 차원 축소 - Data Include Me&u=https://datainclude.me/posts/PCA_tSNE_LDA%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EC%B0%A8%EC%9B%90_%EC%B6%95%EC%86%8C/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=PCA, t-SNE, LDA으로 알아보는 차원 축소 - Data Include Me&url=https://datainclude.me/posts/PCA_tSNE_LDA%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EC%B0%A8%EC%9B%90_%EC%B6%95%EC%86%8C/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><!-- The Panel on right side (Desktop views) v2.3 © 2024 Your Name MIT License --><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><h3 data-toc-skip>Recent Update</h3><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li class="recent-item"> <a href="/posts/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C_%EC%BB%B4%ED%93%A8%ED%8C%85_%EA%B0%80%EC%83%81%ED%99%94/">클라우드 컴퓨팅 - 가상화</a> <span class="text-muted small">2024-10-28</span></li><li class="recent-item"> <a href="/posts/gemini_api_%EC%82%AC%EC%9A%A9%ED%95%B4%EB%B3%B4%EA%B8%B0/">Gemini API 사용해보기</a> <span class="text-muted small">2024-03-12</span></li><li class="recent-item"> <a href="/posts/Ollama%EC%99%80_Python_%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC_LLaMa2%EB%A5%BC_%EB%A1%9C%EC%BB%AC%EC%97%90%EC%84%9C_%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/">Ollama와 Python 라이브러리를 이용하여 LLaMa2를 로컬에서 사용하기</a> <span class="text-muted small">2024-02-13</span></li><li class="recent-item"> <a href="/posts/Mistral_7B_Fine_Tuning/">Mistral 7B 파인튜닝(Fine Tuning)하기</a> <span class="text-muted small">2023-10-25</span></li><li class="recent-item"> <a href="/posts/Penn_Fudan%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EA%B0%9D%EC%B2%B4_%ED%83%90%EC%A7%80_%EB%B6%84%ED%95%A0/">Penn-Fudan으로 알아보는 객체 탐지(Object Detection), 분할(Segmentation) with FasterRCNN</a> <span class="text-muted small">2023-10-23</span></li></ul></div><div id="access-tags"><h3 data-toc-skip>Trending Tags</h3><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/tensorflow/">Tensorflow</a> <a class="post-tag" href="/tags/sklearn/">Sklearn</a> <a class="post-tag" href="/tags/round/">Round</a> <a class="post-tag" href="/tags/python-lv0/">Python Lv0</a> <a class="post-tag" href="/tags/pca/">PCA</a> <a class="post-tag" href="/tags/eda/">EDA</a> <a class="post-tag" href="/tags/distinct/">Distinct</a> <a class="post-tag" href="/tags/random-forest/">Random Forest</a> <a class="post-tag" href="/tags/beautifulsoup/">Beautifulsoup</a> <a class="post-tag" href="/tags/baekjoon/">Baekjoon</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><h3 data-toc-skip class="pl-3 pt-2 mb-2">Contents</h3><nav id="toc" data-toggle="toc"></nav></div></div><style> .recent-item { margin-bottom: 0.5rem; } .recent-item a { color: var(--link-color); } .recent-item .small { font-size: 0.75rem; margin-left: 0.5rem; }</style></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"> <!-- Recommend the other 3 posts according to the tags and categories of the current post, if the number is not enough, use the other latest posts to supplement. v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/%EC%95%84%EC%9D%B4%EB%A6%AC%EC%8A%A4_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%99%80_%EC%99%80%EC%9D%B8%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_PCA/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Oct 23, 2020 <i class="unloaded">2020-10-23T12:10:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>아이리스 데이터와 와인데이터로 해보는 PCA</h3><div class="text-muted small"><p> 1. PCA 1.1 PCA란? 데이터 집합 내에 존재하는 각 데이터의 차이를 가장 잘 나타내주는 요소를 찾아 내는 방법 통계 데이터 분석(주성분 분석), 데이터 압축(차원 감소), 노이즈 제거 등 다양한 분야에서 사용 1.2 간단한 PCA의 개념 주성분 분석 : 차원축소와 변수추출 기법으로 널리 쓰이고 있음 데이터의 분산...</p></div></div></a></div><div class="card"> <a href="/posts/Eigenface%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_PCA/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Oct 23, 2020 <i class="unloaded">2020-10-23T13:10:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Eigenface로 해보는 PCA</h3><div class="text-muted small"><p> 1. Olivetti 데이터 1.1 데이터 소개 미국의 AT&amp;T와 캠프리지 대학 전산 연구실에서 공동으로 제작한 얼굴 사진 데이터 얼굴 인식 등 다양한 분야에서 활용되고 있음 일부 데이터가 sklearn에 dataset으로 내장되어 있음 2. 실습 2.1 Data load from sklearn.datasets im...</p></div></div></a></div><div class="card"> <a href="/posts/HAR%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_PCA/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Oct 23, 2020 <i class="unloaded">2020-10-23T15:10:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>HAR로 해보는 PCA</h3><div class="text-muted small"><p> 1. HAR data 1.1 HAR data load import pandas as pd import matplotlib.pyplot as plt url = 'https://raw.githubusercontent.com/hmkim312/datas/main/HAR/features.txt' feature_name_df = pd.read_csv(ur...</p></div></div></a></div></div></div><!-- Navigation buttons at the bottom of the post. v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --><div class="post-navigation d-flex justify-content-between"> <a href="/posts/LangChain_%EA%B8%B0%EC%B4%88_%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC_%ED%8C%8C%ED%8A%B81/" class="btn btn-outline-primary"><p>LangChain 기초 튜토리얼 파트1</p></a> <a href="/posts/LangChain_%EC%82%AC%EC%9A%A9_%EC%82%AC%EB%A1%80_%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC_%ED%8C%8C%ED%8A%B82/" class="btn btn-outline-primary"><p>LangChain 사용 사례 튜토리얼 파트2</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('#post-wrapper img'); const observer = lozad(imgs); observer.observe(); </script></div><!-- The Search results v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/tensorflow/">Tensorflow</a> <a class="post-tag" href="/tags/sklearn/">Sklearn</a> <a class="post-tag" href="/tags/round/">Round</a> <a class="post-tag" href="/tags/python-lv0/">Python Lv0</a> <a class="post-tag" href="/tags/pca/">PCA</a> <a class="post-tag" href="/tags/eda/">EDA</a> <a class="post-tag" href="/tags/distinct/">Distinct</a> <a class="post-tag" href="/tags/random-forest/">Random Forest</a> <a class="post-tag" href="/tags/beautifulsoup/">Beautifulsoup</a> <a class="post-tag" href="/tags/baekjoon/">Baekjoon</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <!-- The GA snippet v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <!-- Jekyll Simple Search loader v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://datainclude.me{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script>
