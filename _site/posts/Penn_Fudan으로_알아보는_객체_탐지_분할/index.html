<!DOCTYPE html><html lang="ko" mode="light" > <!-- The Head v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Penn-Fudan으로 알아보는 객체 탐지(Object Detection), 분할(Segmentation) with FasterRCNN | Data Include Me</title><meta name="generator" content="Jekyll v3.9.3" /><meta property="og:title" content="Penn-Fudan으로 알아보는 객체 탐지(Object Detection), 분할(Segmentation) with FasterRCNN" /><meta name="author" content="HyunMin Kim" /><meta property="og:locale" content="ko" /><meta name="description" content="해당 게시물은 Torch Vision의 객체 감지 미세조정 튜토리얼을 참고하여 작성되었습니다. Pytorch에서 제공하는 Coco 데이터로 사전 훈련된 FasterRCNN을 활용하여 보행자 감지(detection) 및 분할(segmentation)을 위해 Penn-Fudan 데이터로 파라미터 튜닝을 진행합니다. Penn-Fudan 데이터는 345개의 보행자 정보가 포함된 총 170개의 이미지가 포함되어 있습니다." /><meta property="og:description" content="해당 게시물은 Torch Vision의 객체 감지 미세조정 튜토리얼을 참고하여 작성되었습니다. Pytorch에서 제공하는 Coco 데이터로 사전 훈련된 FasterRCNN을 활용하여 보행자 감지(detection) 및 분할(segmentation)을 위해 Penn-Fudan 데이터로 파라미터 튜닝을 진행합니다. Penn-Fudan 데이터는 345개의 보행자 정보가 포함된 총 170개의 이미지가 포함되어 있습니다." /><link rel="canonical" href="https://datainclude.me/posts/Penn_Fudan%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EA%B0%9D%EC%B2%B4_%ED%83%90%EC%A7%80_%EB%B6%84%ED%95%A0/" /><meta property="og:url" content="https://datainclude.me/posts/Penn_Fudan%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EA%B0%9D%EC%B2%B4_%ED%83%90%EC%A7%80_%EB%B6%84%ED%95%A0/" /><meta property="og:site_name" content="Data Include Me" /><meta property="og:image" content="https://datainclude.me/assets/img/post/2023-10-23/02.png" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2023-10-23T00:00:00+09:00" /><meta name="twitter:card" content="summary_large_image" /><meta property="twitter:image" content="https://datainclude.me/assets/img/post/2023-10-23/02.png" /><meta property="twitter:title" content="Penn-Fudan으로 알아보는 객체 탐지(Object Detection), 분할(Segmentation) with FasterRCNN" /><meta name="twitter:site" content="@" /><meta name="twitter:creator" content="@HyunMin Kim" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"HyunMin Kim"},"dateModified":"2023-10-23T00:00:00+09:00","datePublished":"2023-10-23T00:00:00+09:00","description":"해당 게시물은 Torch Vision의 객체 감지 미세조정 튜토리얼을 참고하여 작성되었습니다. Pytorch에서 제공하는 Coco 데이터로 사전 훈련된 FasterRCNN을 활용하여 보행자 감지(detection) 및 분할(segmentation)을 위해 Penn-Fudan 데이터로 파라미터 튜닝을 진행합니다. Penn-Fudan 데이터는 345개의 보행자 정보가 포함된 총 170개의 이미지가 포함되어 있습니다.","headline":"Penn-Fudan으로 알아보는 객체 탐지(Object Detection), 분할(Segmentation) with FasterRCNN","image":"https://datainclude.me/assets/img/post/2023-10-23/02.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://datainclude.me/posts/Penn_Fudan%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EA%B0%9D%EC%B2%B4_%ED%83%90%EC%A7%80_%EB%B6%84%ED%95%A0/"},"url":"https://datainclude.me/posts/Penn_Fudan%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EA%B0%9D%EC%B2%B4_%ED%83%90%EC%A7%80_%EB%B6%84%ED%95%A0/"}</script> <!-- The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps Generated by: https://www.favicon-generator.org/ v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT license --><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="36x36" href="/assets/img/favicons/android-icon-36x36.png"><link rel="icon" type="image/png" sizes="48x48" href="/assets/img/favicons/android-icon-48x48.png"><link rel="icon" type="image/png" sizes="72x72" href="/assets/img/favicons/android-icon-72x72.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/android-icon-96x96.png"><link rel="icon" type="image/png" sizes="144x144" href="/assets/img/favicons/android-icon-144x144.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="70x70" href="/assets/img/favicons/ms-icon-70x70.png"><link rel="icon" type="image/png" sizes="144x144" href="/assets/img/favicons/ms-icon-144x144.png"><link rel="icon" type="image/png" sizes="150x150" href="/assets/img/favicons/ms-icon-150x150.png"><link rel="icon" type="image/png" sizes="310x310" href="/assets/img/favicons/ms-icon-310x310.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preload" href="https://www.googletagmanager.com/gtm.js?id=GTM-MW9VRMW9" as="script"> <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src= 'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f); })(window,document,'script','dataLayer','GTM-MW9VRMW9');</script><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="preload" as="style" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous" media="print" onload="this.media='all'"> <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"> </noscript> <!-- CSS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --><link rel="preload" as="style" href="/assets/css/post.css"><link rel="stylesheet" href="/assets/css/post.css"><link rel="preload" as="style" href="/assets/css/lib/bootstrap-toc.min.css"><link rel="stylesheet" href="/assets/css/lib/bootstrap-toc.min.css" /><link rel="preload" as="script" href="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" async></script> <!-- JS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --> <script src="/assets/js/post.min.js" async></script> <script src="/app.js" defer></script><body data-spy="scroll" data-target="#toc"> <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MW9VRMW9" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="sidebar" class="d-flex flex-column"> <!-- The Side Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="nav-wrapper"><div id="profile-wrapper" class="d-flex flex-column"><div id="avatar" class="d-flex justify-content-center"> <a href="/" alt="avatar"> <img src="/assets/img/sample/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="profile-text mt-3"><div class="site-title"> <a href="/">Data Include Me</a></div><div class="site-subtitle font-italic">Data Science Blog</div></div></div><ul class="nav flex-column"><li class="nav-item d-flex justify-content-center "> <a href="/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/categories/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/tags/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/archives/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/about/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></li></ul></div><div class="sidebar-bottom d-flex flex-wrap justify-content-around mt-4"> <a href="https://github.com/hmkim312" target="_blank"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/" target="_blank"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:window.open('mailto:' + ['sanarial312','gmail.com'].join('@'))" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" > <i class="fas fa-rss"></i> </a></div></div><!-- The Top Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Penn-Fudan으로 알아보는 객체 탐지(Object Detection), 분할(Segmentation) with FasterRCNN</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"> <!-- Refactor the HTML structure. --> <!-- Suroundding the markdown table with '<div class="table-wrapper">. and '</div>' --> <!-- Fixed kramdown code highlight rendering: https://github.com/penibelst/jekyll-compress-html/issues/101 https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901 --><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"> <script type="text/javascript"> var lazyloadads = false; function loadAds() { if (!lazyloadads) { var script = document.createElement("script"); script.type = "text/javascript"; script.async = true; script.src = "https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7594406644928408"; document.body.appendChild(script); lazyloadads = true; } } window.addEventListener("mousemove", loadAds, { once: true }); window.addEventListener('touchstart', loadAds, { once: true }); </script><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Penn-Fudan으로 알아보는 객체 탐지(Object Detection), 분할(Segmentation) with FasterRCNN</h1><div class="post-meta text-muted d-flex flex-column"><div> Posted <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Mon, Oct 23, 2023, 12:00 AM +0900" > Oct 23, 2023 <i class="unloaded">2023-10-23T00:00:00+09:00</i> </span> by <span class="author"> HyunMin Kim </span></div><a href="https://hits.seeyoufarm.com"> <img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https://datainclude.me/posts/Penn_Fudan%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EA%B0%9D%EC%B2%B4_%ED%83%90%EC%A7%80_%EB%B6%84%ED%95%A0/%2F&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=views&edge_flat=false" alt="페이지 조회수 뱃지", width: 100%;, height: 100%;/> </a></div><div class="post-content"><p>해당 게시물은 <a href="https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html">Torch Vision의 객체 감지 미세조정 튜토리얼</a>을 참고하여 작성되었습니다. Pytorch에서 제공하는 Coco 데이터로 사전 훈련된 FasterRCNN을 활용하여 보행자 감지(detection) 및 분할(segmentation)을 위해 Penn-Fudan 데이터로 파라미터 튜닝을 진행합니다. Penn-Fudan 데이터는 345개의 보행자 정보가 포함된 총 170개의 이미지가 포함되어 있습니다.</p><h2 id="1-download">1. Download</h2><p>최초 1회 아래의 주석을 풀어 cutom function과 Penn-Fudan 데이터를 다운로드합니다.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="c1"># !wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/engine.py
# !wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/utils.py
# !wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_utils.py
# !wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/coco_eval.py
# !wget https://raw.githubusercontent.com/pytorch/vision/main/references/detection/transforms.py
</span></pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="c1"># !wget https://www.cis.upenn.edu/~jshi/ped_html/PennFudanPed.zip
# !unzip PennFudanPed.zip
</span></pre></table></code></div></div><h2 id="2-패키지-import">2. 패키지 import</h2><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre><td class="rouge-code"><pre><span class="c1"># Deafult
</span><span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># Image
</span><span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.image</span> <span class="k">as</span> <span class="n">img</span>
<span class="kn">import</span> <span class="nn">matplotlib.patches</span> <span class="k">as</span> <span class="n">patches</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">from</span> <span class="nn">torchvision.utils</span> <span class="kn">import</span> <span class="n">draw_bounding_boxes</span><span class="p">,</span> <span class="n">draw_segmentation_masks</span>

<span class="c1"># Model
</span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">torchvision.io</span> <span class="kn">import</span> <span class="n">read_image</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">tv_tensors</span>
<span class="kn">from</span> <span class="nn">torchvision.ops.boxes</span> <span class="kn">import</span> <span class="n">masks_to_boxes</span>
<span class="kn">from</span> <span class="nn">torchvision.transforms.v2</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">torchvision.transforms</span> <span class="kn">import</span> <span class="n">v2</span> <span class="k">as</span> <span class="n">T</span>
<span class="kn">from</span> <span class="nn">torchvision.models.detection.faster_rcnn</span> <span class="kn">import</span> <span class="n">FastRCNNPredictor</span>
<span class="kn">from</span> <span class="nn">torchvision.models.detection.mask_rcnn</span> <span class="kn">import</span> <span class="n">MaskRCNNPredictor</span>
<span class="kn">from</span> <span class="nn">torchvision.models.detection</span> <span class="kn">import</span> <span class="n">FasterRCNN</span>
<span class="kn">from</span> <span class="nn">torchvision.models.detection.rpn</span> <span class="kn">import</span> <span class="n">AnchorGenerator</span>

<span class="c1"># Custom Function
</span><span class="kn">import</span> <span class="nn">utils</span>
<span class="kn">from</span> <span class="nn">engine</span> <span class="kn">import</span> <span class="n">train_one_epoch</span><span class="p">,</span> <span class="n">evaluate</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="c1"># 버전 확인
# Torchvision의 버전이 0.15이하이면 앞으로 진핼할 아래의 코드는 실행이 되지 않음
</span><span class="k">print</span><span class="p">(</span><span class="s">'Torch Version : '</span><span class="p">,</span><span class="n">torch</span><span class="p">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Torchvision Version : '</span><span class="p">,</span><span class="n">torchvision</span><span class="p">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Matplotlib Version : '</span><span class="p">,</span><span class="n">matplotlib</span><span class="p">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Cv2 Version : '</span><span class="p">,</span><span class="n">cv2</span><span class="p">.</span><span class="n">__version__</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>Torch Version :  2.1.0+cu118
Torchvision Version :  0.16.0+cu118
Matplotlib Version :  3.4.3
Cv2 Version :  4.8.1
</pre></table></code></div></div><h2 id="3-penn-fudan-dataset-확인">3. Penn-Fudan Dataset 확인</h2><p>PennFudan Dataset은 345개의 보행자 정보와 170개의 이미지 파일로 구성되어있으며 Annotation파일에는 세그먼트, 바운딩 박스, 이미지, 마스크 파일 이름의 정보가 포함되어 있습니다.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre><td class="rouge-code"><pre><span class="n">폴더</span> <span class="n">구조</span>
<span class="n">PennFudanPed</span><span class="o">/</span>
    <span class="n">PedMasks</span><span class="o">/</span>
        <span class="n">FudanPed00001_mask</span><span class="p">.</span><span class="n">png</span>
        <span class="n">FudanPed00002_mask</span><span class="p">.</span><span class="n">png</span>
        <span class="n">FudanPed00003_mask</span><span class="p">.</span><span class="n">png</span>
        <span class="n">FudanPed00004_mask</span><span class="p">.</span><span class="n">png</span>
        <span class="p">...</span>
    <span class="n">PNGImages</span><span class="o">/</span>
        <span class="n">FudanPed00001</span><span class="p">.</span><span class="n">png</span>
        <span class="n">FudanPed00002</span><span class="p">.</span><span class="n">png</span>
        <span class="n">FudanPed00003</span><span class="p">.</span><span class="n">png</span>
        <span class="n">FudanPed00004</span><span class="p">.</span><span class="n">png</span>
        <span class="p">...</span>
    <span class="n">Annotation</span><span class="o">/</span>
        <span class="n">FudanPed00001</span><span class="p">.</span><span class="n">txt</span>
        <span class="n">FudanPed00002</span><span class="p">.</span><span class="n">txt</span>
        <span class="n">FudanPed00003</span><span class="p">.</span><span class="n">txt</span>
        <span class="n">FudanPed00004</span><span class="p">.</span><span class="n">txt</span>
        <span class="p">...</span>
        
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
</pre><td class="rouge-code"><pre><span class="c1"># 샘플 데이터 확인
</span><span class="k">def</span> <span class="nf">draw_images</span><span class="p">(</span><span class="n">annotation_file_path</span><span class="p">):</span>
    <span class="c1"># 어노테이션 파일 읽기
</span>    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">annotation_file_path</span><span class="p">,</span> <span class="s">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="nb">file</span><span class="p">:</span>
        <span class="n">lines</span> <span class="o">=</span> <span class="nb">file</span><span class="p">.</span><span class="n">readlines</span><span class="p">()</span>

    <span class="c1"># 바운딩 박스 정보와 마스크 이미지 경로 추출
</span>    <span class="n">bounding_boxes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">mask_image_path</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">line</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">'Bounding box for object'</span><span class="p">):</span>
            <span class="n">coordinates</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">': '</span><span class="p">)[</span><span class="mi">1</span><span class="p">].</span><span class="n">strip</span><span class="p">().</span><span class="n">replace</span><span class="p">(</span><span class="s">'('</span><span class="p">,</span> <span class="s">''</span><span class="p">).</span><span class="n">replace</span><span class="p">(</span><span class="s">')'</span><span class="p">,</span> <span class="s">''</span><span class="p">).</span><span class="n">split</span><span class="p">(</span><span class="s">' - '</span><span class="p">)</span>
            <span class="n">xmin</span><span class="p">,</span> <span class="n">ymin</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">coordinates</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">split</span><span class="p">(</span><span class="s">', '</span><span class="p">))</span>
            <span class="n">xmax</span><span class="p">,</span> <span class="n">ymax</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">coordinates</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">split</span><span class="p">(</span><span class="s">', '</span><span class="p">))</span>
            <span class="n">bounding_boxes</span><span class="p">.</span><span class="n">append</span><span class="p">(((</span><span class="n">xmin</span><span class="p">,</span> <span class="n">ymin</span><span class="p">),</span> <span class="p">(</span><span class="n">xmax</span><span class="p">,</span> <span class="n">ymax</span><span class="p">)))</span>
        <span class="k">elif</span> <span class="n">line</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">'Pixel mask for object'</span><span class="p">):</span>
            <span class="n">mask_image_path</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">': '</span><span class="p">)[</span><span class="mi">1</span><span class="p">].</span><span class="n">strip</span><span class="p">().</span><span class="n">replace</span><span class="p">(</span><span class="s">'"'</span><span class="p">,</span> <span class="s">''</span><span class="p">)</span>

    <span class="c1"># 이미지와 마스크 이미지 불러오기
</span>    <span class="n">image_path</span> <span class="o">=</span> <span class="n">annotation_file_path</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">'Annotation'</span><span class="p">,</span> <span class="s">'PNGImages'</span><span class="p">).</span><span class="n">replace</span><span class="p">(</span><span class="s">'.txt'</span><span class="p">,</span> <span class="s">'.png'</span><span class="p">)</span>
    <span class="n">png_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
    <span class="n">png_image_rgb</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">png_image</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>
    <span class="n">mask_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">imread</span><span class="p">(</span><span class="n">mask_image_path</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># Grayscale
</span>
    <span class="c1"># 이미지에 바운딩 박스 그리기
</span>    <span class="n">boundingbox_image</span> <span class="o">=</span> <span class="n">png_image_rgb</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">box</span> <span class="ow">in</span> <span class="n">bounding_boxes</span><span class="p">:</span>
        <span class="n">cv2</span><span class="p">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">boundingbox_image</span><span class="p">,</span> <span class="n">box</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">box</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Red bounding box
</span>
    <span class="c1"># 이미지 출력
</span>    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">imshow</span><span class="p">(</span><span class="n">png_image_rgb</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>  <span class="c1"># Hide axes
</span>    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Basic Image'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">imshow</span><span class="p">(</span><span class="n">boundingbox_image</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>  <span class="c1"># Hide axes
</span>    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Bounding Image'</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="n">imshow</span><span class="p">(</span><span class="n">mask_image</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>  <span class="c1"># Hide axes
</span>    <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Segmentation Image'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">):</span>
    <span class="n">annotation_file_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s">'PennFudanPed/Annotation/FudanPed0000</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">.txt'</span>
    <span class="n">draw_images</span><span class="p">(</span><span class="n">annotation_file_path</span><span class="p">)</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/post/2023-10-23/01.png" width="auto" height="auto" max-width="500" /></p><h2 id="4-데이터-세트-정의">4. 데이터 세트 정의</h2><p>이미지의 Detection 및 Segmentation을 위해 torch의 dataset 클래스를 상속하여 Custom Dataset을 구성합니다.</p><ol><li>Image<ul><li>[3, H, W]의 텐서 shape 혹은 PIL Image의 크기 [H, W] (torchvision.tv_tensors.Image)</li></ul></li><li>target<ul><li>boxes : [N, 4]의 shape [x0, y0, x1, y1] (torchvision.tv_tensors.BoundingBoxes)</li><li>labels : 텐서 shape 정수 [N] (torch.Tensor)</li><li>image_id : 이미지를 식별하기 위한 고유 ID</li><li>area : BoundingBoxes의 영역 (torch.Tensor)</li><li>iscrowd : 텐서 shape의 uint8[N] (torch.Tensor)</li><li>masks : segmentation의 정보 [N, H, W] (torchvision.tv_tensors.Mask)</li></ul></li></ol><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
</pre><td class="rouge-code"><pre><span class="k">class</span> <span class="nc">PennFudanDataset</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">root</span><span class="p">,</span> <span class="n">transforms</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">root</span> <span class="o">=</span> <span class="n">root</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">transforms</span> <span class="o">=</span> <span class="n">transforms</span>
        <span class="c1"># 모든 이미지 파일으 불러오고 정렬
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">imgs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="s">"PNGImages"</span><span class="p">))))</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">masks</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="s">"PedMasks"</span><span class="p">))))</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="c1"># 이미지와 마스크 불러오기
</span>        <span class="n">img_path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">root</span><span class="p">,</span> <span class="s">"PNGImages"</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">imgs</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="n">mask_path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">root</span><span class="p">,</span> <span class="s">"PedMasks"</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">masks</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">read_image</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">read_image</span><span class="p">(</span><span class="n">mask_path</span><span class="p">)</span>
        <span class="n">obj_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">unique</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
        <span class="c1"># 첫번째 ID는 Background 이므로 제거 (CoCodataset 기준)
</span>        <span class="n">obj_ids</span> <span class="o">=</span> <span class="n">obj_ids</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="n">num_objs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">obj_ids</span><span class="p">)</span>

        <span class="c1"># 색상으로 인코딩된 마스크를 세트로 분할
</span>        <span class="n">masks</span> <span class="o">=</span> <span class="p">(</span><span class="n">mask</span> <span class="o">==</span> <span class="n">obj_ids</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">]).</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">uint8</span><span class="p">)</span>

        <span class="c1"># 각 마스크의 Bounding box 좌표
</span>        <span class="n">boxes</span> <span class="o">=</span> <span class="n">masks_to_boxes</span><span class="p">(</span><span class="n">masks</span><span class="p">)</span>

        <span class="c1"># there is only one class
</span>        <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="n">num_objs</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span>

        <span class="n">image_id</span> <span class="o">=</span> <span class="n">idx</span>
        <span class="n">area</span> <span class="o">=</span> <span class="p">(</span><span class="n">boxes</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">-</span> <span class="n">boxes</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="p">(</span><span class="n">boxes</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">boxes</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
        <span class="c1"># 모든 인스턴스가 iscrod라고 가정
</span>        <span class="n">iscrowd</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_objs</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span>

        <span class="c1"># 샘플과 대상을 torchvision tv_tensors로 래핑합니다.
</span>        <span class="n">img</span> <span class="o">=</span> <span class="n">tv_tensors</span><span class="p">.</span><span class="n">Image</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

        <span class="n">target</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">target</span><span class="p">[</span><span class="s">"boxes"</span><span class="p">]</span> <span class="o">=</span> <span class="n">tv_tensors</span><span class="p">.</span><span class="n">BoundingBoxes</span><span class="p">(</span><span class="n">boxes</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s">"XYXY"</span><span class="p">,</span> <span class="n">canvas_size</span><span class="o">=</span><span class="n">F</span><span class="p">.</span><span class="n">get_size</span><span class="p">(</span><span class="n">img</span><span class="p">))</span>
        <span class="n">target</span><span class="p">[</span><span class="s">"masks"</span><span class="p">]</span> <span class="o">=</span> <span class="n">tv_tensors</span><span class="p">.</span><span class="n">Mask</span><span class="p">(</span><span class="n">masks</span><span class="p">)</span>
        <span class="n">target</span><span class="p">[</span><span class="s">"labels"</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
        <span class="n">target</span><span class="p">[</span><span class="s">"image_id"</span><span class="p">]</span> <span class="o">=</span> <span class="n">image_id</span>
        <span class="n">target</span><span class="p">[</span><span class="s">"area"</span><span class="p">]</span> <span class="o">=</span> <span class="n">area</span>
        <span class="n">target</span><span class="p">[</span><span class="s">"iscrowd"</span><span class="p">]</span> <span class="o">=</span> <span class="n">iscrowd</span>
        
        <span class="c1"># 이미지 transform 설정
</span>        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">transforms</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">img</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">transforms</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="n">target</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">imgs</span><span class="p">)</span>
</pre></table></code></div></div><h2 id="5-모델-정의">5. 모델 정의</h2><p>Coco dataset으로 사전 훈련된 모델을 기반으로 Penn-Fudan Dataset에 맞춰 Fine-Tuning을 진행할 FastRCNN 모델을 구성합니다. Feature를 추출할 모델은 Resnet50을 사용했습니다. 또한, Segmentation을 하기 위해 MaskRCNN도 사용합니다.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">torchvision.models.detection.faster_rcnn</span> <span class="kn">import</span> <span class="n">FastRCNNPredictor</span>
<span class="kn">from</span> <span class="nn">torchvision.models.detection.mask_rcnn</span> <span class="kn">import</span> <span class="n">MaskRCNNPredictor</span>


<span class="k">def</span> <span class="nf">get_model_instance_segmentation</span><span class="p">(</span><span class="n">num_classes</span><span class="p">):</span>
    <span class="c1"># Coco dataset으로 사전 훈련된 resnet50 불러오기
</span>    <span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">detection</span><span class="p">.</span><span class="n">maskrcnn_resnet50_fpn</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s">"DEFAULT"</span><span class="p">)</span>

    <span class="c1"># classification 모델의 input feature 갯수 가져오기
</span>    <span class="n">in_features</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">roi_heads</span><span class="p">.</span><span class="n">box_predictor</span><span class="p">.</span><span class="n">cls_score</span><span class="p">.</span><span class="n">in_features</span>
    <span class="c1"># 모델의 head 변경
</span>    <span class="n">model</span><span class="p">.</span><span class="n">roi_heads</span><span class="p">.</span><span class="n">box_predictor</span> <span class="o">=</span> <span class="n">FastRCNNPredictor</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

    <span class="c1"># segmentation 모델의 input feature 갯수 가져오기
</span>    <span class="n">in_features_mask</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">roi_heads</span><span class="p">.</span><span class="n">mask_predictor</span><span class="p">.</span><span class="n">conv5_mask</span><span class="p">.</span><span class="n">in_channels</span>
    <span class="n">hidden_layer</span> <span class="o">=</span> <span class="mi">256</span>
    
    <span class="c1"># 수정한 Layer들 model에 적용
</span>    <span class="n">model</span><span class="p">.</span><span class="n">roi_heads</span><span class="p">.</span><span class="n">mask_predictor</span> <span class="o">=</span> <span class="n">MaskRCNNPredictor</span><span class="p">(</span>
        <span class="n">in_features_mask</span><span class="p">,</span>
        <span class="n">hidden_layer</span><span class="p">,</span>
        <span class="n">num_classes</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span>
</pre></table></code></div></div><h2 id="6-모델-훈련">6. 모델 훈련</h2><p>데이터셋을 데이터 로더에 넣고 모델을 Fine-Tuning 합니다.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="c1"># 이미지 변환 함수
</span><span class="k">def</span> <span class="nf">get_transform</span><span class="p">(</span><span class="n">train</span><span class="p">):</span>
    <span class="n">transforms</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
        <span class="n">transforms</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">T</span><span class="p">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="mf">0.5</span><span class="p">))</span>
    <span class="n">transforms</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">T</span><span class="p">.</span><span class="n">ToDtype</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
    <span class="n">transforms</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">T</span><span class="p">.</span><span class="n">ToPureTensor</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">T</span><span class="p">.</span><span class="n">Compose</span><span class="p">(</span><span class="n">transforms</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
</pre><td class="rouge-code"><pre><span class="c1"># GPU or CPU 설정
</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cuda'</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cpu'</span><span class="p">)</span>

<span class="c1"># 사람, Background class 설정
</span><span class="n">num_classes</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># 이미지 변환 및 Dataset 생성
</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">PennFudanDataset</span><span class="p">(</span><span class="s">'data/PennFudanPed'</span><span class="p">,</span> <span class="n">get_transform</span><span class="p">(</span><span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
<span class="n">dataset_test</span> <span class="o">=</span> <span class="n">PennFudanDataset</span><span class="p">(</span><span class="s">'data/PennFudanPed'</span><span class="p">,</span> <span class="n">get_transform</span><span class="p">(</span><span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>

<span class="c1"># Train, Test Dataset 분할
</span><span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randperm</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)).</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Subset</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">indices</span><span class="p">[:</span><span class="o">-</span><span class="mi">50</span><span class="p">])</span>
<span class="n">dataset_test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Subset</span><span class="p">(</span><span class="n">dataset_test</span><span class="p">,</span> <span class="n">indices</span><span class="p">[</span><span class="o">-</span><span class="mi">50</span><span class="p">:])</span>

<span class="c1"># 데이터 로더 정의
</span><span class="n">data_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">dataset</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">collate_fn</span><span class="o">=</span><span class="n">utils</span><span class="p">.</span><span class="n">collate_fn</span>
<span class="p">)</span>

<span class="n">data_loader_test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">dataset_test</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">collate_fn</span><span class="o">=</span><span class="n">utils</span><span class="p">.</span><span class="n">collate_fn</span>
<span class="p">)</span>

<span class="c1"># 모델 생성
</span><span class="n">model</span> <span class="o">=</span> <span class="n">get_model_instance_segmentation</span><span class="p">(</span><span class="n">num_classes</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Optimizer 구성
</span><span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="p">.</span><span class="n">requires_grad</span><span class="p">]</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">SGD</span><span class="p">(</span>
    <span class="n">params</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span>
    <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.0005</span>
<span class="p">)</span>

<span class="c1"># 스케쥴러 구성
</span><span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">lr_scheduler</span><span class="p">.</span><span class="n">StepLR</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="p">,</span>
    <span class="n">step_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span>
<span class="p">)</span>

<span class="c1"># 5회 학습
</span><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">5</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="c1"># Train - 10회 마다 loss 출력
</span>    <span class="n">train_one_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">print_freq</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="c1"># learning rate 업데이트
</span>    <span class="n">lr_scheduler</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
    <span class="c1"># Test 데이터로 평가
</span>    <span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data_loader_test</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"종료"</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
</pre><td class="rouge-code"><pre>Epoch: [0]  [ 0/60]  eta: 0:02:10  lr: 0.000090  loss: 3.3485 (3.3485)  loss_classifier: 0.8555 (0.8555)  loss_box_reg: 0.2014 (0.2014)  loss_mask: 2.2850 (2.2850)  loss_objectness: 0.0051 (0.0051)  loss_rpn_box_reg: 0.0016 (0.0016)  time: 2.1828  data: 0.0141  max mem: 1945
Epoch: [0]  [59/60]  eta: 0:00:00  lr: 0.005000  loss: 0.3216 (0.7944)  loss_classifier: 0.0498 (0.1673)  loss_box_reg: 0.1535 (0.2185)  loss_mask: 0.1549 (0.3942)  loss_objectness: 0.0014 (0.0076)  loss_rpn_box_reg: 0.0055 (0.0068)  time: 0.2061  data: 0.0129  max mem: 2765
Epoch: [0] Total time: 0:00:14 (0.2396 s / it)
creating index...
index created!
Test:  [ 0/50]  eta: 0:00:05  model_time: 0.0931 (0.0931)  evaluator_time: 0.0033 (0.0033)  time: 0.1008  data: 0.0042  max mem: 2765
Test:  [49/50]  eta: 0:00:00  model_time: 0.0385 (0.0639)  evaluator_time: 0.0025 (0.0043)  time: 0.0587  data: 0.0057  max mem: 2765
Test: Total time: 0:00:03 (0.0746 s / it)
Averaged stats: model_time: 0.0385 (0.0639)  evaluator_time: 0.0025 (0.0043)
Accumulating evaluation results...
DONE (t=0.01s).
Accumulating evaluation results...
DONE (t=0.01s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.720
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.942
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.654
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.727
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.285
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.771
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.771
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.776
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.770
IoU metric: segm
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.740
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.990
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.948
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.533
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.754
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.295
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.772
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.775
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.753
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.779

******Result******
-----Bounding BOX AP IoU=0.50:0.95: 0.72-----
-----Segmentation AP IoU=0.50:0.95: 0.74-----

......(생략)......

Epoch: [4]  [ 0/60]  eta: 0:00:13  lr: 0.000500  loss: 0.2298 (0.2298)  loss_classifier: 0.0407 (0.0407)  loss_box_reg: 0.0676 (0.0676)  loss_mask: 0.1175 (0.1175)  loss_objectness: 0.0001 (0.0001)  loss_rpn_box_reg: 0.0040 (0.0040)  time: 0.2326  data: 0.0141  max mem: 3162
Epoch: [4]  [59/60]  eta: 0:00:00  lr: 0.000500  loss: 0.1828 (0.1846)  loss_classifier: 0.0246 (0.0256)  loss_box_reg: 0.0360 (0.0391)  loss_mask: 0.1087 (0.1163)  loss_objectness: 0.0002 (0.0007)  loss_rpn_box_reg: 0.0020 (0.0028)  time: 0.1864  data: 0.0111  max mem: 3162
Epoch: [4] Total time: 0:00:11 (0.1938 s / it)
creating index...
index created!
Test:  [ 0/50]  eta: 0:00:02  model_time: 0.0391 (0.0391)  evaluator_time: 0.0024 (0.0024)  time: 0.0459  data: 0.0042  max mem: 3162
Test:  [49/50]  eta: 0:00:00  model_time: 0.0395 (0.0399)  evaluator_time: 0.0017 (0.0026)  time: 0.0487  data: 0.0057  max mem: 3162
Test: Total time: 0:00:02 (0.0489 s / it)
Averaged stats: model_time: 0.0395 (0.0399)  evaluator_time: 0.0017 (0.0026)
Accumulating evaluation results...
DONE (t=0.00s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.833
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.992
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.956
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.682
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.849
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.340
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.869
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.869
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.782
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.882
IoU metric: segm
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.789
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.992
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.957
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.631
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.804
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.315
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.816
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.816
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.741
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.827

******Result******
-----Bounding BOX AP IoU=0.50:0.95: 0.833-----
-----Segmentation AP IoU=0.50:0.95: 0.789-----

종료
</pre></table></code></div></div><p>5회 반복으로 학습한 결과 Object Detection의 IoU는 0.72에서 0.833까지 0.133상승했으며 segmentation은 0.74에서 0.789으로 0.049 상승된 수치를 보여주었습니다.</p><h2 id="7-예측-결과-확인">7. 예측 결과 확인</h2><p>샘플 데이터를 넣고 Objectdetection과 segmentation의 결과를 확인해보니, 생각보다 결과가 잘 나온것을 알 수 있습니다.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
</pre><td class="rouge-code"><pre><span class="n">image</span> <span class="o">=</span> <span class="n">read_image</span><span class="p">(</span><span class="s">"./PennFudanPed/PNGImages/PennPed00040.png"</span><span class="p">)</span>
<span class="n">eval_transform</span> <span class="o">=</span> <span class="n">get_transform</span><span class="p">(</span><span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># 모델 평가 모드 후 예측
</span><span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">eval_transform</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="p">...].</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="p">])</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>


<span class="c1"># 이미지 변환
</span><span class="n">image</span> <span class="o">=</span> <span class="p">(</span><span class="mf">255.0</span> <span class="o">*</span> <span class="p">(</span><span class="n">image</span> <span class="o">-</span> <span class="n">image</span><span class="p">.</span><span class="nb">min</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">image</span><span class="p">.</span><span class="nb">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">image</span><span class="p">.</span><span class="nb">min</span><span class="p">())).</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="p">...]</span>
<span class="n">pred_labels</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s">"pedestrian: </span><span class="si">{</span><span class="n">score</span><span class="p">:.</span><span class="mi">3</span><span class="n">f</span><span class="si">}</span><span class="s">"</span> <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="s">"labels"</span><span class="p">],</span> <span class="n">pred</span><span class="p">[</span><span class="s">"scores"</span><span class="p">])]</span>
<span class="n">pred_boxes</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="s">"boxes"</span><span class="p">].</span><span class="nb">long</span><span class="p">()</span>
<span class="n">output_image</span> <span class="o">=</span> <span class="n">draw_bounding_boxes</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">pred_boxes</span><span class="p">,</span> <span class="n">pred_labels</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s">"red"</span><span class="p">)</span>

<span class="c1"># Mask 생성
</span><span class="n">masks</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="s">"masks"</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.7</span><span class="p">).</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">output_image</span> <span class="o">=</span> <span class="n">draw_segmentation_masks</span><span class="p">(</span><span class="n">output_image</span><span class="p">,</span> <span class="n">masks</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s">"blue"</span><span class="p">)</span>

<span class="c1"># 이미지 확인
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_image</span><span class="p">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/post/2023-10-23/02.png" width="auto" height="auto" max-width="500" /></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/data-science/'>Data Science</a>, <a href='/categories/cv/'>CV</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/object-detection/" class="post-tag no-text-decoration" >Object Detection</a> <a href="/tags/segmentation/" class="post-tag no-text-decoration" >Segmentation</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><!-- Post sharing snippet v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Penn-Fudan으로 알아보는 객체 탐지(Object Detection), 분할(Segmentation) with FasterRCNN - Data Include Me&url=https://datainclude.me/posts/Penn_Fudan%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EA%B0%9D%EC%B2%B4_%ED%83%90%EC%A7%80_%EB%B6%84%ED%95%A0/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Penn-Fudan으로 알아보는 객체 탐지(Object Detection), 분할(Segmentation) with FasterRCNN - Data Include Me&u=https://datainclude.me/posts/Penn_Fudan%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EA%B0%9D%EC%B2%B4_%ED%83%90%EC%A7%80_%EB%B6%84%ED%95%A0/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Penn-Fudan으로 알아보는 객체 탐지(Object Detection), 분할(Segmentation) with FasterRCNN - Data Include Me&url=https://datainclude.me/posts/Penn_Fudan%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EA%B0%9D%EC%B2%B4_%ED%83%90%EC%A7%80_%EB%B6%84%ED%95%A0/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><!-- The Panel on right side (Desktop views) v2.3 © 2024 Your Name MIT License --><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><h3 data-toc-skip>Recent Update</h3><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li class="recent-item"> <a href="/posts/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C_%EC%BB%B4%ED%93%A8%ED%8C%85_%EA%B0%80%EC%83%81%ED%99%94/">클라우드 컴퓨팅 - 가상화</a> <span class="text-muted small">2024-10-28</span></li><li class="recent-item"> <a href="/posts/gemini_api_%EC%82%AC%EC%9A%A9%ED%95%B4%EB%B3%B4%EA%B8%B0/">Gemini API 사용해보기</a> <span class="text-muted small">2024-03-12</span></li><li class="recent-item"> <a href="/posts/Ollama%EC%99%80_Python_%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC_LLaMa2%EB%A5%BC_%EB%A1%9C%EC%BB%AC%EC%97%90%EC%84%9C_%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/">Ollama와 Python 라이브러리를 이용하여 LLaMa2를 로컬에서 사용하기</a> <span class="text-muted small">2024-02-13</span></li><li class="recent-item"> <a href="/posts/Mistral_7B_Fine_Tuning/">Mistral 7B 파인튜닝(Fine Tuning)하기</a> <span class="text-muted small">2023-10-25</span></li><li class="recent-item"> <a href="/posts/Penn_Fudan%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EA%B0%9D%EC%B2%B4_%ED%83%90%EC%A7%80_%EB%B6%84%ED%95%A0/">Penn-Fudan으로 알아보는 객체 탐지(Object Detection), 분할(Segmentation) with FasterRCNN</a> <span class="text-muted small">2023-10-23</span></li></ul></div><div id="access-tags"><h3 data-toc-skip>Trending Tags</h3><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/tensorflow/">Tensorflow</a> <a class="post-tag" href="/tags/sklearn/">Sklearn</a> <a class="post-tag" href="/tags/round/">Round</a> <a class="post-tag" href="/tags/python-lv0/">Python Lv0</a> <a class="post-tag" href="/tags/pca/">PCA</a> <a class="post-tag" href="/tags/eda/">EDA</a> <a class="post-tag" href="/tags/distinct/">Distinct</a> <a class="post-tag" href="/tags/random-forest/">Random Forest</a> <a class="post-tag" href="/tags/beautifulsoup/">Beautifulsoup</a> <a class="post-tag" href="/tags/baekjoon/">Baekjoon</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><h3 data-toc-skip class="pl-3 pt-2 mb-2">Contents</h3><nav id="toc" data-toggle="toc"></nav></div></div><style> .recent-item { margin-bottom: 0.5rem; } .recent-item a { color: var(--link-color); } .recent-item .small { font-size: 0.75rem; margin-left: 0.5rem; }</style></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"> <!-- Recommend the other 3 posts according to the tags and categories of the current post, if the number is not enough, use the other latest posts to supplement. v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/%EB%BD%90%EB%BF%8C_%ED%8A%B9%EA%B0%80_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EC%84%9D_%ED%95%98%EA%B8%B0/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Aug 25, 2023 <i class="unloaded">2023-08-25T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>뽐뿌 특가 데이터 분석 하기</h3><div class="text-muted small"><p> 나는 현명한 소비자가 되기 위해 항상 최적의 가격과 가성비 있는 상품을 찾는 데 큰 관심을 가지고 있다. 이러한 관심은 소비 습관을 개선하고 특별한 노하우를 가지게 되는데 큰 도움을 주었다. 데이터 사이언티스트로서 이 노하우를 활용하여 대표적인 특가 정보 커뮤니티인 ‘뽐뿌’의 특가 데이터를 분석하려고 한다. ‘뽐뿌’는 연간 약 2만 5천개의 특가 게시...</p></div></div></a></div><div class="card"> <a href="/posts/LangChain_%EA%B8%B0%EC%B4%88_%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC_%ED%8C%8C%ED%8A%B81/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Sep 5, 2023 <i class="unloaded">2023-09-05T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>LangChain 기초 튜토리얼 파트1</h3><div class="text-muted small"><p> 해당 쿡북은 langchain-tutorials-LangChain Cookbook Part 1 - Fundamentals를 한글로 번역한 것이며 LangChain Conceptual Documentation을 기반으로 작성 되었습니다. 목표: ELI5예제와 코드를 통해 LangChain의 구성 요소와 사용 사례에 대한 기본적인 이해를 제공합니다. 사...</p></div></div></a></div><div class="card"> <a href="/posts/%EA%B5%AC%EA%B8%80_colab%EA%B3%BC_vscode_%EC%97%B0%EB%8F%99%ED%95%98%EA%B8%B0/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Jan 23, 2022 <i class="unloaded">2022-01-23T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>구글 colab과 vscode 연동하기</h3><div class="text-muted small"><p> 0. 들어가며 구글 코랩은 굉장히 가성비가 좋은 데이터분석툴이다. 쥬피터와 비슷한 환경을 가지고 있어 사용하는데 어색하지 않으며, GPU를 무료로 빌려주어 딥러닝 학습에도 많이 사용한다. vscode와 연동하여, 굳이 코랩으로 사용하지 않고 vscode 환경에서 사용하는 방법을 소개하려한다. 1. ngrok 설치 https://d...</p></div></div></a></div></div></div><!-- Navigation buttons at the bottom of the post. v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --><div class="post-navigation d-flex justify-content-between"> <a href="/posts/RAG/" class="btn btn-outline-primary"><p>Retrieval-Augmented Generation (RAG, 검색-증강 생성)</p></a> <a href="/posts/Mistral_7B_Fine_Tuning/" class="btn btn-outline-primary"><p>Mistral 7B 파인튜닝(Fine Tuning)하기</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('#post-wrapper img'); const observer = lozad(imgs); observer.observe(); </script></div><!-- The Search results v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/tensorflow/">Tensorflow</a> <a class="post-tag" href="/tags/sklearn/">Sklearn</a> <a class="post-tag" href="/tags/round/">Round</a> <a class="post-tag" href="/tags/python-lv0/">Python Lv0</a> <a class="post-tag" href="/tags/pca/">PCA</a> <a class="post-tag" href="/tags/eda/">EDA</a> <a class="post-tag" href="/tags/distinct/">Distinct</a> <a class="post-tag" href="/tags/random-forest/">Random Forest</a> <a class="post-tag" href="/tags/beautifulsoup/">Beautifulsoup</a> <a class="post-tag" href="/tags/baekjoon/">Baekjoon</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <!-- The GA snippet v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <!-- Jekyll Simple Search loader v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://datainclude.me{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script>
