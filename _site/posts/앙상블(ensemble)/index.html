<!DOCTYPE html><html lang="ko" mode="light" > <!-- The Head v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>앙상블(Ensemble) | Data Include Me</title><meta name="generator" content="Jekyll v3.9.3" /><meta property="og:title" content="앙상블(Ensemble)" /><meta name="author" content="HyunMin Kim" /><meta property="og:locale" content="ko" /><meta name="description" content="1. 앙상블 기법 1.1 앙상블 기법 앙상블 학습을 통한 분류 : 여러 개의 분류기를 생성하고 그 예측을 결합하여 정확한 최종 예측을 기대하는 기법 앙상블 학습의 목표 : 다양한 분류기의 예측 결과를 결합함으로써 단일 분류기보다 신뢰성이 높은 예측 값을 얻는 것 정형 데이터를 대상으로 하는 분류기에서는 앙상블 기법이 뛰어난 성과를 보여줌" /><meta property="og:description" content="1. 앙상블 기법 1.1 앙상블 기법 앙상블 학습을 통한 분류 : 여러 개의 분류기를 생성하고 그 예측을 결합하여 정확한 최종 예측을 기대하는 기법 앙상블 학습의 목표 : 다양한 분류기의 예측 결과를 결합함으로써 단일 분류기보다 신뢰성이 높은 예측 값을 얻는 것 정형 데이터를 대상으로 하는 분류기에서는 앙상블 기법이 뛰어난 성과를 보여줌" /><link rel="canonical" href="https://datainclude.me/posts/%EC%95%99%EC%83%81%EB%B8%94(ensemble)/" /><meta property="og:url" content="https://datainclude.me/posts/%EC%95%99%EC%83%81%EB%B8%94(ensemble)/" /><meta property="og:site_name" content="Data Include Me" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-10-13T09:10:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="앙상블(Ensemble)" /><meta name="twitter:site" content="@" /><meta name="twitter:creator" content="@HyunMin Kim" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"HyunMin Kim"},"dateModified":"2020-10-13T09:10:00+09:00","datePublished":"2020-10-13T09:10:00+09:00","description":"1. 앙상블 기법 1.1 앙상블 기법 앙상블 학습을 통한 분류 : 여러 개의 분류기를 생성하고 그 예측을 결합하여 정확한 최종 예측을 기대하는 기법 앙상블 학습의 목표 : 다양한 분류기의 예측 결과를 결합함으로써 단일 분류기보다 신뢰성이 높은 예측 값을 얻는 것 정형 데이터를 대상으로 하는 분류기에서는 앙상블 기법이 뛰어난 성과를 보여줌","headline":"앙상블(Ensemble)","mainEntityOfPage":{"@type":"WebPage","@id":"https://datainclude.me/posts/%EC%95%99%EC%83%81%EB%B8%94(ensemble)/"},"url":"https://datainclude.me/posts/%EC%95%99%EC%83%81%EB%B8%94(ensemble)/"}</script><meta property="og:image" content="https://datainclude.me/assets/img/sample/avatar.jpg" /> <!-- The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps Generated by: https://www.favicon-generator.org/ v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT license --><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="36x36" href="/assets/img/favicons/android-icon-36x36.png"><link rel="icon" type="image/png" sizes="48x48" href="/assets/img/favicons/android-icon-48x48.png"><link rel="icon" type="image/png" sizes="72x72" href="/assets/img/favicons/android-icon-72x72.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/android-icon-96x96.png"><link rel="icon" type="image/png" sizes="144x144" href="/assets/img/favicons/android-icon-144x144.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="70x70" href="/assets/img/favicons/ms-icon-70x70.png"><link rel="icon" type="image/png" sizes="144x144" href="/assets/img/favicons/ms-icon-144x144.png"><link rel="icon" type="image/png" sizes="150x150" href="/assets/img/favicons/ms-icon-150x150.png"><link rel="icon" type="image/png" sizes="310x310" href="/assets/img/favicons/ms-icon-310x310.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preload" href="https://www.googletagmanager.com/gtm.js?id=GTM-MW9VRMW9" as="script"> <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src= 'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f); })(window,document,'script','dataLayer','GTM-MW9VRMW9');</script><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="preload" as="style" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous" media="print" onload="this.media='all'"> <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"> </noscript> <!-- CSS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --><link rel="preload" as="style" href="/assets/css/post.css"><link rel="stylesheet" href="/assets/css/post.css"><link rel="preload" as="style" href="/assets/css/lib/bootstrap-toc.min.css"><link rel="stylesheet" href="/assets/css/lib/bootstrap-toc.min.css" /><link rel="preload" as="script" href="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" async></script> <!-- JS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --> <script src="/assets/js/post.min.js" async></script> <script src="/app.js" defer></script><body data-spy="scroll" data-target="#toc"> <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MW9VRMW9" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="sidebar" class="d-flex flex-column"> <!-- The Side Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="nav-wrapper"><div id="profile-wrapper" class="d-flex flex-column"><div id="avatar" class="d-flex justify-content-center"> <a href="/" alt="avatar"> <img src="/assets/img/sample/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="profile-text mt-3"><div class="site-title"> <a href="/">Data Include Me</a></div><div class="site-subtitle font-italic">Data Science Blog</div></div></div><ul class="nav flex-column"><li class="nav-item d-flex justify-content-center "> <a href="/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/categories/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/tags/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/archives/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/about/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></li></ul></div><div class="sidebar-bottom d-flex flex-wrap justify-content-around mt-4"> <a href="https://github.com/hmkim312" target="_blank"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/" target="_blank"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:window.open('mailto:' + ['sanarial312','gmail.com'].join('@'))" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" > <i class="fas fa-rss"></i> </a></div></div><!-- The Top Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>앙상블(Ensemble)</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"> <!-- Refactor the HTML structure. --> <!-- Suroundding the markdown table with '<div class="table-wrapper">. and '</div>' --> <!-- Fixed kramdown code highlight rendering: https://github.com/penibelst/jekyll-compress-html/issues/101 https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901 --><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"> <script type="text/javascript"> var lazyloadads = false; function loadAds() { if (!lazyloadads) { var script = document.createElement("script"); script.type = "text/javascript"; script.async = true; script.src = "https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7594406644928408"; document.body.appendChild(script); lazyloadads = true; } } window.addEventListener("mousemove", loadAds, { once: true }); window.addEventListener('touchstart', loadAds, { once: true }); </script><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>앙상블(Ensemble)</h1><div class="post-meta text-muted d-flex flex-column"><div> Posted <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Tue, Oct 13, 2020, 9:10 AM +0900" > Oct 13, 2020 <i class="unloaded">2020-10-13T09:10:00+09:00</i> </span> by <span class="author"> HyunMin Kim </span></div><a href="https://hits.seeyoufarm.com"> <img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https://datainclude.me/posts/%EC%95%99%EC%83%81%EB%B8%94(ensemble)/%2F&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=views&edge_flat=false" alt="페이지 조회수 뱃지", width: 100%;, height: 100%;/> </a></div><div class="post-content"><h2 id="1-앙상블-기법">1. 앙상블 기법</h2><hr /><h3 id="11-앙상블-기법">1.1 앙상블 기법</h3><ul><li>앙상블 학습을 통한 분류 : 여러 개의 분류기를 생성하고 그 예측을 결합하여 정확한 최종 예측을 기대하는 기법</li><li>앙상블 학습의 목표 : 다양한 분류기의 예측 결과를 결합함으로써 단일 분류기보다 신뢰성이 높은 예측 값을 얻는 것</li><li>정형 데이터를 대상으로 하는 분류기에서는 앙상블 기법이 뛰어난 성과를 보여줌</li></ul><p><br /></p><h3 id="12-voting">1.2 Voting</h3><ul><li>하나의 데이터셋을 여러개의 모델이 사용하여 투표를 최종 결정</li></ul><p><br /></p><h3 id="13-bagging">1.3 Bagging</h3><ul><li>데이터를 중복을 허용해서 샘플링하고 각각의 데이터에 같은 알고리즘을 적용하여 결과를 투표로 결정함</li><li>각각의 분류기에 데이터를 각각 샘플링해서 추출하는 방식을 부트스트래핑방식이라고 함</li></ul><p><br /></p><h3 id="14-boosting">1.4 Boosting</h3><ul><li>여러개의 알고리즘이 순차적으로 학습을 하되 앞에 학습한 알고리즘 예측이 틀린 데이터에 대해 올바르게 예측할수 있도록 그 다음번 알고리즘에 가중치를 부여하여 학습과 예측을 진행하는 방식</li></ul><p><br /></p><h3 id="15-stacking">1.5 Stacking</h3><ul><li>여러가지 다른 모델의 예측 결과값을 다시 학습 데이터로 만들어 다른 모델로 재학습시켜 결과를 예측 하는 방법</li></ul><p><br /></p><h3 id="16-hard-voting">1.6 Hard voting</h3><ul><li>다수결의 원칙으로 투표와 비슷함</li></ul><p><br /></p><h3 id="17-soft-voting">1.7 Soft voting</h3><ul><li>각 알고리즘이 레이블 값 결정 확률을 예측해서, 이것을 평균하여 이들 중 가장 확률이 높은 레이블 값을 최종값으로 예측</li></ul><p><br /></p><h3 id="18-random-forest">1.8 Random Forest</h3><ul><li>같은 알고리즘으로 구현하는 배깅의 대표적인 방법</li><li>앙상블 방법 중에서 비교적 속도가 빠르며 다양한 영역에서 높은 성능을 보여줌<ul><li>부트스트래핑은 여러개의 작은 데이터셋을 중첩을 허용하여 만드는 것</li></ul></li><li>랜덤포레스트는 결정 나무를 기본으로 함<ul><li>부트스트래핑으로 샘플링된 데이터마다 결정나무가 예측한 결과를 소프트 보팅으로 최종 예측 결론을 얻음</li></ul></li></ul><p><br /></p><h2 id="2-har-human-activity-recognition">2. HAR, Human Activity Recognition</h2><hr /><h3 id="21-imu-센서를-활용해서-사람의-행동을-인식하는-실험">2.1 IMU 센서를 활용해서 사람의 행동을 인식하는 실험</h3><ul><li>UCI HAR 데이터 셋은 스마트폰을 장착한 사람의 행동을 관찰한 데이터</li><li>허리에 스마트폰을 착용하여 50Hz의 주파수로 데이터를 얻음</li><li>6가지 활동(걷기, 계단 오르기, 계단 내려가기, 앉기, 일어서기, 눕기)을 수행</li><li>내장 된 가속도계와 자이로 스코프를 사용하여 50Hz의 일정한 속도로 3축 선형 가속 및 3축 각속도를 갭처</li><li>중력 및 신체 운동 성분을 갖는 센서 가속 신호는 버터 워스 저역 통과 필터를 사용하여 신체 가속 및 중력으로 분리</li></ul><p><br /></p><h3 id="22-데이터의-특성">2.2 데이터의 특성</h3><ul><li>가속도계로부터의 3축 가속도 및 추정 된 신체 가속도</li><li>자이로 스코프의 3축 가속도</li><li>시간 및 주파수 영역 변수가 포함된 561 기능 백터</li><li>활동 라벨</li><li>실험을 수행 한 대상의 식별자</li></ul><p><br /></p><h3 id="23-데이터의-시간-영역">2.3 데이터의 시간 영역</h3><ul><li>실제 시간 영역의 데이터를 직접 사용하는것은 어려움</li><li>해당 행동도 시간의 영역임 (움직였다가 멈췄다가 함)</li><li>시간 영역 데이터를 머신러닝에 적용하기 위해 여러 통계적 데이터로 변환함</li><li>시간 영역의 평균, 분산, 피크, 중간 값, 주파수 영역의 평균, 분산 등으로 변환한 수리를 가지고 있음</li></ul><p><br /></p><h3 id="24-머신러닝의-행동-인식-연구">2.4 머신러닝의 행동 인식 연구</h3><ul><li>센서신호 -&gt; 특징추출 -&gt; 모델학습 -&gt; 행동추론</li><li>센서신호를 받아, 시간 영역과 주파수 영역에서 특징을 추출하고, 모델을 학습, 행동 추론</li></ul><p><br /></p><h3 id="25-데이터-로드">2.5 데이터 로드</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">url</span> <span class="o">=</span> <span class="s">'https://raw.githubusercontent.com/hmkim312/datas/main/HAR/features.txt'</span>

<span class="n">feature_name_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">sep</span> <span class="o">=</span> <span class="s">'\s+'</span><span class="p">,</span> <span class="n">header</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s">'column_index'</span><span class="p">,</span><span class="s">'column_name'</span><span class="p">])</span>
<span class="n">feature_name_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</pre></table></code></div></div><p><br /></p><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>column_index<th>column_name<tbody><tr><th>0<td>1<td>tBodyAcc-mean()-X<tr><th>1<td>2<td>tBodyAcc-mean()-Y<tr><th>2<td>3<td>tBodyAcc-mean()-Z<tr><th>3<td>4<td>tBodyAcc-std()-X<tr><th>4<td>5<td>tBodyAcc-std()-Y</table></div><p><br /></p><ul><li>(https://github.com/hmkim312/datas/blob/main/HAR){: target=”_blank”}</li><li>데이터는 깃헙에 올려둠</li><li>지금은 데이터의 특성이름만 load한것임</li></ul><p><br /></p><h3 id="26-특성의-갯수">2.6 특성의 갯수</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">feature_name_df</span><span class="p">))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>561
</pre></table></code></div></div><ul><li>전체 특성 (feature)만 561개로 엄청 많음</li></ul><p><br /></p><h3 id="27-특성의-종류">2.7 특성의 종류</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">feature_name</span> <span class="o">=</span> <span class="n">feature_name_df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">].</span><span class="n">values</span><span class="p">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">feature_name</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>['tBodyAcc-mean()-X',
 'tBodyAcc-mean()-Y',
 'tBodyAcc-mean()-Z',
 'tBodyAcc-std()-X',
 'tBodyAcc-std()-Y']
</pre></table></code></div></div><ul><li>평균, 표준편차, 최대값 등으로 이루어져있음</li></ul><p><br /></p><h3 id="28-x데이터-불러오기">2.8 X데이터 불러오기</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">X_train</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'https://raw.githubusercontent.com/hmkim312/datas/main/HAR/X_train.txt'</span><span class="p">,</span> <span class="n">sep</span> <span class="o">=</span> <span class="s">'\s+'</span><span class="p">,</span>  <span class="n">header</span> <span class="o">=</span> <span class="bp">None</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'https://raw.githubusercontent.com/hmkim312/datas/main/HAR/X_test.txt'</span><span class="p">,</span> <span class="n">sep</span> <span class="o">=</span> <span class="s">'\s+'</span><span class="p">,</span>  <span class="n">header</span> <span class="o">=</span> <span class="bp">None</span><span class="p">)</span>

<span class="n">X_train</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">feature_name</span>
<span class="n">X_test</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">feature_name</span>
<span class="n">X_train</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</pre></table></code></div></div><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><div style="width:100%; height:100%; overflow:auto"><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>tBodyAcc-mean()-X<th>tBodyAcc-mean()-Y<th>tBodyAcc-mean()-Z<th>tBodyAcc-std()-X<th>tBodyAcc-std()-Y<th>tBodyAcc-std()-Z<th>tBodyAcc-mad()-X<th>tBodyAcc-mad()-Y<th>tBodyAcc-mad()-Z<th>tBodyAcc-max()-X<th>...<th>fBodyBodyGyroJerkMag-meanFreq()<th>fBodyBodyGyroJerkMag-skewness()<th>fBodyBodyGyroJerkMag-kurtosis()<th>angle(tBodyAccMean,gravity)<th>angle(tBodyAccJerkMean),gravityMean)<th>angle(tBodyGyroMean,gravityMean)<th>angle(tBodyGyroJerkMean,gravityMean)<th>angle(X,gravityMean)<th>angle(Y,gravityMean)<th>angle(Z,gravityMean)<tbody><tr><th>0<td>0.288585<td>-0.020294<td>-0.132905<td>-0.995279<td>-0.983111<td>-0.913526<td>-0.995112<td>-0.983185<td>-0.923527<td>-0.934724<td>...<td>-0.074323<td>-0.298676<td>-0.710304<td>-0.112754<td>0.030400<td>-0.464761<td>-0.018446<td>-0.841247<td>0.179941<td>-0.058627<tr><th>1<td>0.278419<td>-0.016411<td>-0.123520<td>-0.998245<td>-0.975300<td>-0.960322<td>-0.998807<td>-0.974914<td>-0.957686<td>-0.943068<td>...<td>0.158075<td>-0.595051<td>-0.861499<td>0.053477<td>-0.007435<td>-0.732626<td>0.703511<td>-0.844788<td>0.180289<td>-0.054317<tr><th>2<td>0.279653<td>-0.019467<td>-0.113462<td>-0.995380<td>-0.967187<td>-0.978944<td>-0.996520<td>-0.963668<td>-0.977469<td>-0.938692<td>...<td>0.414503<td>-0.390748<td>-0.760104<td>-0.118559<td>0.177899<td>0.100699<td>0.808529<td>-0.848933<td>0.180637<td>-0.049118<tr><th>3<td>0.279174<td>-0.026201<td>-0.123283<td>-0.996091<td>-0.983403<td>-0.990675<td>-0.997099<td>-0.982750<td>-0.989302<td>-0.938692<td>...<td>0.404573<td>-0.117290<td>-0.482845<td>-0.036788<td>-0.012892<td>0.640011<td>-0.485366<td>-0.848649<td>0.181935<td>-0.047663<tr><th>4<td>0.276629<td>-0.016570<td>-0.115362<td>-0.998139<td>-0.980817<td>-0.990482<td>-0.998321<td>-0.979672<td>-0.990441<td>-0.942469<td>...<td>0.087753<td>-0.351471<td>-0.699205<td>0.123320<td>0.122542<td>0.693578<td>-0.615971<td>-0.847865<td>0.185151<td>-0.043892</table></div><p>5 rows × 561 columns</p></div><p><br /></p><ul><li>데이터는 깃헙에 따로 올려주었음</li><li>데이터 용량이 생각보다 커서 오래걸림</li><li>앞에서 불러온 feature_name을 컬럼으로 사용함</li></ul><h3 id="29-y데이터-불러오기">2.9 Y데이터 불러오기</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">y_train</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'https://raw.githubusercontent.com/hmkim312/datas/main/HAR/y_train.txt'</span><span class="p">,</span> <span class="n">sep</span> <span class="o">=</span> <span class="s">'\s+'</span><span class="p">,</span>  <span class="n">header</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s">'action'</span><span class="p">])</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'https://raw.githubusercontent.com/hmkim312/datas/main/HAR/y_test.txt'</span><span class="p">,</span> <span class="n">sep</span> <span class="o">=</span> <span class="s">'\s+'</span><span class="p">,</span>  <span class="n">header</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s">'action'</span><span class="p">])</span>
<span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test</span><span class="p">.</span><span class="n">shape</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>((7352, 561), (2947, 561), (7352, 1), (2947, 1))
</pre></table></code></div></div><ul><li>마찬가지로 y 데이터를 불러옴</li><li>전체 데이터는 약 1만개가 넘음</li></ul><p><br /></p><h3 id="210-액션별-데이터의-수">2.10 액션별 데이터의 수</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">y_train</span><span class="p">[</span><span class="s">'action'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre>6    1407
5    1374
4    1286
1    1226
2    1073
3     986
Name: action, dtype: int64
</pre></table></code></div></div><ul><li>총 6개의 액션 (앉기, 서기, 걷기, 계단 오르기, 계단 내려가기, 눕기)의 갯수</li><li>1 = Walking</li><li>2 = Walkling Upstairs</li><li>3 = Walking Downstairs</li><li>4 = Sitting</li><li>5 = Standing</li><li>6 = Laying</li></ul><p><br /></p><h3 id="211-decision-tree로-하기">2.11 Decision Tree로 하기</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="n">dt_clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">dt_clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">dt_clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>0.8096369189005769
</pre></table></code></div></div><ul><li>딱히 하이퍼파라미터 튜닝을 하지 않고 결정나무를 돌려봤을때 Accuracy는 0.8정도가 나옴</li></ul><p><br /></p><h3 id="212-gridsearch로-max_depth-설정">2.12 Gridsearch로 Max_depth 설정</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s">'max_depth'</span><span class="p">:</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">24</span><span class="p">]}</span>

<span class="n">grid_cv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">dt_clf</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">params</span><span class="p">,</span>
                       <span class="n">scoring</span><span class="o">=</span><span class="s">'accuracy'</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">grid_cv</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>GridSearchCV(cv=5,
             estimator=DecisionTreeClassifier(max_depth=4, random_state=13),
             param_grid={'max_depth': [6, 8, 10, 12, 16, 20, 24]},
             return_train_score=True, scoring='accuracy')
</pre></table></code></div></div><ul><li>GridSearchCV를 이용하여 6,8,10,12,16,20,24의 max_depth를 조절해서 가장 높은 Accuracy가 나오는 것을 구함</li></ul><p><br /></p><h3 id="213-best-score-및-param은">2.13 best score 및 param은?</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">grid_cv</span><span class="p">.</span><span class="n">best_score_</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>0.8543335321892183
</pre></table></code></div></div><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">grid_cv</span><span class="p">.</span><span class="n">best_params_</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>{'max_depth': 8}
</pre></table></code></div></div><ul><li>가장 좋은 Accuracy는 0.85가 나왔고, depth를 8로 했을때가 가장 좋음</li></ul><p><br /></p><h3 id="214-max_depth-별로-표로-성능을-정리">2.14 Max_depth 별로 표로 성능을 정리</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">cv_result_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">grid_cv</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">)</span>
<span class="n">cv_result_df</span><span class="p">[[</span><span class="s">'param_max_depth'</span><span class="p">,</span> <span class="s">'mean_test_score'</span><span class="p">,</span> <span class="s">'mean_train_score'</span><span class="p">]]</span>
</pre></table></code></div></div><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>param_max_depth<th>mean_test_score<th>mean_train_score<tbody><tr><th>0<td>6<td>0.843444<td>0.944879<tr><th>1<td>8<td>0.854334<td>0.982692<tr><th>2<td>10<td>0.847125<td>0.993369<tr><th>3<td>12<td>0.841958<td>0.997212<tr><th>4<td>16<td>0.841958<td>0.999660<tr><th>5<td>20<td>0.842365<td>0.999966<tr><th>6<td>24<td>0.841821<td>1.000000</table></div><p><br /></p><ul><li>train과 test score에 차이가 있음 과적합일수도 있음</li></ul><p><br /></p><h3 id="215-실제-test-데이터에서의-결과">2.15 실제 Test 데이터에서의 결과</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="n">max_depths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">24</span><span class="p">]</span>

<span class="k">for</span> <span class="n">depth</span> <span class="ow">in</span> <span class="n">max_depths</span><span class="p">:</span>
    <span class="n">dt_clf</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">depth</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
    <span class="n">dt_clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">dt_clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Max_depth = </span><span class="si">{</span><span class="n">depth</span><span class="si">}</span><span class="s">, Accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre>Max_depth = 6, Accuracy = 0.8554462164913471
Max_depth = 8, Accuracy = 0.8734306073973532
Max_depth = 10, Accuracy = 0.8615541228367831
Max_depth = 12, Accuracy = 0.8595181540549711
Max_depth = 16, Accuracy = 0.8669833729216152
Max_depth = 20, Accuracy = 0.8652867322701052
Max_depth = 24, Accuracy = 0.8652867322701052
</pre></table></code></div></div><ul><li>실제 Test 데이터로 해본 결과 가장 높은 0.87 Accuracy가 나왔다.</li></ul><p><br /></p><h3 id="216-베스트-모델의-결과">2.16 베스트 모델의 결과</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">best_df_clf</span> <span class="o">=</span> <span class="n">grid_cv</span><span class="p">.</span><span class="n">best_estimator_</span>
<span class="n">pred1</span> <span class="o">=</span> <span class="n">best_df_clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred1</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>0.8734306073973532
</pre></table></code></div></div><ul><li>생각보다 잘 나오지만 과적합 의심을 계속 해야함</li></ul><p><br /></p><h3 id="217-랜덤포레스트에-적용">2.17 랜덤포레스트에 적용</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'max_depth'</span><span class="p">:</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
    <span class="s">'n_estimators'</span> <span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span>
    <span class="s">'min_samples_leaf'</span> <span class="p">:</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">12</span><span class="p">],</span>
    <span class="s">'min_samples_split'</span> <span class="p">:</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">12</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">rf_clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span> <span class="mi">13</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">grid_cv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">rf_clf</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span> <span class="n">params</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">grid_cv</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>GridSearchCV(cv=2, estimator=RandomForestClassifier(n_jobs=-1, random_state=13),
             n_jobs=-1,
             param_grid={'max_depth': [6, 8, 10], 'min_samples_leaf': [6, 12],
                         'min_samples_split': [6, 12],
                         'n_estimators': [50, 100, 200]})
</pre></table></code></div></div><ul><li><p>똑같이 GridSearchCV를 이용하여 찾았으며 Cross Validation은 2로 설정하였다.</p></li><li>max_depth : int or None, optional (default=None)<ul><li>트리의 깊이</li><li>None 이면 최대한 깊게 (불순도 혹은 복잡도가 0일 때까지)</li><li>클수록 정확 (과대적합)</li><li>작을수록 가지치기 (과대적합 방지)</li></ul></li><li>max_leaf_nodes : int or None, optional (default=None)<ul><li>최대 몇개 잎 노드가 만들어 질때 까지 split(하위 (잎) 노드로 분리) 될지</li><li>클수록 정확 (과대적합)</li><li>작을수록 가지치기 (과대적합 방지)</li></ul></li><li>min_samples_split : int, float, optional (default=2)<ul><li>샘플이 최소한 몇개 이상이어야 split(하위 (잎) 노드로 분리) 할것인지</li><li>int일 경우 주어진 값을 그대로 사용, float일 경우 0에서 1사이의 값을 줄 수 있으며 전체 데이터 수 <code class="language-plaintext highlighter-rouge">*</code> min_sample_split의 값을 사용</li><li>클수록 가지치기 (과대적합 방지)</li><li>작을수록 정확 (과대적합)</li></ul></li><li>min_samples_leaf : int, float, optional (default=1)<ul><li>(잎) 노드가 되려면 가지고 있어야할 최소 샘플 수</li><li>클수록 가지치기 (과대적합 방지)</li><li>작을수록 정확 (과대적합)</li></ul></li></ul><p><br /></p><h3 id="218-결과-정리를-위한-작업">2.18 결과 정리를 위한 작업</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">cv_result_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">grid_cv</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">)</span>
<span class="n">cv_result_df</span><span class="p">.</span><span class="n">columns</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre>Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',
       'param_max_depth', 'param_min_samples_leaf', 'param_min_samples_split',
       'param_n_estimators', 'params', 'split0_test_score',
       'split1_test_score', 'mean_test_score', 'std_test_score',
       'rank_test_score'],
      dtype='object')
</pre></table></code></div></div><ul><li>결과를 데이터프레임으로 생성</li></ul><p><br /></p><h3 id="219-랜덤포레스트-성능-확인">2.19 랜덤포레스트 성능 확인</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">target_col</span> <span class="o">=</span> <span class="p">[</span><span class="s">'rank_test_score'</span><span class="p">,</span> <span class="s">'mean_test_score'</span><span class="p">,</span>
              <span class="s">'param_n_estimators'</span><span class="p">,</span> <span class="s">'param_max_depth'</span><span class="p">]</span>

<span class="n">cv_result_df</span><span class="p">[</span><span class="n">target_col</span><span class="p">].</span><span class="n">sort_values</span><span class="p">(</span><span class="s">'rank_test_score'</span><span class="p">).</span><span class="n">head</span><span class="p">()</span>
</pre></table></code></div></div><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>rank_test_score<th>mean_test_score<th>param_n_estimators<th>param_max_depth<tbody><tr><th>23<td>1<td>0.912813<td>200<td>8<tr><th>20<td>1<td>0.912813<td>200<td>8<tr><th>35<td>3<td>0.912541<td>200<td>10<tr><th>32<td>3<td>0.912541<td>200<td>10<tr><th>29<td>5<td>0.911725<td>200<td>10</table></div><ul><li>Max_depth는 8과 분류기는 200개를 사용하는게 가장 높은 결과를 가져옴</li><li>의사결정나무보다 성능이 좋게 나옴</li></ul><p><br /></p><h3 id="220-랜덤-포레스트의-best-모델">2.20 랜덤 포레스트의 Best 모델</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">grid_cv</span><span class="p">.</span><span class="n">best_params_</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>{'max_depth': 8,
 'min_samples_leaf': 12,
 'min_samples_split': 6,
 'n_estimators': 200}
</pre></table></code></div></div><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">grid_cv</span><span class="p">.</span><span class="n">best_estimator_</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>RandomForestClassifier(max_depth=8, min_samples_leaf=12, min_samples_split=6,
                       n_estimators=200, n_jobs=-1, random_state=13)
</pre></table></code></div></div><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">grid_cv</span><span class="p">.</span><span class="n">best_score_</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>0.9128128400435256
</pre></table></code></div></div><p><br /></p><ul><li>랜덤포레스트의 베스트 모델은</li><li>Max_depth가 8이고 최소 노드가 되기위한 샘플 수는 6개, 최소 노드는 12개의 파라미터가 나왔음</li></ul><p><br /></p><h3 id="221-test-데이터에-적용">2.21 test 데이터에 적용</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">rf_clf_best</span> <span class="o">=</span> <span class="n">grid_cv</span><span class="p">.</span><span class="n">best_estimator_</span>
<span class="n">rf_clf_best</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">pred1</span> <span class="o">=</span> <span class="n">rf_clf_best</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred1</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>0.9121140142517815
</pre></table></code></div></div><ul><li>베스트 모델을 Test 데이터에 적용해도 의사결정 나무보다 더 높은 Accuracy를 보여줌</li></ul><p><br /></p><h3 id="222-중요-특성-확인">2.22 중요 특성 확인</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">best_cols_values</span> <span class="o">=</span> <span class="n">rf_clf_best</span><span class="p">.</span><span class="n">feature_importances_</span>
<span class="n">best_cols</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">best_cols_values</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">top20_cols</span> <span class="o">=</span> <span class="n">best_cols</span><span class="p">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)[:</span><span class="mi">20</span><span class="p">]</span>
<span class="n">top20_cols</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre><td class="rouge-code"><pre>tGravityAcc-max()-X                0.033146
angle(X,gravityMean)               0.031783
tGravityAcc-mean()-X               0.031114
angle(Y,gravityMean)               0.028749
tGravityAcc-min()-X                0.028376
tGravityAcc-mean()-Y               0.027525
tGravityAcc-max()-Y                0.026787
tGravityAcc-energy()-X             0.024104
tGravityAcc-min()-Y                0.023466
tGravityAcc-energy()-Y             0.019362
tBodyAcc-max()-X                   0.013909
tGravityAcc-mean()-Z               0.013876
tBodyAccMag-std()                  0.013222
tGravityAcc-max()-Z                0.012954
fBodyAccJerk-bandsEnergy()-1,8     0.011679
fBodyAccJerk-bandsEnergy()-1,24    0.011569
tGravityAcc-min()-Z                0.010980
tBodyAccJerk-entropy()-X           0.010875
tBodyAccMag-mad()                  0.010858
tGravityAcc-arCoeff()-Z,2          0.010688
dtype: float64
</pre></table></code></div></div><ul><li>feature_importances_ 메서드로 결과에 영향을 미친 특성을 볼수있음</li><li>전체 특성이 561개나 되기때문에 각 개의 특성은 큰 값을 가지진 못함</li></ul><p><br /></p><h3 id="223-주요-특성-그래프">2.23 주요 특성 그래프</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">top20_cols</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">top20_cols</span><span class="p">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/95834419-e473dd80-0d77-11eb-8ec5-ec7f1e753213.png" /></p><ul><li>주요 특성 20개를 그래프화 함</li><li>tGravityAcc-max()-X 특성이 제일 중요하게 나옴</li></ul><p><br /></p><h3 id="224-주요-20개-특성만-가지고-다시-성능-확인">2.24 주요 20개 특성만 가지고 다시 성능 확인</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="n">X_train_re</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">top20_cols</span><span class="p">.</span><span class="n">index</span><span class="p">]</span>
<span class="n">X_test_re</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[</span><span class="n">top20_cols</span><span class="p">.</span><span class="n">index</span><span class="p">]</span>

<span class="n">rf_clf_best_re</span> <span class="o">=</span> <span class="n">grid_cv</span><span class="p">.</span><span class="n">best_estimator_</span>
<span class="n">rf_clf_best_re</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_re</span><span class="p">,</span> <span class="n">y_train</span><span class="p">.</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">))</span>

<span class="n">pred1_re</span> <span class="o">=</span> <span class="n">rf_clf_best_re</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_re</span><span class="p">)</span>

<span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred1_re</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>0.8096369189005769
</pre></table></code></div></div><ul><li>561개 특성보다 20개 특성으로하니 모델 학습 및 예측에는 오래걸리진 않지만, acc가 떨어짐</li></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/data-science/'>Data Science</a>, <a href='/categories/machine-learning/'>Machine Learning</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/random-forest/" class="post-tag no-text-decoration" >Random Forest</a> <a href="/tags/gridsearch/" class="post-tag no-text-decoration" >GridSearch</a> <a href="/tags/har/" class="post-tag no-text-decoration" >HAR</a> <a href="/tags/important-feature/" class="post-tag no-text-decoration" >Important Feature</a> <a href="/tags/voting/" class="post-tag no-text-decoration" >Voting</a> <a href="/tags/bagging/" class="post-tag no-text-decoration" >Bagging</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><!-- Post sharing snippet v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=앙상블(Ensemble) - Data Include Me&url=https://datainclude.me/posts/%EC%95%99%EC%83%81%EB%B8%94(ensemble)/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=앙상블(Ensemble) - Data Include Me&u=https://datainclude.me/posts/%EC%95%99%EC%83%81%EB%B8%94(ensemble)/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=앙상블(Ensemble) - Data Include Me&url=https://datainclude.me/posts/%EC%95%99%EC%83%81%EB%B8%94(ensemble)/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><!-- The Panel on right side (Desktop views) v2.3 © 2024 Your Name MIT License --><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><h3 data-toc-skip>Recent Update</h3><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li class="recent-item"> <a href="/posts/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C_%EC%BB%B4%ED%93%A8%ED%8C%85_%EA%B0%80%EC%83%81%ED%99%94/">클라우드 컴퓨팅 - 가상화</a> <span class="text-muted small">2024-10-28</span></li><li class="recent-item"> <a href="/posts/gemini_api_%EC%82%AC%EC%9A%A9%ED%95%B4%EB%B3%B4%EA%B8%B0/">Gemini API 사용해보기</a> <span class="text-muted small">2024-03-12</span></li><li class="recent-item"> <a href="/posts/Ollama%EC%99%80_Python_%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC_LLaMa2%EB%A5%BC_%EB%A1%9C%EC%BB%AC%EC%97%90%EC%84%9C_%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/">Ollama와 Python 라이브러리를 이용하여 LLaMa2를 로컬에서 사용하기</a> <span class="text-muted small">2024-02-13</span></li><li class="recent-item"> <a href="/posts/Mistral_7B_Fine_Tuning/">Mistral 7B 파인튜닝(Fine Tuning)하기</a> <span class="text-muted small">2023-10-25</span></li><li class="recent-item"> <a href="/posts/Penn_Fudan%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EA%B0%9D%EC%B2%B4_%ED%83%90%EC%A7%80_%EB%B6%84%ED%95%A0/">Penn-Fudan으로 알아보는 객체 탐지(Object Detection), 분할(Segmentation) with FasterRCNN</a> <span class="text-muted small">2023-10-23</span></li></ul></div><div id="access-tags"><h3 data-toc-skip>Trending Tags</h3><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/tensorflow/">Tensorflow</a> <a class="post-tag" href="/tags/sklearn/">Sklearn</a> <a class="post-tag" href="/tags/round/">Round</a> <a class="post-tag" href="/tags/python-lv0/">Python Lv0</a> <a class="post-tag" href="/tags/pca/">PCA</a> <a class="post-tag" href="/tags/eda/">EDA</a> <a class="post-tag" href="/tags/distinct/">Distinct</a> <a class="post-tag" href="/tags/random-forest/">Random Forest</a> <a class="post-tag" href="/tags/beautifulsoup/">Beautifulsoup</a> <a class="post-tag" href="/tags/baekjoon/">Baekjoon</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><h3 data-toc-skip class="pl-3 pt-2 mb-2">Contents</h3><nav id="toc" data-toggle="toc"></nav></div></div><style> .recent-item { margin-bottom: 0.5rem; } .recent-item a { color: var(--link-color); } .recent-item .small { font-size: 0.75rem; margin-left: 0.5rem; }</style></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"> <!-- Recommend the other 3 posts according to the tags and categories of the current post, if the number is not enough, use the other latest posts to supplement. v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/%EC%99%80%EC%9D%B8_%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_%EB%B6%80%EC%8A%A4%ED%8C%85_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98_Boosting_Algorithm_/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Oct 23, 2020 <i class="unloaded">2020-10-23T09:10:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>와인데이터로 해보는 부스팅 알고리즘(Boosting Algorithm)</h3><div class="text-muted small"><p> 1. 앙상블 1.1 앙상블이란 앙상블은 전통적으로 Voting, Bagging, Boosting, 스태깅으로 나뉨 보팅과 배깅은 여러개의 분류기가 투표를 통해 최종 예측 결과를 결정하는 방식임 보팅과 배깅의 차이점은 보팅은 각각 다른 분류기, 배깅은 같은 분류기를 사용함 대표적인 배깅은 랜덤 포레스트 1.2 Boosting의...</p></div></div></a></div><div class="card"> <a href="/posts/IBM_HR_Data%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_%ED%87%B4%EC%82%AC%EC%9E%90_%EC%98%88%EC%B8%A1/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Jun 2, 2021 <i class="unloaded">2021-06-02T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>IBM HR Data로 해보는 퇴사자 예측</h3><div class="text-muted small"><p> Predicting Employee Attrition IBM 데이터 과학자들이 만든 가상의 HR 데이터셋입니다. 1,470명에 대한 35개의 변수가 기록되어 있고, 종속변수는 Attrition, 즉 0 또는 1의 퇴사 여부입니다. Data Source: https://www.kaggle.com/pavansubhasht/ibm-hr-an...</p></div></div></a></div><div class="card"> <a href="/posts/%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1%ED%9A%8C%EA%B7%80_(Logistic_Regression)/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Oct 12, 2020 <i class="unloaded">2020-10-12T21:10:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>로지스틱 회귀 (Logistic Regression)</h3><div class="text-muted small"><p> 1. 로지스틱 회귀 (Logistic Regression) 1.1 분류? 회귀? 악성 종양을 찾는 문제 0.5보다 크거나 같으면 1(악성)으로 예측 0.5보다 작으면 0(양성)으로 예측 1.2 Linear Regression을 분류 문제에 적용? 회귀는 0보다 작은수, 1보다 큰수가 나오므로 그대로 분류문제에 사용할수...</p></div></div></a></div></div></div><!-- Navigation buttons at the bottom of the post. v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --><div class="post-navigation d-flex justify-content-between"> <a href="/posts/%EB%82%98%EC%9D%B4%EB%B8%8C_%EB%B2%A0%EC%9D%B4%EC%A7%80%EC%95%88%EC%9C%BC%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_NLTK/" class="btn btn-outline-primary"><p>나이브 베이지안 분류기(Naive Bayes Classifier)으로 해보는 NLTK</p></a> <a href="/posts/%ED%81%AC%EB%A1%A4%EB%A7%81(Crawling)_%EA%B8%B0%EC%B4%88(1)/" class="btn btn-outline-primary"><p>크롤링(Crawling) 기초(1)</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('#post-wrapper img'); const observer = lozad(imgs); observer.observe(); </script></div><!-- The Search results v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/tensorflow/">Tensorflow</a> <a class="post-tag" href="/tags/sklearn/">Sklearn</a> <a class="post-tag" href="/tags/round/">Round</a> <a class="post-tag" href="/tags/python-lv0/">Python Lv0</a> <a class="post-tag" href="/tags/pca/">PCA</a> <a class="post-tag" href="/tags/eda/">EDA</a> <a class="post-tag" href="/tags/distinct/">Distinct</a> <a class="post-tag" href="/tags/random-forest/">Random Forest</a> <a class="post-tag" href="/tags/beautifulsoup/">Beautifulsoup</a> <a class="post-tag" href="/tags/baekjoon/">Baekjoon</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <!-- The GA snippet v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <!-- Jekyll Simple Search loader v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://datainclude.me{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script>
