<!DOCTYPE html><html lang="ko" mode="light" > <!-- The Head v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Porto Seguro’s Safe Driver Prediction 데이터 Preparation & Exploration | Data Include Me</title><meta name="generator" content="Jekyll v3.9.3" /><meta property="og:title" content="Porto Seguro’s Safe Driver Prediction 데이터 Preparation &amp; Exploration" /><meta name="author" content="HyunMin Kim" /><meta property="og:locale" content="ko" /><meta name="description" content="1. Porto Seguro Safe Driver Prediction 1.1 Porto Seguro Safe Driver Prediction Porto Seguro는 브라질의 자동차 보험회사로, 어떤 차주가 내년에 보험을 청구할지에 대한 예측을 하는것 https://www.kaggle.com/c/porto-seguro-safe-driver-prediction" /><meta property="og:description" content="1. Porto Seguro Safe Driver Prediction 1.1 Porto Seguro Safe Driver Prediction Porto Seguro는 브라질의 자동차 보험회사로, 어떤 차주가 내년에 보험을 청구할지에 대한 예측을 하는것 https://www.kaggle.com/c/porto-seguro-safe-driver-prediction" /><link rel="canonical" href="https://datainclude.me/posts/Data_Preparation_and_Exploration/" /><meta property="og:url" content="https://datainclude.me/posts/Data_Preparation_and_Exploration/" /><meta property="og:site_name" content="Data Include Me" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-11-09T00:30:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Porto Seguro’s Safe Driver Prediction 데이터 Preparation &amp; Exploration" /><meta name="twitter:site" content="@" /><meta name="twitter:creator" content="@HyunMin Kim" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"HyunMin Kim"},"dateModified":"2020-11-09T00:30:00+09:00","datePublished":"2020-11-09T00:30:00+09:00","description":"1. Porto Seguro Safe Driver Prediction 1.1 Porto Seguro Safe Driver Prediction Porto Seguro는 브라질의 자동차 보험회사로, 어떤 차주가 내년에 보험을 청구할지에 대한 예측을 하는것 https://www.kaggle.com/c/porto-seguro-safe-driver-prediction","headline":"Porto Seguro’s Safe Driver Prediction 데이터 Preparation &amp; Exploration","mainEntityOfPage":{"@type":"WebPage","@id":"https://datainclude.me/posts/Data_Preparation_and_Exploration/"},"url":"https://datainclude.me/posts/Data_Preparation_and_Exploration/"}</script><meta property="og:image" content="https://datainclude.me/assets/img/sample/avatar.jpg" /> <!-- The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps Generated by: https://www.favicon-generator.org/ v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT license --><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="36x36" href="/assets/img/favicons/android-icon-36x36.png"><link rel="icon" type="image/png" sizes="48x48" href="/assets/img/favicons/android-icon-48x48.png"><link rel="icon" type="image/png" sizes="72x72" href="/assets/img/favicons/android-icon-72x72.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/android-icon-96x96.png"><link rel="icon" type="image/png" sizes="144x144" href="/assets/img/favicons/android-icon-144x144.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="70x70" href="/assets/img/favicons/ms-icon-70x70.png"><link rel="icon" type="image/png" sizes="144x144" href="/assets/img/favicons/ms-icon-144x144.png"><link rel="icon" type="image/png" sizes="150x150" href="/assets/img/favicons/ms-icon-150x150.png"><link rel="icon" type="image/png" sizes="310x310" href="/assets/img/favicons/ms-icon-310x310.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preload" href="https://www.googletagmanager.com/gtm.js?id=GTM-MW9VRMW9" as="script"> <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src= 'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f); })(window,document,'script','dataLayer','GTM-MW9VRMW9');</script><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="preload" as="style" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous" media="print" onload="this.media='all'"> <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"> </noscript> <!-- CSS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --><link rel="preload" as="style" href="/assets/css/post.css"><link rel="stylesheet" href="/assets/css/post.css"><link rel="preload" as="style" href="/assets/css/lib/bootstrap-toc.min.css"><link rel="stylesheet" href="/assets/css/lib/bootstrap-toc.min.css" /><link rel="preload" as="script" href="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" async></script> <!-- JS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --> <script src="/assets/js/post.min.js" async></script> <script src="/app.js" defer></script><body data-spy="scroll" data-target="#toc"> <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MW9VRMW9" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="sidebar" class="d-flex flex-column"> <!-- The Side Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="nav-wrapper"><div id="profile-wrapper" class="d-flex flex-column"><div id="avatar" class="d-flex justify-content-center"> <a href="/" alt="avatar"> <img src="/assets/img/sample/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="profile-text mt-3"><div class="site-title"> <a href="/">Data Include Me</a></div><div class="site-subtitle font-italic">Data Science Blog</div></div></div><ul class="nav flex-column"><li class="nav-item d-flex justify-content-center "> <a href="/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/categories/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/tags/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/archives/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/about/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></li></ul></div><div class="sidebar-bottom d-flex flex-wrap justify-content-around mt-4"> <a href="https://github.com/hmkim312" target="_blank"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/" target="_blank"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:window.open('mailto:' + ['sanarial312','gmail.com'].join('@'))" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" > <i class="fas fa-rss"></i> </a></div></div><!-- The Top Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Porto Seguro’s Safe Driver Prediction 데이터 Preparation & Exploration</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"> <!-- Refactor the HTML structure. --> <!-- Suroundding the markdown table with '<div class="table-wrapper">. and '</div>' --> <!-- Fixed kramdown code highlight rendering: https://github.com/penibelst/jekyll-compress-html/issues/101 https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901 --><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"> <script type="text/javascript"> var lazyloadads = false; function loadAds() { if (!lazyloadads) { var script = document.createElement("script"); script.type = "text/javascript"; script.async = true; script.src = "https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7594406644928408"; document.body.appendChild(script); lazyloadads = true; } } window.addEventListener("mousemove", loadAds, { once: true }); window.addEventListener('touchstart', loadAds, { once: true }); </script><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Porto Seguro’s Safe Driver Prediction 데이터 Preparation & Exploration</h1><div class="post-meta text-muted d-flex flex-column"><div> Posted <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Mon, Nov 9, 2020, 12:30 AM +0900" > Nov 9, 2020 <i class="unloaded">2020-11-09T00:30:00+09:00</i> </span> by <span class="author"> HyunMin Kim </span></div><a href="https://hits.seeyoufarm.com"> <img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https://datainclude.me/posts/Data_Preparation_and_Exploration/%2F&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=views&edge_flat=false" alt="페이지 조회수 뱃지", width: 100%;, height: 100%;/> </a></div><div class="post-content"><h2 id="1-porto-seguro-safe-driver-prediction">1. Porto Seguro Safe Driver Prediction</h2><hr /><h3 id="11-porto-seguro-safe-driver-prediction">1.1 Porto Seguro Safe Driver Prediction</h3><ul><li>Porto Seguro는 브라질의 자동차 보험회사로, 어떤 차주가 내년에 보험을 청구할지에 대한 예측을 하는것</li><li><a href="https://www.kaggle.com/c/porto-seguro-safe-driver-prediction" target="_blank">https://www.kaggle.com/c/porto-seguro-safe-driver-prediction</a></li></ul><p><br /></p><h2 id="2-introduction">2. Introduction</h2><hr /><h3 id="21-introduction">2.1 Introduction</h3><ul><li>이 노트북은 PorteSeguro 대회의 데이터에서 좋은 통찰력을 얻는 것을 목표로합니다. 그 외에도 모델링을 위해 데이터를 준비하는 몇 가지 팁과 요령을 제공합니다. 노트북은 다음과 같은 주요 섹션으로 구성됩니다.</li></ul><p><br /></p><h3 id="22-sections">2.2 Sections</h3><ul><li>Visual inspection of your data</li><li>Defining the metadata</li><li>Descriptive statistics</li><li>Handling imbalanced classes</li><li>Data quality checks</li><li>Exploratory data visualization</li><li>Feature engineering</li><li>Feature selection</li><li>Feature scaling</li><li>Loading packages</li></ul><p><br /></p><h3 id="23-출처">2.3 출처</h3><ul><li><a href="https://www.kaggle.com/bertcarremans/data-preparation-exploration" target="_blank">https://www.kaggle.com/bertcarremans/data-preparation-exploration</a></li></ul><p><br /></p><h2 id="3-loading-packages">3. Loading packages</h2><hr /><h3 id="31-패키지-로드">3.1 패키지 로드</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="c1">#from sklearn.preprocessing import Imputer
</span><span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">VarianceThreshold</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectFromModel</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">shuffle</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="n">pd</span><span class="p">.</span><span class="n">set_option</span><span class="p">(</span><span class="s">'display.max_columns'</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
</pre></table></code></div></div><p><br /></p><h2 id="4-visual-inspection-of-your-data">4. Visual inspection of your data</h2><hr /><h3 id="41-data-load">4.1 Data Load</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'https://media.githubusercontent.com/media/hmkim312/datas/main/porto-seguro-safe-driver-prediction/train.csv'</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'https://media.githubusercontent.com/media/hmkim312/datas/main/porto-seguro-safe-driver-prediction/test.csv'</span><span class="p">)</span>
</pre></table></code></div></div><p><br /></p><h3 id="42-data-at-first-sight">4.2 Data at first sight</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">train</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</pre></table></code></div></div><div style="width:100%; height:200px; overflow:auto"><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>id<th>target<th>ps_ind_01<th>ps_ind_02_cat<th>ps_ind_03<th>ps_ind_04_cat<th>ps_ind_05_cat<th>ps_ind_06_bin<th>ps_ind_07_bin<th>ps_ind_08_bin<th>ps_ind_09_bin<th>ps_ind_10_bin<th>ps_ind_11_bin<th>ps_ind_12_bin<th>ps_ind_13_bin<th>ps_ind_14<th>ps_ind_15<th>ps_ind_16_bin<th>ps_ind_17_bin<th>ps_ind_18_bin<th>ps_reg_01<th>ps_reg_02<th>ps_reg_03<th>ps_car_01_cat<th>ps_car_02_cat<th>ps_car_03_cat<th>ps_car_04_cat<th>ps_car_05_cat<th>ps_car_06_cat<th>ps_car_07_cat<th>ps_car_08_cat<th>ps_car_09_cat<th>ps_car_10_cat<th>ps_car_11_cat<th>ps_car_11<th>ps_car_12<th>ps_car_13<th>ps_car_14<th>ps_car_15<th>ps_calc_01<th>ps_calc_02<th>ps_calc_03<th>ps_calc_04<th>ps_calc_05<th>ps_calc_06<th>ps_calc_07<th>ps_calc_08<th>ps_calc_09<th>ps_calc_10<th>ps_calc_11<th>ps_calc_12<th>ps_calc_13<th>ps_calc_14<th>ps_calc_15_bin<th>ps_calc_16_bin<th>ps_calc_17_bin<th>ps_calc_18_bin<th>ps_calc_19_bin<th>ps_calc_20_bin<tbody><tr><th>0<td>7<td>0<td>2<td>2<td>5<td>1<td>0<td>0<td>1<td>0<td>0<td>0<td>0<td>0<td>0<td>0<td>11<td>0<td>1<td>0<td>0.7<td>0.2<td>0.718070<td>10<td>1<td>-1<td>0<td>1<td>4<td>1<td>0<td>0<td>1<td>12<td>2<td>0.400000<td>0.883679<td>0.370810<td>3.605551<td>0.6<td>0.5<td>0.2<td>3<td>1<td>10<td>1<td>10<td>1<td>5<td>9<td>1<td>5<td>8<td>0<td>1<td>1<td>0<td>0<td>1<tr><th>1<td>9<td>0<td>1<td>1<td>7<td>0<td>0<td>0<td>0<td>1<td>0<td>0<td>0<td>0<td>0<td>0<td>3<td>0<td>0<td>1<td>0.8<td>0.4<td>0.766078<td>11<td>1<td>-1<td>0<td>-1<td>11<td>1<td>1<td>2<td>1<td>19<td>3<td>0.316228<td>0.618817<td>0.388716<td>2.449490<td>0.3<td>0.1<td>0.3<td>2<td>1<td>9<td>5<td>8<td>1<td>7<td>3<td>1<td>1<td>9<td>0<td>1<td>1<td>0<td>1<td>0<tr><th>2<td>13<td>0<td>5<td>4<td>9<td>1<td>0<td>0<td>0<td>1<td>0<td>0<td>0<td>0<td>0<td>0<td>12<td>1<td>0<td>0<td>0.0<td>0.0<td>-1.000000<td>7<td>1<td>-1<td>0<td>-1<td>14<td>1<td>1<td>2<td>1<td>60<td>1<td>0.316228<td>0.641586<td>0.347275<td>3.316625<td>0.5<td>0.7<td>0.1<td>2<td>2<td>9<td>1<td>8<td>2<td>7<td>4<td>2<td>7<td>7<td>0<td>1<td>1<td>0<td>1<td>0<tr><th>3<td>16<td>0<td>0<td>1<td>2<td>0<td>0<td>1<td>0<td>0<td>0<td>0<td>0<td>0<td>0<td>0<td>8<td>1<td>0<td>0<td>0.9<td>0.2<td>0.580948<td>7<td>1<td>0<td>0<td>1<td>11<td>1<td>1<td>3<td>1<td>104<td>1<td>0.374166<td>0.542949<td>0.294958<td>2.000000<td>0.6<td>0.9<td>0.1<td>2<td>4<td>7<td>1<td>8<td>4<td>2<td>2<td>2<td>4<td>9<td>0<td>0<td>0<td>0<td>0<td>0<tr><th>4<td>17<td>0<td>0<td>2<td>0<td>1<td>0<td>1<td>0<td>0<td>0<td>0<td>0<td>0<td>0<td>0<td>9<td>1<td>0<td>0<td>0.7<td>0.6<td>0.840759<td>11<td>1<td>-1<td>0<td>-1<td>14<td>1<td>1<td>2<td>1<td>82<td>3<td>0.316070<td>0.565832<td>0.365103<td>2.000000<td>0.4<td>0.6<td>0.0<td>2<td>2<td>6<td>3<td>10<td>2<td>12<td>3<td>1<td>1<td>3<td>0<td>0<td>0<td>1<td>1<td>0</table></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">train</span><span class="p">.</span><span class="n">tail</span><span class="p">()</span>
</pre></table></code></div></div><div style="width:100%; height:200px; overflow:auto"><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>id<th>target<th>ps_ind_01<th>ps_ind_02_cat<th>ps_ind_03<th>ps_ind_04_cat<th>ps_ind_05_cat<th>ps_ind_06_bin<th>ps_ind_07_bin<th>ps_ind_08_bin<th>ps_ind_09_bin<th>ps_ind_10_bin<th>ps_ind_11_bin<th>ps_ind_12_bin<th>ps_ind_13_bin<th>ps_ind_14<th>ps_ind_15<th>ps_ind_16_bin<th>ps_ind_17_bin<th>ps_ind_18_bin<th>ps_reg_01<th>ps_reg_02<th>ps_reg_03<th>ps_car_01_cat<th>ps_car_02_cat<th>ps_car_03_cat<th>ps_car_04_cat<th>ps_car_05_cat<th>ps_car_06_cat<th>ps_car_07_cat<th>ps_car_08_cat<th>ps_car_09_cat<th>ps_car_10_cat<th>ps_car_11_cat<th>ps_car_11<th>ps_car_12<th>ps_car_13<th>ps_car_14<th>ps_car_15<th>ps_calc_01<th>ps_calc_02<th>ps_calc_03<th>ps_calc_04<th>ps_calc_05<th>ps_calc_06<th>ps_calc_07<th>ps_calc_08<th>ps_calc_09<th>ps_calc_10<th>ps_calc_11<th>ps_calc_12<th>ps_calc_13<th>ps_calc_14<th>ps_calc_15_bin<th>ps_calc_16_bin<th>ps_calc_17_bin<th>ps_calc_18_bin<th>ps_calc_19_bin<th>ps_calc_20_bin<tbody><tr><th>595207<td>1488013<td>0<td>3<td>1<td>10<td>0<td>0<td>0<td>0<td>0<td>1<td>0<td>0<td>0<td>0<td>0<td>13<td>1<td>0<td>0<td>0.5<td>0.3<td>0.692820<td>10<td>1<td>-1<td>0<td>1<td>1<td>1<td>1<td>0<td>1<td>31<td>3<td>0.374166<td>0.684631<td>0.385487<td>2.645751<td>0.4<td>0.5<td>0.3<td>3<td>0<td>9<td>0<td>9<td>1<td>12<td>4<td>1<td>9<td>6<td>0<td>1<td>1<td>0<td>1<td>1<tr><th>595208<td>1488016<td>0<td>5<td>1<td>3<td>0<td>0<td>0<td>0<td>0<td>1<td>0<td>0<td>0<td>0<td>0<td>6<td>1<td>0<td>0<td>0.9<td>0.7<td>1.382027<td>9<td>1<td>-1<td>0<td>-1<td>15<td>0<td>0<td>2<td>1<td>63<td>2<td>0.387298<td>0.972145<td>-1.000000<td>3.605551<td>0.2<td>0.2<td>0.0<td>2<td>4<td>8<td>6<td>8<td>2<td>12<td>4<td>1<td>3<td>8<td>1<td>0<td>1<td>0<td>1<td>1<tr><th>595209<td>1488017<td>0<td>1<td>1<td>10<td>0<td>0<td>1<td>0<td>0<td>0<td>0<td>0<td>0<td>0<td>0<td>12<td>1<td>0<td>0<td>0.9<td>0.2<td>0.659071<td>7<td>1<td>-1<td>0<td>-1<td>1<td>1<td>1<td>2<td>1<td>31<td>3<td>0.397492<td>0.596373<td>0.398748<td>1.732051<td>0.4<td>0.0<td>0.3<td>3<td>2<td>7<td>4<td>8<td>0<td>10<td>3<td>2<td>2<td>6<td>0<td>0<td>1<td>0<td>0<td>0<tr><th>595210<td>1488021<td>0<td>5<td>2<td>3<td>1<td>0<td>0<td>0<td>1<td>0<td>0<td>0<td>0<td>0<td>0<td>12<td>1<td>0<td>0<td>0.9<td>0.4<td>0.698212<td>11<td>1<td>-1<td>0<td>-1<td>11<td>1<td>1<td>2<td>1<td>101<td>3<td>0.374166<td>0.764434<td>0.384968<td>3.162278<td>0.0<td>0.7<td>0.0<td>4<td>0<td>9<td>4<td>9<td>2<td>11<td>4<td>1<td>4<td>2<td>0<td>1<td>1<td>1<td>0<td>0<tr><th>595211<td>1488027<td>0<td>0<td>1<td>8<td>0<td>0<td>1<td>0<td>0<td>0<td>0<td>0<td>0<td>0<td>0<td>7<td>1<td>0<td>0<td>0.1<td>0.2<td>-1.000000<td>7<td>0<td>-1<td>0<td>-1<td>0<td>1<td>0<td>2<td>1<td>34<td>2<td>0.400000<td>0.932649<td>0.378021<td>3.741657<td>0.4<td>0.0<td>0.5<td>2<td>3<td>10<td>4<td>10<td>2<td>5<td>4<td>4<td>3<td>8<td>0<td>1<td>0<td>0<td>0<td>0</table></div><ul><li>유사한 그룹에 속하는 기능은 기능 이름 (예 : ind, reg, car, calc)에 태그가 지정됩니다.</li><li>기능 이름에는 이진 기능을 나타내는 접미사 bin과 범주 기능을 나타내는 cat이 포함됩니다.</li><li>이러한 지정이없는 특징은 연속 형이거나 순서 형입니다.</li><li>-1 값은 관측치에서 피쳐가 누락되었음을 나타냅니다.</li><li>target 열은 해당 보험 계약자에 대한 청구가 접수되었는지 여부를 나타냅니다.</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">train</span><span class="p">.</span><span class="n">shape</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>(595212, 59)
</pre></table></code></div></div><ul><li>Train Data는 59개의 Column과 595,212개의 Row로 이루어져있습니다.</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">train</span><span class="p">.</span><span class="n">drop_duplicates</span><span class="p">()</span>
<span class="n">train</span><span class="p">.</span><span class="n">shape</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>(595212, 59)
</pre></table></code></div></div><ul><li>중복된 데이터가 있는지 확인하기 위해 drop_duplicates를 해보았고, 중복된 데이터는 없는것을 확인하였습니다.</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">test</span><span class="p">.</span><span class="n">shape</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>(892816, 58)
</pre></table></code></div></div><ul><li>Test data는 Train data와 비교하여 1개의 column이 부족하지만, 이것은 target column입니다.</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">train</span><span class="p">.</span><span class="n">info</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
</pre><td class="rouge-code"><pre>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 595212 entries, 0 to 595211
Data columns (total 59 columns):
 #   Column          Non-Null Count   Dtype  
---  ------          --------------   -----  
 0   id              595212 non-null  int64  
 1   target          595212 non-null  int64  
 2   ps_ind_01       595212 non-null  int64  
 3   ps_ind_02_cat   595212 non-null  int64  
 4   ps_ind_03       595212 non-null  int64  
 5   ps_ind_04_cat   595212 non-null  int64  
 6   ps_ind_05_cat   595212 non-null  int64  
 7   ps_ind_06_bin   595212 non-null  int64  
 8   ps_ind_07_bin   595212 non-null  int64  
 9   ps_ind_08_bin   595212 non-null  int64  
 10  ps_ind_09_bin   595212 non-null  int64  
 11  ps_ind_10_bin   595212 non-null  int64  
 12  ps_ind_11_bin   595212 non-null  int64  
 13  ps_ind_12_bin   595212 non-null  int64  
 14  ps_ind_13_bin   595212 non-null  int64  
 15  ps_ind_14       595212 non-null  int64  
 16  ps_ind_15       595212 non-null  int64  
 17  ps_ind_16_bin   595212 non-null  int64  
 18  ps_ind_17_bin   595212 non-null  int64  
 19  ps_ind_18_bin   595212 non-null  int64  
 20  ps_reg_01       595212 non-null  float64
 21  ps_reg_02       595212 non-null  float64
 22  ps_reg_03       595212 non-null  float64
 23  ps_car_01_cat   595212 non-null  int64  
 24  ps_car_02_cat   595212 non-null  int64  
 25  ps_car_03_cat   595212 non-null  int64  
 26  ps_car_04_cat   595212 non-null  int64  
 27  ps_car_05_cat   595212 non-null  int64  
 28  ps_car_06_cat   595212 non-null  int64  
 29  ps_car_07_cat   595212 non-null  int64  
 30  ps_car_08_cat   595212 non-null  int64  
 31  ps_car_09_cat   595212 non-null  int64  
 32  ps_car_10_cat   595212 non-null  int64  
 33  ps_car_11_cat   595212 non-null  int64  
 34  ps_car_11       595212 non-null  int64  
 35  ps_car_12       595212 non-null  float64
 36  ps_car_13       595212 non-null  float64
 37  ps_car_14       595212 non-null  float64
 38  ps_car_15       595212 non-null  float64
 39  ps_calc_01      595212 non-null  float64
 40  ps_calc_02      595212 non-null  float64
 41  ps_calc_03      595212 non-null  float64
 42  ps_calc_04      595212 non-null  int64  
 43  ps_calc_05      595212 non-null  int64  
 44  ps_calc_06      595212 non-null  int64  
 45  ps_calc_07      595212 non-null  int64  
 46  ps_calc_08      595212 non-null  int64  
 47  ps_calc_09      595212 non-null  int64  
 48  ps_calc_10      595212 non-null  int64  
 49  ps_calc_11      595212 non-null  int64  
 50  ps_calc_12      595212 non-null  int64  
 51  ps_calc_13      595212 non-null  int64  
 52  ps_calc_14      595212 non-null  int64  
 53  ps_calc_15_bin  595212 non-null  int64  
 54  ps_calc_16_bin  595212 non-null  int64  
 55  ps_calc_17_bin  595212 non-null  int64  
 56  ps_calc_18_bin  595212 non-null  int64  
 57  ps_calc_19_bin  595212 non-null  int64  
 58  ps_calc_20_bin  595212 non-null  int64  
dtypes: float64(10), int64(49)
memory usage: 267.9 MB
</pre></table></code></div></div><ul><li>14개의 Categorical 변수(cat)는 더미 변수를 만들어야하고, binary 변수(bin)는 binary이기에 더미변수를 만들지 않아도 됩니다.</li><li>데이터는 float이거나 int64 데이터 타입입니다.</li><li>Null값은 없는것으로 나오는데, 누락값은 -1로 처리하였기 때문입니다.</li></ul><p><br /></p><h2 id="5-defining-the-metadata">5. Defining the metadata</h2><hr /><h3 id="51-metadata">5.1 Metadata</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
</pre><td class="rouge-code"><pre><span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">train</span><span class="p">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="c1"># Defining the role
</span>    <span class="k">if</span> <span class="n">f</span> <span class="o">==</span> <span class="s">'target'</span><span class="p">:</span>
        <span class="n">role</span> <span class="o">=</span> <span class="s">'target'</span>
    <span class="k">elif</span> <span class="n">f</span> <span class="o">==</span> <span class="s">'id'</span><span class="p">:</span>
        <span class="n">role</span> <span class="o">=</span> <span class="s">'id'</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">role</span> <span class="o">=</span> <span class="s">'input'</span>

    <span class="c1"># Defining the level
</span>    <span class="k">if</span> <span class="s">'bin'</span> <span class="ow">in</span> <span class="n">f</span> <span class="ow">or</span> <span class="n">f</span> <span class="o">==</span> <span class="s">'target'</span><span class="p">:</span>
        <span class="n">level</span> <span class="o">=</span> <span class="s">'binary'</span>
    <span class="k">elif</span> <span class="s">'cat'</span> <span class="ow">in</span> <span class="n">f</span> <span class="ow">or</span> <span class="n">f</span> <span class="o">==</span> <span class="s">'id'</span><span class="p">:</span>
        <span class="n">level</span> <span class="o">=</span> <span class="s">'nominal'</span>
    <span class="k">elif</span> <span class="n">train</span><span class="p">[</span><span class="n">f</span><span class="p">].</span><span class="n">dtype</span> <span class="o">==</span> <span class="nb">float</span><span class="p">:</span>
        <span class="n">level</span> <span class="o">=</span> <span class="s">'interval'</span>
    <span class="k">elif</span> <span class="n">train</span><span class="p">[</span><span class="n">f</span><span class="p">].</span><span class="n">dtype</span> <span class="o">==</span> <span class="nb">int</span><span class="p">:</span>
        <span class="n">level</span> <span class="o">=</span> <span class="s">'ordinal'</span>
        
    <span class="c1"># Initialize keep to True for all variables except for id
</span>    
    <span class="n">keep</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="k">if</span> <span class="n">f</span> <span class="o">==</span> <span class="s">'id'</span><span class="p">:</span>
        <span class="n">keep</span> <span class="o">=</span> <span class="bp">False</span>
        
    <span class="c1"># Defining the data type
</span>    
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">f</span><span class="p">].</span><span class="n">dtype</span>
    
    <span class="c1"># Creating a Dict tha contains all the metadata for the variable
</span>    
    <span class="n">f_dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">'varname'</span> <span class="p">:</span> <span class="n">f</span><span class="p">,</span>
        <span class="s">'role'</span> <span class="p">:</span> <span class="n">role</span><span class="p">,</span>
        <span class="s">'level'</span> <span class="p">:</span> <span class="n">level</span><span class="p">,</span>
        <span class="s">'keep'</span> <span class="p">:</span> <span class="n">keep</span><span class="p">,</span>
        <span class="s">'dtype'</span> <span class="p">:</span> <span class="n">dtype</span>
    <span class="p">}</span>
    <span class="n">data</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">f_dict</span><span class="p">)</span>
    
<span class="n">meta</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'varname'</span><span class="p">,</span> <span class="s">'role'</span><span class="p">,</span> <span class="s">'level'</span><span class="p">,</span> <span class="s">'keep'</span><span class="p">,</span> <span class="s">'dtype'</span><span class="p">])</span>
<span class="n">meta</span><span class="p">.</span><span class="n">set_index</span><span class="p">(</span><span class="s">'varname'</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">meta</span>
</pre></table></code></div></div><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>role<th>level<th>keep<th>dtype<tr><th>varname<th><th><th><th><tbody><tr><th>id<td>id<td>nominal<td>False<td>int64<tr><th>target<td>target<td>binary<td>True<td>int64<tr><th>ps_ind_01<td>input<td>ordinal<td>True<td>int64<tr><th>ps_ind_02_cat<td>input<td>nominal<td>True<td>int64<tr><th>ps_ind_03<td>input<td>ordinal<td>True<td>int64<tr><th>ps_ind_04_cat<td>input<td>nominal<td>True<td>int64<tr><th>ps_ind_05_cat<td>input<td>nominal<td>True<td>int64<tr><th>ps_ind_06_bin<td>input<td>binary<td>True<td>int64<tr><th>ps_ind_07_bin<td>input<td>binary<td>True<td>int64<tr><th>ps_ind_08_bin<td>input<td>binary<td>True<td>int64<tr><th>ps_ind_09_bin<td>input<td>binary<td>True<td>int64<tr><th>ps_ind_10_bin<td>input<td>binary<td>True<td>int64<tr><th>ps_ind_11_bin<td>input<td>binary<td>True<td>int64<tr><th>ps_ind_12_bin<td>input<td>binary<td>True<td>int64<tr><th>ps_ind_13_bin<td>input<td>binary<td>True<td>int64<tr><th>ps_ind_14<td>input<td>ordinal<td>True<td>int64<tr><th>ps_ind_15<td>input<td>ordinal<td>True<td>int64<tr><th>ps_ind_16_bin<td>input<td>binary<td>True<td>int64<tr><th>ps_ind_17_bin<td>input<td>binary<td>True<td>int64<tr><th>ps_ind_18_bin<td>input<td>binary<td>True<td>int64<tr><th>ps_reg_01<td>input<td>interval<td>True<td>float64<tr><th>ps_reg_02<td>input<td>interval<td>True<td>float64<tr><th>ps_reg_03<td>input<td>interval<td>True<td>float64<tr><th>ps_car_01_cat<td>input<td>nominal<td>True<td>int64<tr><th>ps_car_02_cat<td>input<td>nominal<td>True<td>int64<tr><th>ps_car_03_cat<td>input<td>nominal<td>True<td>int64<tr><th>ps_car_04_cat<td>input<td>nominal<td>True<td>int64<tr><th>ps_car_05_cat<td>input<td>nominal<td>True<td>int64<tr><th>ps_car_06_cat<td>input<td>nominal<td>True<td>int64<tr><th>ps_car_07_cat<td>input<td>nominal<td>True<td>int64<tr><th>ps_car_08_cat<td>input<td>nominal<td>True<td>int64<tr><th>ps_car_09_cat<td>input<td>nominal<td>True<td>int64<tr><th>ps_car_10_cat<td>input<td>nominal<td>True<td>int64<tr><th>ps_car_11_cat<td>input<td>nominal<td>True<td>int64<tr><th>ps_car_11<td>input<td>ordinal<td>True<td>int64<tr><th>ps_car_12<td>input<td>interval<td>True<td>float64<tr><th>ps_car_13<td>input<td>interval<td>True<td>float64<tr><th>ps_car_14<td>input<td>interval<td>True<td>float64<tr><th>ps_car_15<td>input<td>interval<td>True<td>float64<tr><th>ps_calc_01<td>input<td>interval<td>True<td>float64<tr><th>ps_calc_02<td>input<td>interval<td>True<td>float64<tr><th>ps_calc_03<td>input<td>interval<td>True<td>float64<tr><th>ps_calc_04<td>input<td>ordinal<td>True<td>int64<tr><th>ps_calc_05<td>input<td>ordinal<td>True<td>int64<tr><th>ps_calc_06<td>input<td>ordinal<td>True<td>int64<tr><th>ps_calc_07<td>input<td>ordinal<td>True<td>int64<tr><th>ps_calc_08<td>input<td>ordinal<td>True<td>int64<tr><th>ps_calc_09<td>input<td>ordinal<td>True<td>int64<tr><th>ps_calc_10<td>input<td>ordinal<td>True<td>int64<tr><th>ps_calc_11<td>input<td>ordinal<td>True<td>int64<tr><th>ps_calc_12<td>input<td>ordinal<td>True<td>int64<tr><th>ps_calc_13<td>input<td>ordinal<td>True<td>int64<tr><th>ps_calc_14<td>input<td>ordinal<td>True<td>int64<tr><th>ps_calc_15_bin<td>input<td>binary<td>True<td>int64<tr><th>ps_calc_16_bin<td>input<td>binary<td>True<td>int64<tr><th>ps_calc_17_bin<td>input<td>binary<td>True<td>int64<tr><th>ps_calc_18_bin<td>input<td>binary<td>True<td>int64<tr><th>ps_calc_19_bin<td>input<td>binary<td>True<td>int64<tr><th>ps_calc_20_bin<td>input<td>binary<td>True<td>int64</table></div><ul><li>데이터의 시각화, 분석, 모델링 위해 모델의 메타데이터를 데이터프레임에 저장함<ul><li>role: input, ID, target</li><li>level: nominal, interval, ordinal, binary</li><li>keep: True or False</li><li>dtype: int, float, str <br /></li></ul></li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">meta</span><span class="p">[(</span><span class="n">meta</span><span class="p">.</span><span class="n">level</span> <span class="o">==</span> <span class="s">'nominal'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">meta</span><span class="p">.</span><span class="n">keep</span> <span class="o">==</span> <span class="bp">True</span><span class="p">)].</span><span class="n">index</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>Index(['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat',
       'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat', 'ps_car_05_cat',
       'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat',
       'ps_car_10_cat', 'ps_car_11_cat'],
      dtype='object', name='varname')
</pre></table></code></div></div><ul><li>Kepp은 True(삭제되지않음)인 nominal 변수들의 목록</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">'count'</span> <span class="p">:</span> <span class="n">meta</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'role'</span><span class="p">,</span> <span class="s">'level'</span><span class="p">])[</span><span class="s">'role'</span><span class="p">].</span><span class="n">size</span><span class="p">()}).</span><span class="n">reset_index</span><span class="p">()</span>
</pre></table></code></div></div><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>role<th>level<th>count<tbody><tr><th>0<td>id<td>nominal<td>1<tr><th>1<td>input<td>binary<td>17<tr><th>2<td>input<td>interval<td>10<tr><th>3<td>input<td>nominal<td>14<tr><th>4<td>input<td>ordinal<td>16<tr><th>5<td>target<td>binary<td>1</table></div><ul><li>Role 및 level별 변수의 count를 Group By로 묶어서 DataFrame으로 만듬</li></ul><p><br /></p><h2 id="6-descriptive-statistics">6. Descriptive statistics</h2><hr /><h3 id="61-descriptive-statistics">6.1 Descriptive statistics</h3><ul><li>데이터프레임에 describe를 할수 있습니다. 다만, 범주형 범수에는 의미가 없으니 실수형 변수에 사용하여 평균, 표준편차 등을 알수 있습니다.</li></ul><p><br /></p><h3 id="62-interval-variables">6.2 Interval variables</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">v</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[(</span><span class="n">meta</span><span class="p">.</span><span class="n">level</span> <span class="o">==</span> <span class="s">'interval'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">meta</span><span class="p">.</span><span class="n">keep</span> <span class="o">==</span> <span class="bp">True</span><span class="p">)].</span><span class="n">index</span>
<span class="n">train</span><span class="p">[</span><span class="n">v</span><span class="p">].</span><span class="n">describe</span><span class="p">()</span>
</pre></table></code></div></div><div style="width:100%; height:200px; overflow:auto"><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>ps_reg_01<th>ps_reg_02<th>ps_reg_03<th>ps_car_12<th>ps_car_13<th>ps_car_14<th>ps_car_15<th>ps_calc_01<th>ps_calc_02<th>ps_calc_03<tbody><tr><th>count<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<tr><th>mean<td>0.610991<td>0.439184<td>0.551102<td>0.379945<td>0.813265<td>0.276256<td>3.065899<td>0.449756<td>0.449589<td>0.449849<tr><th>std<td>0.287643<td>0.404264<td>0.793506<td>0.058327<td>0.224588<td>0.357154<td>0.731366<td>0.287198<td>0.286893<td>0.287153<tr><th>min<td>0.000000<td>0.000000<td>-1.000000<td>-1.000000<td>0.250619<td>-1.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<tr><th>25%<td>0.400000<td>0.200000<td>0.525000<td>0.316228<td>0.670867<td>0.333167<td>2.828427<td>0.200000<td>0.200000<td>0.200000<tr><th>50%<td>0.700000<td>0.300000<td>0.720677<td>0.374166<td>0.765811<td>0.368782<td>3.316625<td>0.500000<td>0.400000<td>0.500000<tr><th>75%<td>0.900000<td>0.600000<td>1.000000<td>0.400000<td>0.906190<td>0.396485<td>3.605551<td>0.700000<td>0.700000<td>0.700000<tr><th>max<td>0.900000<td>1.800000<td>4.037945<td>1.264911<td>3.720626<td>0.636396<td>3.741657<td>0.900000<td>0.900000<td>0.900000</table></div><ul><li>Level이 interval인 변수에 대해 describe를 진행하였습니다.</li><li>reg 변수들중에는 ps_reg_03에만 -1(Null data)가 있습니다.</li><li>car 변수들중에는 ps_car_12, ps_car_14에 -1(Null data)가 있습니다.</li><li>calc 변수들에는 -1(NUll data)는 없습니다.</li><li>변수별로 min과 max의 range가 다릅니다, 스케일링을 적용해야 할듯 합니다.</li><li>interval 변수들의 범위는 그렇게 크지 않음을 알수 있습니다.</li></ul><p><br /></p><h3 id="63-ordinal-variables">6.3 Ordinal variables</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">v</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[(</span><span class="n">meta</span><span class="p">.</span><span class="n">level</span> <span class="o">==</span> <span class="s">'ordinal'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">meta</span><span class="p">.</span><span class="n">keep</span> <span class="o">==</span> <span class="bp">True</span><span class="p">)].</span><span class="n">index</span>
<span class="n">train</span><span class="p">[</span><span class="n">v</span><span class="p">].</span><span class="n">describe</span><span class="p">()</span>
</pre></table></code></div></div><div style="width:100%; height:200px; overflow:auto"><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>ps_ind_01<th>ps_ind_03<th>ps_ind_14<th>ps_ind_15<th>ps_car_11<th>ps_calc_04<th>ps_calc_05<th>ps_calc_06<th>ps_calc_07<th>ps_calc_08<th>ps_calc_09<th>ps_calc_10<th>ps_calc_11<th>ps_calc_12<th>ps_calc_13<th>ps_calc_14<tbody><tr><th>count<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<tr><th>mean<td>1.900378<td>4.423318<td>0.012451<td>7.299922<td>2.346072<td>2.372081<td>1.885886<td>7.689445<td>3.005823<td>9.225904<td>2.339034<td>8.433590<td>5.441382<td>1.441918<td>2.872288<td>7.539026<tr><th>std<td>1.983789<td>2.699902<td>0.127545<td>3.546042<td>0.832548<td>1.117219<td>1.134927<td>1.334312<td>1.414564<td>1.459672<td>1.246949<td>2.904597<td>2.332871<td>1.202963<td>1.694887<td>2.746652<tr><th>min<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>-1.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>2.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<tr><th>25%<td>0.000000<td>2.000000<td>0.000000<td>5.000000<td>2.000000<td>2.000000<td>1.000000<td>7.000000<td>2.000000<td>8.000000<td>1.000000<td>6.000000<td>4.000000<td>1.000000<td>2.000000<td>6.000000<tr><th>50%<td>1.000000<td>4.000000<td>0.000000<td>7.000000<td>3.000000<td>2.000000<td>2.000000<td>8.000000<td>3.000000<td>9.000000<td>2.000000<td>8.000000<td>5.000000<td>1.000000<td>3.000000<td>7.000000<tr><th>75%<td>3.000000<td>6.000000<td>0.000000<td>10.000000<td>3.000000<td>3.000000<td>3.000000<td>9.000000<td>4.000000<td>10.000000<td>3.000000<td>10.000000<td>7.000000<td>2.000000<td>4.000000<td>9.000000<tr><th>max<td>7.000000<td>11.000000<td>4.000000<td>13.000000<td>3.000000<td>5.000000<td>6.000000<td>10.000000<td>9.000000<td>12.000000<td>7.000000<td>25.000000<td>19.000000<td>10.000000<td>13.000000<td>23.000000</table></div><ul><li>ps_car_11 변수에만 -1(Null data)가 있습니다.</li><li>모두 min, max range가 다르므로 scaling을 진행해야 합니다.</li></ul><p><br /></p><h3 id="64-binary-variables">6.4 Binary variables</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">v</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[(</span><span class="n">meta</span><span class="p">.</span><span class="n">level</span> <span class="o">==</span> <span class="s">'binary'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">meta</span><span class="p">.</span><span class="n">keep</span> <span class="o">==</span> <span class="bp">True</span><span class="p">)].</span><span class="n">index</span>
<span class="n">train</span><span class="p">[</span><span class="n">v</span><span class="p">].</span><span class="n">describe</span><span class="p">()</span>
</pre></table></code></div></div><div style="width:100%; height:200px; overflow:auto"><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>target<th>ps_ind_06_bin<th>ps_ind_07_bin<th>ps_ind_08_bin<th>ps_ind_09_bin<th>ps_ind_10_bin<th>ps_ind_11_bin<th>ps_ind_12_bin<th>ps_ind_13_bin<th>ps_ind_16_bin<th>ps_ind_17_bin<th>ps_ind_18_bin<th>ps_calc_15_bin<th>ps_calc_16_bin<th>ps_calc_17_bin<th>ps_calc_18_bin<th>ps_calc_19_bin<th>ps_calc_20_bin<tbody><tr><th>count<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<td>595212.000000<tr><th>mean<td>0.036448<td>0.393742<td>0.257033<td>0.163921<td>0.185304<td>0.000373<td>0.001692<td>0.009439<td>0.000948<td>0.660823<td>0.121081<td>0.153446<td>0.122427<td>0.627840<td>0.554182<td>0.287182<td>0.349024<td>0.153318<tr><th>std<td>0.187401<td>0.488579<td>0.436998<td>0.370205<td>0.388544<td>0.019309<td>0.041097<td>0.096693<td>0.030768<td>0.473430<td>0.326222<td>0.360417<td>0.327779<td>0.483381<td>0.497056<td>0.452447<td>0.476662<td>0.360295<tr><th>min<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<tr><th>25%<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<tr><th>50%<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>1.000000<td>0.000000<td>0.000000<td>0.000000<td>1.000000<td>1.000000<td>0.000000<td>0.000000<td>0.000000<tr><th>75%<td>0.000000<td>1.000000<td>1.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>0.000000<td>1.000000<td>0.000000<td>0.000000<td>0.000000<td>1.000000<td>1.000000<td>1.000000<td>1.000000<td>0.000000<tr><th>max<td>1.000000<td>1.000000<td>1.000000<td>1.000000<td>1.000000<td>1.000000<td>1.000000<td>1.000000<td>1.000000<td>1.000000<td>1.000000<td>1.000000<td>1.000000<td>1.000000<td>1.000000<td>1.000000<td>1.000000<td>1.000000</table></div><ul><li>Train 데이터에서 target은 3.645% 입니다. 이것은 강력한 불균형 (strongly imbalanced) 입니다.</li><li>이것은 대부분의 값이 0으로 되어있음을 의미합니다.</li></ul><p><br /></p><h2 id="7-handling-imbalanced-classes">7. Handling imbalanced classes</h2><hr /><h3 id="71-handling-imbalanced-classes">7.1 Handling imbalanced classes</h3><ul><li>Target = 1인 Record의 비율이 너무 적습니다. 그 말인즉슨, 모두다 target을 0으로 예측해도 얼마안되는 1만 틀린것으로 파악됩니다.</li><li>이를 해결하기 위해 1을 오버 샘플링하거나 0을 언더샘플링 하는 방법이 있습니다.</li><li>이번에는 언더샘플링을 하겠습니다.</li></ul><p><br /></p><h3 id="72-undersampling">7.2 UnderSampling</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
</pre><td class="rouge-code"><pre><span class="n">desired_apriori</span><span class="o">=</span><span class="mf">0.10</span>

<span class="c1"># Get the indices per target value
</span><span class="n">idx_0</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">.</span><span class="n">target</span> <span class="o">==</span> <span class="mi">0</span><span class="p">].</span><span class="n">index</span>
<span class="n">idx_1</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">.</span><span class="n">target</span> <span class="o">==</span> <span class="mi">1</span><span class="p">].</span><span class="n">index</span>

<span class="c1"># Get original number of records per target value
</span><span class="n">nb_0</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx_0</span><span class="p">])</span>
<span class="n">nb_1</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx_1</span><span class="p">])</span>

<span class="c1"># Calculate the undersampling rate and resulting number of records with target=0
</span><span class="n">undersampling_rate</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">desired_apriori</span><span class="p">)</span><span class="o">*</span><span class="n">nb_1</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">nb_0</span><span class="o">*</span><span class="n">desired_apriori</span><span class="p">)</span>
<span class="n">undersampled_nb_0</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">undersampling_rate</span><span class="o">*</span><span class="n">nb_0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Rate to undersample records with target=0: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">undersampling_rate</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Number of records with target=0 after undersampling: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">undersampled_nb_0</span><span class="p">))</span>

<span class="c1"># Randomly select records with target=0 to get at the desired a priori
</span><span class="n">undersampled_idx</span> <span class="o">=</span> <span class="n">shuffle</span><span class="p">(</span><span class="n">idx_0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">37</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="n">undersampled_nb_0</span><span class="p">)</span>

<span class="c1"># Construct list with remaining indices
</span><span class="n">idx_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">undersampled_idx</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">idx_1</span><span class="p">)</span>

<span class="c1"># Return undersample data frame
</span><span class="n">train</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx_list</span><span class="p">].</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">under_rate</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'target'</span><span class="p">].</span><span class="nb">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">train</span><span class="p">[</span><span class="s">'target'</span><span class="p">].</span><span class="n">count</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Under sampling으로 변환된 target의 비율 : </span><span class="si">{</span><span class="n">under_rate</span><span class="si">}</span><span class="s"> %'</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>Rate to undersample records with target=0: 0.34043569687437886
Number of records with target=0 after undersampling: 195246
Under sampling으로 변환된 target의 비율 : 0.1 %
</pre></table></code></div></div><ul><li>undersampling_rate는 0인 타겟이 몇%가 되어야 target 1이 1%가 되는지의 대한 비율</li><li>desired_apriori = 0.10 는 undersampling 하여 나오게될 target = 1의 비율</li></ul><p><br /></p><h2 id="8-data-quality-checks">8. Data Quality Checks</h2><hr /><h3 id="81-checking-missing-values">8.1 Checking missing values</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="n">vars_with_missing</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">train</span><span class="p">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">missings</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">[</span><span class="n">f</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="n">f</span><span class="p">].</span><span class="n">count</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">missings</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">vars_with_missing</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
        <span class="n">missings_perc</span> <span class="o">=</span> <span class="n">missings</span> <span class="o">/</span> <span class="n">train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Variable </span><span class="si">{</span><span class="n">f</span><span class="si">}</span><span class="s"> has </span><span class="si">{</span><span class="n">missings</span><span class="si">}</span><span class="s"> records </span><span class="si">{</span><span class="n">missings_perc</span><span class="p">:.</span><span class="mi">2</span><span class="o">%</span><span class="si">}</span><span class="s"> with missing values'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'In total, there are </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">vars_with_missing</span><span class="p">)</span><span class="si">}</span><span class="s"> varialbles with missing values'</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre>Variable ps_ind_02_cat has 103 records 0.05% with missing values
Variable ps_ind_04_cat has 51 records 0.02% with missing values
Variable ps_ind_05_cat has 2256 records 1.04% with missing values
Variable ps_reg_03 has 38580 records 17.78% with missing values
Variable ps_car_01_cat has 62 records 0.03% with missing values
Variable ps_car_02_cat has 2 records 0.00% with missing values
Variable ps_car_03_cat has 148367 records 68.39% with missing values
Variable ps_car_05_cat has 96026 records 44.26% with missing values
Variable ps_car_07_cat has 4431 records 2.04% with missing values
Variable ps_car_09_cat has 230 records 0.11% with missing values
Variable ps_car_11 has 1 records 0.00% with missing values
Variable ps_car_14 has 15726 records 7.25% with missing values
In total, there are 12 varialbles with missing values
</pre></table></code></div></div><ul><li>Missing Values(Null Data)인 -1을 각 변수별로 찾아서, 비율을 확인한것 입니다.</li><li>생각보다 Missing Values가 많은 변수가 있습니다. ps_res_03, ps_car_03_cat, ps_car_05_cat …</li><li>총 12개의 변수에서 Missing values가 있습니다.</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="c1"># Dropping the variables with too many missing values
</span><span class="n">vars_to_drop</span> <span class="o">=</span> <span class="p">[</span><span class="s">'ps_car_03_cat'</span><span class="p">,</span> <span class="s">'ps_car_05_cat'</span><span class="p">]</span>
<span class="n">train</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">vars_to_drop</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">meta</span><span class="p">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">vars_to_drop</span><span class="p">),</span><span class="s">'keep'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>  <span class="c1"># Updating the meta
</span>
<span class="c1"># Imputing with the mean or mode
</span><span class="n">mean_imp</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">missing_values</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s">'mean'</span><span class="p">)</span>
<span class="n">mode_imp</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">missing_values</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s">'most_frequent'</span><span class="p">)</span>
<span class="n">train</span><span class="p">[</span><span class="s">'ps_reg_03'</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_imp</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">[[</span><span class="s">'ps_reg_03'</span><span class="p">]]).</span><span class="n">ravel</span><span class="p">()</span>
<span class="n">train</span><span class="p">[</span><span class="s">'ps_car_12'</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_imp</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">[[</span><span class="s">'ps_car_12'</span><span class="p">]]).</span><span class="n">ravel</span><span class="p">()</span>
<span class="n">train</span><span class="p">[</span><span class="s">'ps_car_14'</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_imp</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">[[</span><span class="s">'ps_car_14'</span><span class="p">]]).</span><span class="n">ravel</span><span class="p">()</span>
<span class="n">train</span><span class="p">[</span><span class="s">'ps_car_11'</span><span class="p">]</span> <span class="o">=</span> <span class="n">mode_imp</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">[[</span><span class="s">'ps_car_11'</span><span class="p">]]).</span><span class="n">ravel</span><span class="p">()</span>
</pre></table></code></div></div><ul><li>Missing value이있는 다른범주형 변수의 경우 Missing value -1을 그대로 둠</li><li>ps_reg_03 (continuous)의 18%의 Missing value는 평균으로 바꿉니다.</li><li>ps_car_11 (ordinal)의 5개의 Misisng values는 최빈값으로 바꿉니다.</li><li>ps_car_12 (continuous)의 단 1개의 Missing value 평균으로 바꿉니다.</li><li>ps_car_14 (continuous)의 7% Missing values는 평균으로 바꿉니다.</li></ul><p><br /></p><h3 id="82-checking-the-cardinality-of-the-categorical-variables">8.2 Checking the cardinality of the categorical variables</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="n">v</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[(</span><span class="n">meta</span><span class="p">[</span><span class="s">'level'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'nominal'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">meta</span><span class="p">[</span><span class="s">'keep'</span><span class="p">])].</span><span class="n">index</span>

<span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">v</span><span class="p">:</span>
    <span class="n">dist_values</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">f</span><span class="p">].</span><span class="n">value_counts</span><span class="p">().</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Variable </span><span class="si">{</span><span class="n">f</span><span class="si">}</span><span class="s"> has </span><span class="si">{</span><span class="n">dist_values</span><span class="si">}</span><span class="s"> distinct values'</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre>Variable ps_ind_02_cat has 5 distinct values
Variable ps_ind_04_cat has 3 distinct values
Variable ps_ind_05_cat has 8 distinct values
Variable ps_car_01_cat has 13 distinct values
Variable ps_car_02_cat has 3 distinct values
Variable ps_car_04_cat has 10 distinct values
Variable ps_car_06_cat has 18 distinct values
Variable ps_car_07_cat has 3 distinct values
Variable ps_car_08_cat has 2 distinct values
Variable ps_car_09_cat has 6 distinct values
Variable ps_car_10_cat has 3 distinct values
Variable ps_car_11_cat has 104 distinct values
</pre></table></code></div></div><ul><li>cardinality는 변수에있는 서로 다른 값의 수를 나타냅니다.</li><li>범주 형 변수에서 더미 변수를 만들 것이므로 고유 한 값이 많은 변수가 있는지 확인해야합니다. 이러한 변수는 많은 더미 변수를 생성하므로 다르게 처리해야합니다</li><li>ps_car_11_cat이 104개의 distinct data를 가집니다.</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
</pre><td class="rouge-code"><pre><span class="c1"># Script by https://www.kaggle.com/ogrellier
# Code: https://www.kaggle.com/ogrellier/python-target-encoding-for-categorical-features
</span><span class="k">def</span> <span class="nf">add_noise</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">noise_level</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">series</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">noise_level</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">series</span><span class="p">)))</span>

<span class="k">def</span> <span class="nf">target_encode</span><span class="p">(</span><span class="n">trn_series</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                  <span class="n">tst_series</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                  <span class="n">target</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                  <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                  <span class="n">smoothing</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                  <span class="n">noise_level</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="s">"""
    Smoothing is computed like in the following paper by Daniele Micci-Barreca
    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf
    trn_series : training categorical feature as a pd.Series
    tst_series : test categorical feature as a pd.Series
    target : target data as a pd.Series
    min_samples_leaf (int) : minimum samples to take category average into account
    smoothing (int) : smoothing effect to balance categorical average vs prior  
    """</span> 
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">trn_series</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">trn_series</span><span class="p">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">tst_series</span><span class="p">.</span><span class="n">name</span>
    <span class="n">temp</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span><span class="n">trn_series</span><span class="p">,</span> <span class="n">target</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># Compute target mean 
</span>    <span class="n">averages</span> <span class="o">=</span> <span class="n">temp</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="n">trn_series</span><span class="p">.</span><span class="n">name</span><span class="p">)[</span><span class="n">target</span><span class="p">.</span><span class="n">name</span><span class="p">].</span><span class="n">agg</span><span class="p">([</span><span class="s">"mean"</span><span class="p">,</span> <span class="s">"count"</span><span class="p">])</span>
    <span class="c1"># Compute smoothing
</span>    <span class="n">smoothing</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">averages</span><span class="p">[</span><span class="s">"count"</span><span class="p">]</span> <span class="o">-</span> <span class="n">min_samples_leaf</span><span class="p">)</span> <span class="o">/</span> <span class="n">smoothing</span><span class="p">))</span>
    <span class="c1"># Apply average function to all target data
</span>    <span class="n">prior</span> <span class="o">=</span> <span class="n">target</span><span class="p">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="c1"># The bigger the count the less full_avg is taken into account
</span>    <span class="n">averages</span><span class="p">[</span><span class="n">target</span><span class="p">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">prior</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">smoothing</span><span class="p">)</span> <span class="o">+</span> <span class="n">averages</span><span class="p">[</span><span class="s">"mean"</span><span class="p">]</span> <span class="o">*</span> <span class="n">smoothing</span>
    <span class="n">averages</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">"mean"</span><span class="p">,</span> <span class="s">"count"</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="c1"># Apply averages to trn and tst series
</span>    <span class="n">ft_trn_series</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span>
        <span class="n">trn_series</span><span class="p">.</span><span class="n">to_frame</span><span class="p">(</span><span class="n">trn_series</span><span class="p">.</span><span class="n">name</span><span class="p">),</span>
        <span class="n">averages</span><span class="p">.</span><span class="n">reset_index</span><span class="p">().</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'index'</span><span class="p">:</span> <span class="n">target</span><span class="p">.</span><span class="n">name</span><span class="p">,</span> <span class="n">target</span><span class="p">.</span><span class="n">name</span><span class="p">:</span> <span class="s">'average'</span><span class="p">}),</span>
        <span class="n">on</span><span class="o">=</span><span class="n">trn_series</span><span class="p">.</span><span class="n">name</span><span class="p">,</span>
        <span class="n">how</span><span class="o">=</span><span class="s">'left'</span><span class="p">)[</span><span class="s">'average'</span><span class="p">].</span><span class="n">rename</span><span class="p">(</span><span class="n">trn_series</span><span class="p">.</span><span class="n">name</span> <span class="o">+</span> <span class="s">'_mean'</span><span class="p">).</span><span class="n">fillna</span><span class="p">(</span><span class="n">prior</span><span class="p">)</span>
    <span class="c1"># pd.merge does not keep the index so restore it
</span>    <span class="n">ft_trn_series</span><span class="p">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">trn_series</span><span class="p">.</span><span class="n">index</span> 
    <span class="n">ft_tst_series</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span>
        <span class="n">tst_series</span><span class="p">.</span><span class="n">to_frame</span><span class="p">(</span><span class="n">tst_series</span><span class="p">.</span><span class="n">name</span><span class="p">),</span>
        <span class="n">averages</span><span class="p">.</span><span class="n">reset_index</span><span class="p">().</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'index'</span><span class="p">:</span> <span class="n">target</span><span class="p">.</span><span class="n">name</span><span class="p">,</span> <span class="n">target</span><span class="p">.</span><span class="n">name</span><span class="p">:</span> <span class="s">'average'</span><span class="p">}),</span>
        <span class="n">on</span><span class="o">=</span><span class="n">tst_series</span><span class="p">.</span><span class="n">name</span><span class="p">,</span>
        <span class="n">how</span><span class="o">=</span><span class="s">'left'</span><span class="p">)[</span><span class="s">'average'</span><span class="p">].</span><span class="n">rename</span><span class="p">(</span><span class="n">trn_series</span><span class="p">.</span><span class="n">name</span> <span class="o">+</span> <span class="s">'_mean'</span><span class="p">).</span><span class="n">fillna</span><span class="p">(</span><span class="n">prior</span><span class="p">)</span>
    <span class="c1"># pd.merge does not keep the index so restore it
</span>    <span class="n">ft_tst_series</span><span class="p">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">tst_series</span><span class="p">.</span><span class="n">index</span>
    <span class="k">return</span> <span class="n">add_noise</span><span class="p">(</span><span class="n">ft_trn_series</span><span class="p">,</span> <span class="n">noise_level</span><span class="p">),</span> <span class="n">add_noise</span><span class="p">(</span><span class="n">ft_tst_series</span><span class="p">,</span> <span class="n">noise_level</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="n">train_encoded</span><span class="p">,</span> <span class="n">test_encoded</span> <span class="o">=</span> <span class="n">target_encode</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s">'ps_car_11_cat'</span><span class="p">],</span>
                                            <span class="n">test</span><span class="p">[</span><span class="s">'ps_car_11_cat'</span><span class="p">],</span>
                                            <span class="n">target</span><span class="o">=</span><span class="n">train</span><span class="p">.</span><span class="n">target</span><span class="p">,</span>
                                            <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                                            <span class="n">smoothing</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                                            <span class="n">noise_level</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="n">train</span><span class="p">[</span><span class="s">'ps_car_11_cat_te'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_encoded</span>
<span class="n">train</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'ps_car_11_cat'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">meta</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="s">'ps_car_11_cat'</span><span class="p">,</span> <span class="s">'keep'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>  <span class="c1"># Updating the meta
</span><span class="n">test</span><span class="p">[</span><span class="s">'ps_car_11_cat_te'</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_encoded</span>
<span class="n">test</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'ps_car_11_cat'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></table></code></div></div><p><br /></p><h2 id="9-exploratory-data-visualization">9. Exploratory Data Visualization</h2><hr /><h3 id="91-categorical-variables">9.1 Categorical variables</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre><td class="rouge-code"><pre><span class="n">v</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[(</span><span class="n">meta</span><span class="p">.</span><span class="n">level</span> <span class="o">==</span> <span class="s">'nominal'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">meta</span><span class="p">.</span><span class="n">keep</span><span class="p">)].</span><span class="n">index</span>

<span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">v</span><span class="p">:</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
    
    <span class="c1"># Calculate the percentage of target = 1 per category value
</span>    <span class="n">cat_perc</span> <span class="o">=</span> <span class="n">train</span><span class="p">[[</span><span class="n">f</span><span class="p">,</span> <span class="s">'target'</span><span class="p">]].</span><span class="n">groupby</span><span class="p">([</span><span class="n">f</span><span class="p">],</span> <span class="n">as_index</span> <span class="o">=</span> <span class="bp">False</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">cat_perc</span><span class="p">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s">'target'</span><span class="p">,</span> <span class="n">ascending</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
    
    <span class="c1"># Bar plot
</span>    <span class="c1"># Order the bars descending on target mean
</span>    <span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">f</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s">'target'</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">cat_perc</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span> <span class="n">cat_perc</span><span class="p">[</span><span class="n">f</span><span class="p">])</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s">'barplot of </span><span class="si">{</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">18</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'% Target'</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">18</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">18</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="s">'both'</span><span class="p">,</span> <span class="n">which</span> <span class="o">=</span> <span class="s">'major'</span><span class="p">,</span> <span class="n">labelsize</span> <span class="o">=</span> <span class="mi">18</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>&lt;Figure size 432x288 with 0 Axes&gt;
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98533692-a4484200-22c6-11eb-9fb3-f63c6111be71.png" /></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>&lt;Figure size 432x288 with 0 Axes&gt;
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98533696-a5796f00-22c6-11eb-95be-f9052ebeb69a.png" /></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>&lt;Figure size 432x288 with 0 Axes&gt;
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98533700-a6120580-22c6-11eb-85b0-d058aee3710b.png" /></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>&lt;Figure size 432x288 with 0 Axes&gt;
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98533702-a6aa9c00-22c6-11eb-8894-5a2e2eb2d167.png" /></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>&lt;Figure size 432x288 with 0 Axes&gt;
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98533703-a7433280-22c6-11eb-91d7-9bb990de917d.png" /></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>&lt;Figure size 432x288 with 0 Axes&gt;
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98533705-a7433280-22c6-11eb-81c2-ba88415da9a8.png" /></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>&lt;Figure size 432x288 with 0 Axes&gt;
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98533706-a7dbc900-22c6-11eb-8dfe-23cc366683b2.png" /></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>&lt;Figure size 432x288 with 0 Axes&gt;
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98533707-a8745f80-22c6-11eb-93fc-b3ff612e01e2.png" /></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>&lt;Figure size 432x288 with 0 Axes&gt;
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98533709-a8745f80-22c6-11eb-8660-ab551e8798ae.png" /></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>&lt;Figure size 432x288 with 0 Axes&gt;
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98533711-a90cf600-22c6-11eb-9bd2-4e60cae88fe4.png" /></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>&lt;Figure size 432x288 with 0 Axes&gt;
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98533713-a90cf600-22c6-11eb-94d7-7c1a40737fba.png" /></p><ul><li>Categorical variables와 Target = 1인 고객 비율을 살펴 보겠습니다.</li><li>Missing value가 있는 변수에서 알 수 있듯이 Missing value를 다른 값으로 대체하는 대신 별도의 범주 값으로 유지하는 것이 좋습니다.</li><li>Missing value가 있는 고객은 보험 청구를 요청할 가능성이 훨씬 더 높은 (경우에 따라 훨씬 더 낮은) 것으로 보입니다</li></ul><p><br /></p><h3 id="92-interval-variables">9.2 Interval variables</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">corr_heatmap</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
    <span class="n">correlations</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">v</span><span class="p">].</span><span class="n">corr</span><span class="p">()</span>

    <span class="c1"># Create color map ranging between two colors
</span>    <span class="n">cmap</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">diverging_palette</span><span class="p">(</span><span class="mi">220</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">as_cmap</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
    <span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">correlations</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s">'.2f'</span><span class="p">,</span>
                <span class="n">square</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">cbar_kws</span><span class="o">=</span><span class="p">{</span><span class="s">"shrink"</span><span class="p">:</span> <span class="p">.</span><span class="mi">75</span><span class="p">})</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">();</span>
    
<span class="n">v</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[(</span><span class="n">meta</span><span class="p">.</span><span class="n">level</span> <span class="o">==</span> <span class="s">'interval'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">meta</span><span class="p">.</span><span class="n">keep</span><span class="p">)].</span><span class="n">index</span>
<span class="n">corr_heatmap</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98533714-a9a58c80-22c6-11eb-8f82-4e10229f63f2.png" /></p><ul><li>Interval variables 간의 상관 관계를 확인합니다.</li><li>heatmap은 변수 간의 상관 관계를 시각화하는 좋은 방법입니다.</li><li>아래의 변수들은 강한 상관 관계를 가집니다.<ul><li>ps_reg_02 and ps_reg_03 (0.7)</li><li>ps_car_12 and ps_car13 (0.67)</li><li>ps_car_12 and ps_car14 (0.58)</li><li>ps_car_13 and ps_car15 (0.67)</li></ul></li><li>Seaborn은 변수들 사이의 (선형) 관계를 시각화할 수 있는 몇 가지 유용한 플롯을 가지고 있다. 우리는 변수들 사이의 관계를 시각화하기 위해 Pairplot 사용할 수 있습니다.</li><li>하지만 Heatmap에서 이미 제한된 수의 상관 변수를 보여 주었기 때문에, 우리는 각각의 높은 상관 관계를 가진 변수들을 개별적으로 살펴보도록 하겠습니다.</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">s</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">)</span>
</pre></table></code></div></div><ul><li>참고: 속도를 높이기 위해 학습 데이터의 샘플을 가져옵니다.</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">sns</span><span class="p">.</span><span class="n">lmplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'ps_reg_02'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'ps_reg_03'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">s</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'target'</span><span class="p">,</span>
           <span class="n">palette</span><span class="o">=</span><span class="s">'Set1'</span><span class="p">,</span> <span class="n">scatter_kws</span><span class="o">=</span><span class="p">{</span><span class="s">'alpha'</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">})</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98533716-a9a58c80-22c6-11eb-9a0a-46c9efaf671a.png" /></p><ul><li>ps_reg_02 및 ps_reg_03 회귀선에서 알 수 있듯이 이러한 변수 사이에는 선형 관계가 있습니다.</li><li>hue 매개 변수는 target = 0과 target = 1에 대한 회귀선이 동일 함을 알 수 있습니다.</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">sns</span><span class="p">.</span><span class="n">lmplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'ps_car_12'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'ps_car_13'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">s</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'target'</span><span class="p">,</span>
           <span class="n">palette</span><span class="o">=</span><span class="s">'Set1'</span><span class="p">,</span> <span class="n">scatter_kws</span><span class="o">=</span><span class="p">{</span><span class="s">'alpha'</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">})</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98533718-aa3e2300-22c6-11eb-9a00-5657932f2ef5.png" /></p><ul><li>ps_car_12, ps_car_13의 선형관계</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">sns</span><span class="p">.</span><span class="n">lmplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'ps_car_12'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'ps_car_14'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">s</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'target'</span><span class="p">,</span>
           <span class="n">palette</span><span class="o">=</span><span class="s">'Set1'</span><span class="p">,</span> <span class="n">scatter_kws</span><span class="o">=</span><span class="p">{</span><span class="s">'alpha'</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">})</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98533719-aad6b980-22c6-11eb-8f76-e9ddc16860a6.png" /></p><ul><li>ps_car_12, ps_car_14의 선형관계</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">sns</span><span class="p">.</span><span class="n">lmplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'ps_car_15'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'ps_car_13'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">s</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'target'</span><span class="p">,</span>
           <span class="n">palette</span><span class="o">=</span><span class="s">'Set1'</span><span class="p">,</span> <span class="n">scatter_kws</span><span class="o">=</span><span class="p">{</span><span class="s">'alpha'</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">})</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98533720-aad6b980-22c6-11eb-8f51-88f97c289088.png" /></p><ul><li>ps_car_15와 ps_car_13</li></ul><p><br /></p><ul><li>변수에 대해 PCA (주성분 분석)를 수행하여 차원을 줄일 수 있습니다.</li><li>하지만 상관 변수의 수가 적기 때문에 모델이 무거운 작업을 수행하도록 할 것입니다.</li></ul><p><br /></p><h3 id="93-checking-the-correlations-betwwen-ordinal-variables">9.3 Checking the correlations betwwen ordinal variables</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">v</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[(</span><span class="n">meta</span><span class="p">.</span><span class="n">level</span> <span class="o">==</span> <span class="s">'ordinal'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">meta</span><span class="p">.</span><span class="n">keep</span><span class="p">)].</span><span class="n">index</span>
<span class="n">corr_heatmap</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98533721-ab6f5000-22c6-11eb-876d-4596468499fc.png" /></p><ul><li>Ordinal variables의 경우 많은 상관 관계를 볼 수 없다.</li><li>하지만 Tatget Value으로 그룹화할 때 분포가 어떻게 되는지 살펴볼 수 있다.</li></ul><p><br /></p><h2 id="10-feature-engineering">10. Feature engineering</h2><hr /><h3 id="101-creating-dummy-variables">10.1 Creating dummy variables</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">v</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[(</span><span class="n">meta</span><span class="p">.</span><span class="n">level</span> <span class="o">==</span> <span class="s">'nominal'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">meta</span><span class="p">.</span><span class="n">keep</span><span class="p">)].</span><span class="n">index</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Before dummification we have </span><span class="si">{</span><span class="n">train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s"> variables in train.'</span><span class="p">)</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span> <span class="n">v</span><span class="p">,</span> <span class="n">drop_first</span><span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'After dummification we have </span><span class="si">{</span><span class="n">train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s"> variables in train.'</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>Before dummification we have 57 variables in train.
After dummification we have 109 variables in train.
</pre></table></code></div></div><ul><li>Categorical variables의 값은 순서나 크기를 나타내지 않는다. 예를 들어 범주 2는 범주 1의 두 배가 아니다.</li><li>그러므로 우리는 그것을 다룰 더미 변수를 만들 수 있다.</li><li>이 정보는 원래 변수의 범주에 대해 생성된 다른 더미 변수에서 파생될 수 있으므로 첫 번째 더미 변수를 삭제한다.</li><li>총 52개의 dummy 변수를 생성하였습니다.</li></ul><p><br /></p><h3 id="102-creating-interaction-variables">10.2 Creating interaction variables</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="n">v</span> <span class="o">=</span> <span class="n">meta</span><span class="p">[(</span><span class="n">meta</span><span class="p">.</span><span class="n">level</span> <span class="o">==</span> <span class="s">'interval'</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">meta</span><span class="p">.</span><span class="n">keep</span><span class="p">)].</span><span class="n">index</span>

<span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">interaction_only</span><span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="n">include_bias</span><span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="n">interactions</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">poly</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">v</span><span class="p">]),</span> <span class="n">columns</span><span class="o">=</span><span class="n">poly</span><span class="p">.</span><span class="n">get_feature_names</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
<span class="n">interactions</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span> <span class="c1"># Remove the original columns
</span>
<span class="c1"># Concat the interaction variables to the train data
</span><span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Before creating interactions we have </span><span class="si">{</span><span class="n">train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s"> variables in train.'</span><span class="p">)</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span><span class="n">train</span><span class="p">,</span> <span class="n">interactions</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'After creating interactions we have </span><span class="si">{</span><span class="n">train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s"> variables in train.'</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>Before creating interactions we have 109 variables in train.
After creating interactions we have 164 variables in train.
</pre></table></code></div></div><ul><li>get_feature_names 메서드를 사용해서 편하게 interactions variables을 추가하였습니다.</li></ul><p><br /></p><h2 id="11-feature-selection">11. Feature selection</h2><hr /><h3 id="111-removing-features-with-low-or-zero-variance">11.1 Removing features with low or zero variance</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="n">selector</span> <span class="o">=</span> <span class="n">VarianceThreshold</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">selector</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'id'</span><span class="p">,</span> <span class="s">'target'</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">))</span> <span class="c1"># Fit to train without id and target variables
</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">vectorize</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="ow">not</span> <span class="n">x</span><span class="p">)</span> <span class="c1"># Function to toggle boolean_array elements
</span><span class="n">v</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'id'</span><span class="p">,</span> <span class="s">'target'</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">).</span><span class="n">columns</span><span class="p">[</span><span class="n">f</span><span class="p">(</span><span class="n">selector</span><span class="p">.</span><span class="n">get_support</span><span class="p">())]</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="si">}</span><span class="s"> variables have too low variance.'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'These variables are </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>28 variables have too low variance.
These variables are ['ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_car_12', 'ps_car_14', 'ps_car_11_cat_te', 'ps_ind_05_cat_2', 'ps_ind_05_cat_5', 'ps_car_01_cat_1', 'ps_car_01_cat_2', 'ps_car_04_cat_3', 'ps_car_04_cat_4', 'ps_car_04_cat_5', 'ps_car_04_cat_6', 'ps_car_04_cat_7', 'ps_car_06_cat_2', 'ps_car_06_cat_5', 'ps_car_06_cat_8', 'ps_car_06_cat_12', 'ps_car_06_cat_16', 'ps_car_06_cat_17', 'ps_car_09_cat_4', 'ps_car_10_cat_1', 'ps_car_10_cat_2', 'ps_car_12^2', 'ps_car_12 ps_car_14', 'ps_car_14^2']
</pre></table></code></div></div><ul><li>변동이 없거나 매우 낮은 특성을 제거하는 것입니다. (분산이 0인것)</li><li>Sklearn에는 VarianceThreshold라는 편리한 방법이 있습니다. 기본적으로 분산이 0 인 기능을 제거합니다.</li><li>이전 단계에서 0 분산 변수가 없음을 확인 했으므로이 대회에는 적용되지 않습니다.</li><li>그러나 분산이 1 % 미만인 특성을 제거하면 31 개의 변수가 제거됩니다.</li><li>분산을 기반으로 선택하면 다소 많은 변수(31개)를 잃게됩니다. 그러나 변수가 너무 많지 않기 때문에 classifier가 선택하도록 할 것입니다.</li><li>더 많은 변수가있는 데이터 세트의 경우 처리 시간을 줄일 수 있습니다.</li><li>Sklearn은 또한 다른 기능 선택 방법과 함께 제공됩니다.</li><li>이러한 메서드 중 하나는 another classifier가 최상의 기능을 선택하고 계속 진행하도록하는 SelectFromModel입니다.</li><li>아래에서는 Random Forest로 수행하겠습니다.</li></ul><p><br /></p><h3 id="112-selecting-features-with-a-random-forest-and-selectfrommodel">11.2 Selecting features with a Random Forest and SelectFromModel</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="n">X_train</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'id'</span><span class="p">,</span> <span class="s">'target'</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'target'</span><span class="p">]</span>

<span class="n">feat_labels</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">columns</span>

<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">rf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">importances</span> <span class="o">=</span> <span class="n">rf</span><span class="p">.</span><span class="n">feature_importances_</span>

<span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">rf</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'%2d) %-*s %f'</span> <span class="o">%</span> <span class="p">(</span><span class="n">f</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="n">feat_labels</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="n">f</span><span class="p">]],</span> <span class="n">importances</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="n">f</span><span class="p">]]))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
</pre><td class="rouge-code"><pre> 1) ps_car_11_cat_te               0.021062
 2) ps_car_13^2                    0.017319
 3) ps_car_13                      0.017288
 4) ps_car_12 ps_car_13            0.017244
 5) ps_car_13 ps_car_14            0.017148
 6) ps_reg_03 ps_car_13            0.017067
 7) ps_car_13 ps_car_15            0.016812
 8) ps_reg_01 ps_car_13            0.016788
 9) ps_reg_03 ps_car_14            0.016261
10) ps_reg_03 ps_car_12            0.015580
11) ps_reg_03 ps_car_15            0.015165
12) ps_car_14 ps_car_15            0.015012
13) ps_car_13 ps_calc_01           0.014751
14) ps_car_13 ps_calc_03           0.014726
15) ps_car_13 ps_calc_02           0.014673
16) ps_reg_02 ps_car_13            0.014671
17) ps_reg_01 ps_reg_03            0.014666
18) ps_reg_01 ps_car_14            0.014455
19) ps_reg_03^2                    0.014283
20) ps_reg_03                      0.014255
21) ps_reg_03 ps_calc_02           0.013804
22) ps_reg_03 ps_calc_03           0.013758
23) ps_reg_03 ps_calc_01           0.013711
24) ps_calc_10                     0.013696
25) ps_car_14 ps_calc_02           0.013633
26) ps_car_14 ps_calc_01           0.013542
27) ps_car_14 ps_calc_03           0.013499
28) ps_calc_14                     0.013363
29) ps_car_12 ps_car_14            0.012968
30) ps_ind_03                      0.012923
31) ps_car_14                      0.012806
32) ps_car_14^2                    0.012734
33) ps_reg_02 ps_car_14            0.012671
34) ps_calc_11                     0.012585
35) ps_reg_02 ps_reg_03            0.012559
36) ps_ind_15                      0.012153
37) ps_car_12 ps_car_15            0.010944
38) ps_car_15 ps_calc_03           0.010888
39) ps_car_15 ps_calc_02           0.010879
40) ps_car_15 ps_calc_01           0.010851
41) ps_calc_13                     0.010479
42) ps_car_12 ps_calc_01           0.010467
43) ps_car_12 ps_calc_03           0.010340
44) ps_car_12 ps_calc_02           0.010287
45) ps_reg_02 ps_car_15            0.010213
46) ps_reg_01 ps_car_15            0.010201
47) ps_calc_02 ps_calc_03          0.010092
48) ps_calc_01 ps_calc_03          0.010010
49) ps_calc_01 ps_calc_02          0.010005
50) ps_calc_07                     0.009837
51) ps_calc_08                     0.009801
52) ps_reg_01 ps_car_12            0.009480
53) ps_reg_02 ps_calc_01           0.009281
54) ps_reg_02 ps_car_12            0.009270
55) ps_reg_02 ps_calc_03           0.009218
56) ps_reg_02 ps_calc_02           0.009210
57) ps_reg_01 ps_calc_03           0.009043
58) ps_reg_01 ps_calc_01           0.009036
59) ps_calc_06                     0.009021
60) ps_reg_01 ps_calc_02           0.008985
61) ps_calc_09                     0.008808
62) ps_ind_01                      0.008519
63) ps_calc_05                     0.008296
64) ps_calc_04                     0.008122
65) ps_calc_12                     0.008066
66) ps_reg_01 ps_reg_02            0.008024
67) ps_car_15^2                    0.006172
68) ps_car_15                      0.006147
69) ps_calc_01                     0.005971
70) ps_calc_03^2                   0.005967
71) ps_calc_03                     0.005955
72) ps_calc_02                     0.005949
73) ps_calc_01^2                   0.005949
74) ps_calc_02^2                   0.005930
75) ps_car_12                      0.005373
76) ps_car_12^2                    0.005366
77) ps_reg_02^2                    0.005007
78) ps_reg_02                      0.004993
79) ps_reg_01                      0.004152
80) ps_reg_01^2                    0.004116
81) ps_car_11                      0.003787
82) ps_ind_05_cat_0                0.003570
83) ps_ind_17_bin                  0.002847
84) ps_calc_17_bin                 0.002692
85) ps_calc_16_bin                 0.002611
86) ps_calc_19_bin                 0.002534
87) ps_calc_18_bin                 0.002485
88) ps_ind_16_bin                  0.002397
89) ps_ind_04_cat_0                0.002387
90) ps_car_01_cat_11               0.002376
91) ps_ind_04_cat_1                0.002370
92) ps_ind_07_bin                  0.002327
93) ps_car_09_cat_2                0.002292
94) ps_ind_02_cat_1                0.002249
95) ps_car_09_cat_0                0.002115
96) ps_car_01_cat_7                0.002103
97) ps_ind_02_cat_2                0.002093
98) ps_calc_20_bin                 0.002081
99) ps_ind_06_bin                  0.002042
100) ps_calc_15_bin                 0.001985
101) ps_car_06_cat_1                0.001983
102) ps_car_07_cat_1                0.001971
103) ps_ind_08_bin                  0.001952
104) ps_car_09_cat_1                0.001833
105) ps_car_06_cat_11               0.001810
106) ps_ind_09_bin                  0.001731
107) ps_ind_18_bin                  0.001718
108) ps_car_01_cat_10               0.001593
109) ps_car_01_cat_9                0.001580
110) ps_car_06_cat_14               0.001549
111) ps_car_01_cat_6                0.001547
112) ps_car_01_cat_4                0.001545
113) ps_ind_05_cat_6                0.001502
114) ps_ind_02_cat_3                0.001437
115) ps_car_07_cat_0                0.001388
116) ps_car_08_cat_1                0.001345
117) ps_car_01_cat_8                0.001335
118) ps_car_02_cat_1                0.001329
119) ps_car_02_cat_0                0.001314
120) ps_car_06_cat_4                0.001232
121) ps_ind_05_cat_4                0.001212
122) ps_car_01_cat_5                0.001151
123) ps_ind_02_cat_4                0.001149
124) ps_car_06_cat_6                0.001111
125) ps_car_06_cat_10               0.001066
126) ps_ind_05_cat_2                0.001025
127) ps_car_04_cat_1                0.001017
128) ps_car_06_cat_7                0.000991
129) ps_car_04_cat_2                0.000979
130) ps_car_01_cat_3                0.000899
131) ps_car_09_cat_3                0.000879
132) ps_car_01_cat_0                0.000872
133) ps_car_06_cat_15               0.000851
134) ps_ind_14                      0.000846
135) ps_car_06_cat_9                0.000796
136) ps_ind_05_cat_1                0.000740
137) ps_car_06_cat_3                0.000706
138) ps_car_10_cat_1                0.000700
139) ps_ind_12_bin                  0.000689
140) ps_ind_05_cat_3                0.000671
141) ps_car_09_cat_4                0.000631
142) ps_car_01_cat_2                0.000562
143) ps_car_04_cat_8                0.000561
144) ps_car_06_cat_17               0.000511
145) ps_car_06_cat_16               0.000481
146) ps_car_04_cat_9                0.000433
147) ps_car_06_cat_12               0.000422
148) ps_car_06_cat_13               0.000385
149) ps_car_01_cat_1                0.000379
150) ps_ind_05_cat_5                0.000305
151) ps_car_06_cat_5                0.000283
152) ps_ind_11_bin                  0.000218
153) ps_car_04_cat_6                0.000207
154) ps_ind_13_bin                  0.000148
155) ps_car_04_cat_3                0.000146
156) ps_car_06_cat_2                0.000137
157) ps_car_06_cat_8                0.000099
158) ps_car_04_cat_5                0.000098
159) ps_car_04_cat_7                0.000082
160) ps_ind_10_bin                  0.000072
161) ps_car_10_cat_2                0.000062
162) ps_car_04_cat_4                0.000044
</pre></table></code></div></div><ul><li>여기서는 랜덤 포레스트의 feature importances를 기준으로 기능 선택을 할 것입니다.</li><li>Sklearn의 SelectFromModel을 사용하면 유지할 변수 수를 지정할 수 있습니다.</li><li>feature importances 수준에 대한 threshold를 수동으로 설정할 수 있습니다.</li><li>그러나 우리는 단순히 상위 50 % 최고의 변수를 선택합니다.</li><li>위의 코드는 Sebastian Raschka의 GitHub 저장소에서 가져 왔습니다.</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">sfm</span> <span class="o">=</span> <span class="n">SelectFromModel</span><span class="p">(</span><span class="n">rf</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="s">'median'</span><span class="p">,</span> <span class="n">prefit</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Number of features before selection : </span><span class="si">{</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>

<span class="n">n_features</span> <span class="o">=</span> <span class="n">sfm</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">).</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Number of features after selection : </span><span class="si">{</span><span class="n">n_features</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="n">selected_vars</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">feat_labels</span><span class="p">[</span><span class="n">sfm</span><span class="p">.</span><span class="n">get_support</span><span class="p">()])</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>Number of features before selection : 162
Number of features after selection : 81
</pre></table></code></div></div><ul><li>SelectFromModel을 사용하여 사용할 prefit classifier와 feature importances에 대한 threshold을 지정할 수 있습니다.</li><li>get_support 메소드를 사용하면 train 데이터의 변수 수를 제한 할 수 있습니다.</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">train</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">selected_vars</span> <span class="o">+</span> <span class="p">[</span><span class="s">'target'</span><span class="p">]]</span>
</pre></table></code></div></div><ul><li>train 데이터에 target까지 더함</li></ul><p><br /></p><h2 id="12-feature-scaling">12. Feature scaling</h2><hr /><h3 id="121-feature-scaling">12.1 Feature scaling</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">scaler</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'target'</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre>array([[-0.45941104, -1.26665356,  1.05087653, ..., -0.72553616,
        -1.01071913, -1.06173767],
       [ 1.55538958,  0.95034274, -0.63847299, ..., -1.06120876,
        -1.01071913,  0.27907892],
       [ 1.05168943, -0.52765479, -0.92003125, ...,  1.95984463,
        -0.56215309, -1.02449277],
       ...,
       [-0.9631112 ,  0.58084336,  0.48776003, ..., -0.46445747,
         0.18545696,  0.27907892],
       [-0.9631112 , -0.89715418, -1.48314775, ..., -0.91202093,
        -0.41263108,  0.27907892],
       [-0.45941104, -1.26665356,  1.61399304, ...,  0.28148164,
        -0.11358706, -0.72653353]])
</pre></table></code></div></div><ul><li>train 데이터에 standardscaler를 적용 할 수 있습니다.</li><li>이 작업이 완료되면 일부 classifier가 더 잘 작동됩니다.</li></ul><p><br /></p><h2 id="13-conclusion">13. Conclusion</h2><hr /><h3 id="131-conclusion">13.1 Conclusion</h3><ul><li>Porto Seguro Safe Driver Prediction의 EDA Note book</li><li>Kaggle 필사를 진행 한것입니다.</li></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/kaggle/'>Kaggle</a>, <a href='/categories/porto-seguro%E2%80%99s-safe-driver-prediction/'>Porto Seguro’s Safe Driver Prediction</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/kaggle-transcription/" class="post-tag no-text-decoration" >Kaggle Transcription</a> <a href="/tags/porto-seguro%E2%80%99s-safe-driver-prediction/" class="post-tag no-text-decoration" >Porto Seguro’s Safe Driver Prediction</a> <a href="/tags/eda/" class="post-tag no-text-decoration" >EDA</a> <a href="/tags/sklearn/" class="post-tag no-text-decoration" >Sklearn</a> <a href="/tags/random-forest/" class="post-tag no-text-decoration" >Random Forest</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><!-- Post sharing snippet v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Porto Seguro’s Safe Driver Prediction 데이터 Preparation & Exploration - Data Include Me&url=https://datainclude.me/posts/Data_Preparation_and_Exploration/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Porto Seguro’s Safe Driver Prediction 데이터 Preparation & Exploration - Data Include Me&u=https://datainclude.me/posts/Data_Preparation_and_Exploration/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Porto Seguro’s Safe Driver Prediction 데이터 Preparation & Exploration - Data Include Me&url=https://datainclude.me/posts/Data_Preparation_and_Exploration/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><!-- The Panel on right side (Desktop views) v2.3 © 2024 Your Name MIT License --><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><h3 data-toc-skip>Recent Update</h3><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li class="recent-item"> <a href="/posts/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C_%EC%BB%B4%ED%93%A8%ED%8C%85_%EA%B0%80%EC%83%81%ED%99%94/">클라우드 컴퓨팅 - 가상화</a> <span class="text-muted small">2024-10-28</span></li><li class="recent-item"> <a href="/posts/gemini_api_%EC%82%AC%EC%9A%A9%ED%95%B4%EB%B3%B4%EA%B8%B0/">Gemini API 사용해보기</a> <span class="text-muted small">2024-03-12</span></li><li class="recent-item"> <a href="/posts/Ollama%EC%99%80_Python_%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC_LLaMa2%EB%A5%BC_%EB%A1%9C%EC%BB%AC%EC%97%90%EC%84%9C_%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/">Ollama와 Python 라이브러리를 이용하여 LLaMa2를 로컬에서 사용하기</a> <span class="text-muted small">2024-02-13</span></li><li class="recent-item"> <a href="/posts/Mistral_7B_Fine_Tuning/">Mistral 7B 파인튜닝(Fine Tuning)하기</a> <span class="text-muted small">2023-10-25</span></li><li class="recent-item"> <a href="/posts/Penn_Fudan%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EA%B0%9D%EC%B2%B4_%ED%83%90%EC%A7%80_%EB%B6%84%ED%95%A0/">Penn-Fudan으로 알아보는 객체 탐지(Object Detection), 분할(Segmentation) with FasterRCNN</a> <span class="text-muted small">2023-10-23</span></li></ul></div><div id="access-tags"><h3 data-toc-skip>Trending Tags</h3><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/tensorflow/">Tensorflow</a> <a class="post-tag" href="/tags/sklearn/">Sklearn</a> <a class="post-tag" href="/tags/round/">Round</a> <a class="post-tag" href="/tags/python-lv0/">Python Lv0</a> <a class="post-tag" href="/tags/pca/">PCA</a> <a class="post-tag" href="/tags/eda/">EDA</a> <a class="post-tag" href="/tags/distinct/">Distinct</a> <a class="post-tag" href="/tags/random-forest/">Random Forest</a> <a class="post-tag" href="/tags/beautifulsoup/">Beautifulsoup</a> <a class="post-tag" href="/tags/baekjoon/">Baekjoon</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><h3 data-toc-skip class="pl-3 pt-2 mb-2">Contents</h3><nav id="toc" data-toggle="toc"></nav></div></div><style> .recent-item { margin-bottom: 0.5rem; } .recent-item a { color: var(--link-color); } .recent-item .small { font-size: 0.75rem; margin-left: 0.5rem; }</style></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"> <!-- Recommend the other 3 posts according to the tags and categories of the current post, if the number is not enough, use the other latest posts to supplement. v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/%ED%83%80%EC%9D%B4%ED%83%80%EB%8B%89_%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC_with_Kaggle/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Sep 19, 2020 <i class="unloaded">2020-09-19T20:30:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>타이타닉 튜토리얼</h3><div class="text-muted small"><p> 타이타닉 튜토리얼 만약 데이터 사이언스, 머신러닝 또는 캐글에서 어떤 것을 해야하는 지 잘 모르는 newbie 라면, 타이타닉을 하시는 게 가장 좋은 선택입니다. 타이타닉은 아시다시피, 사상 최대 해난사고로써, 1,500여명의 희생자가 생겼습니다. 우리는 이 튜토리얼에서 타이타닉에 탑승한 사람들의 신상정보를 활용하여, 승선한 사람들의 생존...</p></div></div></a></div><div class="card"> <a href="/posts/Prediction%EC%9D%84_%EC%9C%84%ED%95%9C_Titanic_EDA/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Nov 5, 2020 <i class="unloaded">2020-11-05T00:30:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Prediction을 위한 Titanic EDA</h3><div class="text-muted small"><p> The sinking of the Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out...</p></div></div></a></div><div class="card"> <a href="/posts/%ED%83%80%EC%9D%B4%ED%83%80%EB%8B%89_%ED%83%914_%EC%95%99%EC%83%81%EB%B8%94_%EB%AA%A8%EB%8D%B8%EB%A7%81/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Nov 5, 2020 <i class="unloaded">2020-11-05T00:30:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>타이타닉 탑4% 앙상블 모델링</h3><div class="text-muted small"><p> 1 Introduction 2 Load and check data 2.1 load data 2.2 Outlier detection 2.3 joining train and test set 2.4 check for null and missing values 3 Feature a...</p></div></div></a></div></div></div><!-- Navigation buttons at the bottom of the post. v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --><div class="post-navigation d-flex justify-content-between"> <a href="/posts/%ED%83%80%EC%9D%B4%ED%83%80%EB%8B%89_%ED%83%914_%EC%95%99%EC%83%81%EB%B8%94_%EB%AA%A8%EB%8D%B8%EB%A7%81/" class="btn btn-outline-primary"><p>타이타닉 탑4% 앙상블 모델링</p></a> <a href="/posts/%ED%8C%90%EB%8B%A4%EC%8A%A4(Pandas)_%EC%BB%AC%EB%9F%BC%EA%B3%BC_%ED%96%89_%EA%B8%B8%EA%B2%8C_%EB%B3%B4%EA%B8%B0/" class="btn btn-outline-primary"><p>판다스(Pandas) 컬럼과 행 길게 보기</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('#post-wrapper img'); const observer = lozad(imgs); observer.observe(); </script></div><!-- The Search results v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/tensorflow/">Tensorflow</a> <a class="post-tag" href="/tags/sklearn/">Sklearn</a> <a class="post-tag" href="/tags/round/">Round</a> <a class="post-tag" href="/tags/python-lv0/">Python Lv0</a> <a class="post-tag" href="/tags/pca/">PCA</a> <a class="post-tag" href="/tags/eda/">EDA</a> <a class="post-tag" href="/tags/distinct/">Distinct</a> <a class="post-tag" href="/tags/random-forest/">Random Forest</a> <a class="post-tag" href="/tags/beautifulsoup/">Beautifulsoup</a> <a class="post-tag" href="/tags/baekjoon/">Baekjoon</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <!-- The GA snippet v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <!-- Jekyll Simple Search loader v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://datainclude.me{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script>
