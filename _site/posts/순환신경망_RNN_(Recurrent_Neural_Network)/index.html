<!DOCTYPE html><html lang="ko" mode="light" > <!-- The Head v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>순환신경망 - RNN (Recurrent Neural Network) | Data Include Me</title><meta name="generator" content="Jekyll v3.9.3" /><meta property="og:title" content="순환신경망 - RNN (Recurrent Neural Network)" /><meta name="author" content="HyunMin Kim" /><meta property="og:locale" content="ko" /><meta name="description" content="1. Simple RNN 1.1 순환 신경망" /><meta property="og:description" content="1. Simple RNN 1.1 순환 신경망" /><link rel="canonical" href="https://datainclude.me/posts/%EC%88%9C%ED%99%98%EC%8B%A0%EA%B2%BD%EB%A7%9D_RNN_(Recurrent_Neural_Network)/" /><meta property="og:url" content="https://datainclude.me/posts/%EC%88%9C%ED%99%98%EC%8B%A0%EA%B2%BD%EB%A7%9D_RNN_(Recurrent_Neural_Network)/" /><meta property="og:site_name" content="Data Include Me" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-10-30T00:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="순환신경망 - RNN (Recurrent Neural Network)" /><meta name="twitter:site" content="@" /><meta name="twitter:creator" content="@HyunMin Kim" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"HyunMin Kim"},"dateModified":"2020-10-30T00:00:00+09:00","datePublished":"2020-10-30T00:00:00+09:00","description":"1. Simple RNN 1.1 순환 신경망","headline":"순환신경망 - RNN (Recurrent Neural Network)","mainEntityOfPage":{"@type":"WebPage","@id":"https://datainclude.me/posts/%EC%88%9C%ED%99%98%EC%8B%A0%EA%B2%BD%EB%A7%9D_RNN_(Recurrent_Neural_Network)/"},"url":"https://datainclude.me/posts/%EC%88%9C%ED%99%98%EC%8B%A0%EA%B2%BD%EB%A7%9D_RNN_(Recurrent_Neural_Network)/"}</script><meta property="og:image" content="https://datainclude.me/assets/img/sample/avatar.jpg" /> <!-- The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps Generated by: https://www.favicon-generator.org/ v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT license --><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="36x36" href="/assets/img/favicons/android-icon-36x36.png"><link rel="icon" type="image/png" sizes="48x48" href="/assets/img/favicons/android-icon-48x48.png"><link rel="icon" type="image/png" sizes="72x72" href="/assets/img/favicons/android-icon-72x72.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/android-icon-96x96.png"><link rel="icon" type="image/png" sizes="144x144" href="/assets/img/favicons/android-icon-144x144.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="70x70" href="/assets/img/favicons/ms-icon-70x70.png"><link rel="icon" type="image/png" sizes="144x144" href="/assets/img/favicons/ms-icon-144x144.png"><link rel="icon" type="image/png" sizes="150x150" href="/assets/img/favicons/ms-icon-150x150.png"><link rel="icon" type="image/png" sizes="310x310" href="/assets/img/favicons/ms-icon-310x310.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preload" href="https://www.googletagmanager.com/gtm.js?id=GTM-MW9VRMW9" as="script"> <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src= 'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f); })(window,document,'script','dataLayer','GTM-MW9VRMW9');</script><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="preload" as="style" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous" media="print" onload="this.media='all'"> <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"> </noscript> <!-- CSS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --><link rel="preload" as="style" href="/assets/css/post.css"><link rel="stylesheet" href="/assets/css/post.css"><link rel="preload" as="style" href="/assets/css/lib/bootstrap-toc.min.css"><link rel="stylesheet" href="/assets/css/lib/bootstrap-toc.min.css" /><link rel="preload" as="script" href="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" async></script> <!-- JS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --> <script src="/assets/js/post.min.js" async></script> <script src="/app.js" defer></script><body data-spy="scroll" data-target="#toc"> <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MW9VRMW9" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="sidebar" class="d-flex flex-column"> <!-- The Side Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="nav-wrapper"><div id="profile-wrapper" class="d-flex flex-column"><div id="avatar" class="d-flex justify-content-center"> <a href="/" alt="avatar"> <img src="/assets/img/sample/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="profile-text mt-3"><div class="site-title"> <a href="/">Data Include Me</a></div><div class="site-subtitle font-italic">Data Science Blog</div></div></div><ul class="nav flex-column"><li class="nav-item d-flex justify-content-center "> <a href="/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/categories/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/tags/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/archives/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/about/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></li></ul></div><div class="sidebar-bottom d-flex flex-wrap justify-content-around mt-4"> <a href="https://github.com/hmkim312" target="_blank"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/" target="_blank"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:window.open('mailto:' + ['sanarial312','gmail.com'].join('@'))" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" > <i class="fas fa-rss"></i> </a></div></div><!-- The Top Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>순환신경망 - RNN (Recurrent Neural Network)</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"> <!-- Refactor the HTML structure. --> <!-- Suroundding the markdown table with '<div class="table-wrapper">. and '</div>' --> <!-- Fixed kramdown code highlight rendering: https://github.com/penibelst/jekyll-compress-html/issues/101 https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901 --><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"> <script type="text/javascript"> var lazyloadads = false; function loadAds() { if (!lazyloadads) { var script = document.createElement("script"); script.type = "text/javascript"; script.async = true; script.src = "https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7594406644928408"; document.body.appendChild(script); lazyloadads = true; } } window.addEventListener("mousemove", loadAds, { once: true }); window.addEventListener('touchstart', loadAds, { once: true }); </script><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>순환신경망 - RNN (Recurrent Neural Network)</h1><div class="post-meta text-muted d-flex flex-column"><div> Posted <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Fri, Oct 30, 2020, 12:00 AM +0900" > Oct 30, 2020 <i class="unloaded">2020-10-30T00:00:00+09:00</i> </span> by <span class="author"> HyunMin Kim </span></div><a href="https://hits.seeyoufarm.com"> <img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https://datainclude.me/posts/%EC%88%9C%ED%99%98%EC%8B%A0%EA%B2%BD%EB%A7%9D_RNN_(Recurrent_Neural_Network)/%2F&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=views&edge_flat=false" alt="페이지 조회수 뱃지", width: 100%;, height: 100%;/> </a></div><div class="post-content"><h2 id="1-simple-rnn">1. Simple RNN</h2><hr /><h3 id="11-순환-신경망">1.1 순환 신경망</h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/97583622-806d3c80-1a3a-11eb-9135-f7d79096fc65.png" /></p><ul><li>순서가 있는 데이터를 입력으로 받고 변화하는 입력에 대한 출력을 얻음</li></ul><p><br /></p><h3 id="12-rnn의-한-셀-모양">1.2 RNN의 한 셀 모양</h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/97583770-a4c91900-1a3a-11eb-99c5-22db43a40645.png" /></p><p><br /></p><h2 id="2-rnn-실습">2. RNN 실습</h2><hr /><h3 id="21-간단한-time-stamp-데이터로-rnn-실습">2.1 간단한 Time Stamp 데이터로 RNN 실습</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">X</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">Y</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">):</span>
    
    <span class="n">lst</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">4</span><span class="p">))</span>
    
    <span class="n">X</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">c</span> <span class="p">:</span> <span class="p">[</span><span class="n">c</span><span class="o">/</span><span class="mi">10</span><span class="p">],</span> <span class="n">lst</span><span class="p">)))</span>
    <span class="n">Y</span><span class="p">.</span><span class="n">append</span><span class="p">((</span><span class="n">i</span> <span class="o">+</span><span class="mi">4</span><span class="p">)</span><span class="o">/</span><span class="mi">10</span><span class="p">)</span>
    
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)):</span>
    <span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="k">print</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
</pre><td class="rouge-code"><pre>[[0. ]
 [0.1]
 [0.2]
 [0.3]] 0.4

[[0.1]
 [0.2]
 [0.3]
 [0.4]] 0.5

[[0.2]
 [0.3]
 [0.4]
 [0.5]] 0.6

[[0.3]
 [0.4]
 [0.5]
 [0.6]] 0.7

[[0.4]
 [0.5]
 [0.6]
 [0.7]] 0.8

[[0.5]
 [0.6]
 [0.7]
 [0.8]] 0.9
</pre></table></code></div></div><ul><li>0.0 ~ 0.3 -&gt; 0.4</li><li>0.1 ~ 0.4 -&gt; 0.5</li><li>이런식의 데이터</li></ul><p><br /></p><h3 id="22-simple-rnn-구성">2.2 Simple RNN 구성</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">SimpleRNN</span><span class="p">(</span>
        <span class="n">units</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="s">'adam'</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="s">'mse'</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre>Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn (SimpleRNN)       (None, 10)                120       
_________________________________________________________________
dense (Dense)                (None, 1)                 11        
=================================================================
Total params: 131
Trainable params: 131
Non-trainable params: 0
_________________________________________________________________
</pre></table></code></div></div><ul><li>input_shape이 4.1 이라는것은 timesteps가 4, input_dim이 1</li><li>units : SimpleRNN 레이어에 존재하는 뉴런의 수</li><li>return_sequences : 출력으로 시퀀스 전체를 출력할지 여부</li></ul><p><br /></p><h3 id="23-모델의-구성도">2.3 모델의 구성도</h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/97584902-dee6ea80-1a3b-11eb-8d23-82f123b4df7d.png" /></p><p><br /></p><h3 id="24-학습">2.4 학습</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>&lt;tensorflow.python.keras.callbacks.History at 0x7fd850d79d90&gt;
</pre></table></code></div></div><p><br /></p><h3 id="25-예측">2.5 예측</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[[</span><span class="o">-</span><span class="mf">0.1</span><span class="p">],[</span><span class="mf">0.0</span><span class="p">],[</span><span class="mf">0.1</span><span class="p">],[</span><span class="mf">0.2</span><span class="p">]]]))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>array([[0.29263034]], dtype=float32)
</pre></table></code></div></div><ul><li>-0.1 ~ 0.2 다음은 0.3이 나와야하는데 0.2926이 나오는것 보니, 비슷은 해보인다</li></ul><p><br /></p><h3 id="26-simple-rnn의-단점">2.6 Simple RNN의 단점</h3><ul><li>Long-Term Dependency : 입력 데이터가 길어지면 학습 능력이떨어짐</li><li>현재의 답을 얻기 위해 과거의 정보에 의존해야하는 RNN, 하지만 과거 시점이 현재와 너무 멀어지면 문제를 풀기 어려움</li></ul><p><br /></p><h2 id="3-lstm">3. LSTM</h2><hr /><h3 id="31-lstm">3.1 LSTM</h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/97585488-86fcb380-1a3c-11eb-8c42-6b6b49bbeb9f.png" /></p><ul><li>Simple RNN의 장기 의존성 문제를 해결하기 위한 알고리즘</li><li>Time Step을 가르지르며 셀 상태가 보존</li></ul><p><br /></p><h2 id="4-lstm-실습">4. LSTM 실습</h2><hr /><h3 id="41-예제">4.1 예제</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="n">X</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">Y</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">lst</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">replace</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
    <span class="n">zeros</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">zeros</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">X</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">zeros</span><span class="p">,</span> <span class="n">lst</span><span class="p">))))</span>
    <span class="n">Y</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">prod</span><span class="p">(</span><span class="n">lst</span><span class="p">[</span><span class="n">idx</span><span class="p">]))</span>

<span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
</pre><td class="rouge-code"><pre>[[0.         0.80008966]
 [0.         0.30359938]
 [0.         0.87163122]
 [0.         0.7413119 ]
 [0.         0.11942425]
 [0.         0.27352657]
 [0.         0.76802368]
 [0.         0.14609984]
 [0.         0.18106652]
 [0.         0.01171455]
 [0.         0.92461019]
 [0.         0.27576429]
 [0.         0.8144809 ]
 [0.         0.15831039]
 [0.         0.03956734]
 [0.         0.74086254]
 [0.         0.71514832]
 [0.         0.05864715]
 [0.         0.2165122 ]
 [0.         0.67536621]
 [0.         0.83084592]
 [0.         0.02361978]
 [0.         0.96610312]
 [0.         0.65990591]
 [0.         0.97501121]
 [0.         0.56664119]
 [0.         0.98403786]
 [0.         0.61782982]
 [0.         0.98569084]
 [0.         0.93561593]
 [0.         0.06791456]
 [0.         0.54954407]
 [0.         0.49462747]
 [0.         0.74715515]
 [0.         0.31521783]
 [0.         0.72605368]
 [0.         0.62690249]
 [0.         0.31447398]
 [0.         0.15953186]
 [0.         0.12764518]
 [0.         0.07478073]
 [0.         0.00354316]
 [0.         0.28523369]
 [0.         0.06752979]
 [0.         0.83515363]
 [0.         0.85055375]
 [1.         0.88817727]
 [0.         0.00453563]
 [0.         0.30259626]
 [0.         0.93822272]
 [0.         0.10927959]
 [0.         0.92989588]
 [0.         0.47279259]
 [0.         0.40970746]
 [0.         0.32246528]
 [0.         0.73999216]
 [0.         0.62096274]
 [0.         0.48123822]
 [0.         0.78971826]
 [0.         0.89842873]
 [0.         0.87298911]
 [0.         0.55976035]
 [0.         0.82265406]
 [0.         0.11174719]
 [0.         0.00784555]
 [0.         0.6851193 ]
 [0.         0.75893765]
 [0.         0.50567489]
 [0.         0.01901901]
 [0.         0.7303575 ]
 [0.         0.68753022]
 [0.         0.45555408]
 [0.         0.47891555]
 [0.         0.73691181]
 [0.         0.05961961]
 [0.         0.94850333]
 [0.         0.79596296]
 [0.         0.86432501]
 [0.         0.49509131]
 [0.         0.1899921 ]
 [0.         0.25937904]
 [0.         0.52905918]
 [0.         0.21323525]
 [0.         0.41142003]
 [0.         0.15834983]
 [0.         0.52050195]
 [0.         0.13767634]
 [0.         0.67453866]
 [0.         0.54832447]
 [0.         0.4106969 ]
 [0.         0.57071902]
 [0.         0.54413813]
 [0.         0.16043092]
 [1.         0.37390211]
 [0.         0.6987448 ]
 [0.         0.31205635]
 [0.         0.0487809 ]
 [0.         0.14050364]
 [0.         0.69102483]
 [0.         0.49156883]] 0.3320913581177933
</pre></table></code></div></div><ul><li>LSTM을 처음 제안한 논문에서 LSTM의 성능을 확인하기 위해서 제시한 문제</li></ul><p><br /></p><h3 id="42-rnn으로">4.2 RNN으로</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">SimpleRNN</span><span class="p">(</span>
        <span class="n">units</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">SimpleRNN</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">30</span><span class="p">),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">'mse'</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre><td class="rouge-code"><pre>Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
simple_rnn_1 (SimpleRNN)     (None, 100, 30)           990       
_________________________________________________________________
simple_rnn_2 (SimpleRNN)     (None, 30)                1830      
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 31        
=================================================================
Total params: 2,851
Trainable params: 2,851
Non-trainable params: 0
_________________________________________________________________
</pre></table></code></div></div><ul><li>일단 SimpleRNN으로 확인</li></ul><p><br /></p><h3 id="43-simplernn-훈련-후-그래프">4.3 SimpleRNN 훈련 후 그래프</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">2560</span><span class="p">],</span> <span class="n">Y</span><span class="p">[:</span><span class="mi">2560</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">],</span> <span class="s">'b-'</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">'loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">],</span> <span class="s">'r--'</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">'val_loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Epoch'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre>Epoch 1/100
25/25 [==============================] - 1s 27ms/step - loss: 0.0806 - val_loss: 0.0600
Epoch 2/100
25/25 [==============================] - 0s 20ms/step - loss: 0.0517 - val_loss: 0.0586
Epoch 3/100
25/25 [==============================] - 0s 19ms/step - loss: 0.0512 - val_loss: 0.0581
...
Epoch 99/100
25/25 [==============================] - 0s 20ms/step - loss: 0.0100 - val_loss: 0.0821
Epoch 100/100
25/25 [==============================] - 0s 19ms/step - loss: 0.0099 - val_loss: 0.0804
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/97599977-eadaa880-1a4b-11eb-9d8d-b913de74bbf8.png" /></p><ul><li>Loss가 계속 벌어진다. 이것은 아까 이야기했던 Long-Term Dependency 때문임</li></ul><p><br /></p><h3 id="44-lstm">4.4 LSTM</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                         <span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">30</span><span class="p">),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="s">'adam'</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="s">'mse'</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre><td class="rouge-code"><pre>Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 100, 30)           3960      
_________________________________________________________________
lstm_1 (LSTM)                (None, 30)                7320      
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 31        
=================================================================
Total params: 11,311
Trainable params: 11,311
Non-trainable params: 0
_________________________________________________________________
</pre></table></code></div></div><p><br /></p><h3 id="45-lstm-훈련-후-그래프">4.5 LSTM 훈련 후 그래프</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">2560</span><span class="p">],</span> <span class="n">Y</span><span class="p">[:</span><span class="mi">2560</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">],</span> <span class="s">'b-'</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">'loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">],</span> <span class="s">'r--'</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">'val_loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Epoch'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre>Epoch 1/100
25/25 [==============================] - 1s 46ms/step - loss: 0.0620 - val_loss: 0.0558
Epoch 2/100
25/25 [==============================] - 1s 29ms/step - loss: 0.0507 - val_loss: 0.0539
Epoch 3/100
25/25 [==============================] - 1s 29ms/step - loss: 0.0508 - val_loss: 0.0543
...
Epoch 100/100
25/25 [==============================] - 1s 29ms/step - loss: 0.0510 - val_loss: 0.0543
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/97599982-eca46c00-1a4b-11eb-9482-c8f7ff9602cb.png" /></p><ul><li>SimpleRNN과는 다르게 Loss와 Val Loss가 같이 떨어진다.</li></ul><p><br /></p><h2 id="5-gru-레이어-gated-recurrent-unit">5. GRU 레이어 (Gated Recurrent Unit)</h2><hr /><h3 id="51-gru의-셀-구조">5.1 GRU의 셀 구조</h3><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/97587381-abf22600-1a3e-11eb-9286-cbca34a5b352.png" /></p><ul><li>LSTM에 비해 연산량이 작고, 성능이 어떤 경우는 괜찮은것으로 나타난다.</li></ul><p><br /></p><h3 id="52-gru-생성">5.2 GRU 생성</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="n">mdoel</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>  <span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">30</span><span class="p">),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="s">'adam'</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="s">'mse'</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre><td class="rouge-code"><pre>Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 100, 30)           3960      
_________________________________________________________________
lstm_1 (LSTM)                (None, 30)                7320      
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 31        
=================================================================
Total params: 11,311
Trainable params: 11,311
Non-trainable params: 0
_________________________________________________________________
</pre></table></code></div></div><p><br /></p><h3 id="53-gru-훈련-후-그래프-그리기">5.3 GRU 훈련 후 그래프 그리기</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">2560</span><span class="p">],</span> <span class="n">Y</span><span class="p">[:</span><span class="mi">2560</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">],</span> <span class="s">'b-'</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">'loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">],</span> <span class="s">'r--'</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">'val_loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Epoch'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>Epoch 1/100
25/25 [==============================] - 1s 52ms/step - loss: 0.0506 - val_loss: 0.0550
Epoch 2/100
25/25 [==============================] - 1s 29ms/step - loss: 0.0497 - val_loss: 0.0555
Epoch 3/100
...
Epoch 100/100
25/25 [==============================] - 1s 30ms/step - loss: 6.9079e-04 - val_loss: 9.3052e-04
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/97599985-ed3d0280-1a4b-11eb-8a10-f97e933e2e65.png" /></p><ul><li>이것도 마찬가지로 Loss와 Val Loss가 엄청 잘 떨어진다.</li></ul><p><br /></p><h2 id="6-감성-분석-실습">6. 감성 분석 실습</h2><hr /><h3 id="61-감성분석">6.1 감성분석</h3><ul><li>입력된 자연어 안의 주관적 의견, 감정등을 찾아내는 문제</li><li>문장의 긍정/부정 등을 구분하는 경우가 많음</li></ul><p><br /></p><h3 id="62-data-load">6.2 Data Load</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="n">path_to_train_file</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">get_file</span><span class="p">(</span><span class="s">'train_txt'</span><span class="p">,</span> <span class="s">'https://raw.githubusercontent.com/hmkim312/datas/main/navermoviereview/ratings_train.txt'</span><span class="p">)</span>
<span class="n">path_to_test_file</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">get_file</span><span class="p">(</span><span class="s">'test_txt'</span><span class="p">,</span> <span class="s">'https://raw.githubusercontent.com/hmkim312/datas/main/navermoviereview/ratings_test.txt'</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>Downloading data from https://raw.githubusercontent.com/hmkim312/datas/main/navermoviereview/ratings_train.txt
14630912/14628807 [==============================] - 4s 0us/step
Downloading data from https://raw.githubusercontent.com/hmkim312/datas/main/navermoviereview/ratings_test.txt
4898816/4893335 [==============================] - 2s 0us/step
</pre></table></code></div></div><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="n">train_text</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">path_to_train_file</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">).</span><span class="n">read</span><span class="p">().</span><span class="n">decode</span><span class="p">(</span><span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span>
<span class="n">test_text</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">path_to_test_file</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">).</span><span class="n">read</span><span class="p">().</span><span class="n">decode</span><span class="p">(</span><span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Length of text : </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_text</span><span class="p">)</span><span class="si">}</span><span class="s"> characters'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Length of text : </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_text</span><span class="p">)</span><span class="si">}</span><span class="s"> characters'</span><span class="p">)</span>
<span class="k">print</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">train_text</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre>Length of text : 6937271 characters
Length of text : 2318260 characters

id	document	label
9976970	아 더빙.. 진짜 짜증나네요 목소리	0
3819312	흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나	1
10265843
</pre></table></code></div></div><ul><li>일전에 사용했던 영화 리뷰 감성분석 <a href="https://hmkim312.github.io/posts/네이버영화평점을_이용한_감정분석/" target="_blank">https://hmkim312.github.io/posts/네이버영화평점을_이용한_감정분석/</a></li><li>id: 리뷰한 관객의 id 고유값</li><li>document: 실제 리뷰</li><li>label: 감정 (0: 부정, 1: 긍정)</li><li>총 200K의 감정분석(20만)</li><li>ratings_test.txt: 5만개의 테스트용 리뷰</li><li>ratings_train.txt: 15만개의 훈련용 리뷰</li><li>모든 리뷰는 140자 미만</li><li>100k(10만) 부정 리뷰 (평점이 0점 ~ 4점)</li><li>100K(10만) 긍정 리뷰 (평점이 9점 ~ 10점)</li><li>평점이 5점 ~ 8점은 중립리뷰점수로 로 제외시킴</li></ul><p><br /></p><h3 id="63-데이터가-깨끗하지-않음">6.3 데이터가 깨끗하지 않음</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">train_text</span><span class="p">[:</span><span class="mi">300</span><span class="p">]</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>'id\tdocument\tlabel\n9976970\t아 더빙.. 진짜 짜증나네요 목소리\t0\n3819312\t흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\t1\n10265843\t너무재밓었다그래서보는것을추천한다\t0\n9045019\t교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\t0\n6483659\t사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\t1\n5403919\t막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.\t0\n7797314\t원작의'
</pre></table></code></div></div><p><br /></p><h3 id="64-데이터-전처리">6.4 데이터 전처리</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">train_text</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre>['id\tdocument\tlabel',
 '9976970\t아 더빙.. 진짜 짜증나네요 목소리\t0',
 '3819312\t흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\t1',
 '10265843\t너무재밓었다그래서보는것을추천한다\t0',
 '9045019\t교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\t0',
 '6483659\t사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\t1',
 ...]
</pre></table></code></div></div><ul><li>split을 하여 리뷰별로 가져옴</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">train_text</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)[</span><span class="mi">3</span><span class="p">].</span><span class="n">split</span><span class="p">(</span><span class="s">'</span><span class="se">\t</span><span class="s">'</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>['10265843', '너무재밓었다그래서보는것을추천한다', '0']
</pre></table></code></div></div><ul><li>리뷰 한줄을 탭으로 split하면 id, review, target이 나옴</li></ul><p><br /></p><h3 id="65-target-데이터-정리">6.5 Target 데이터 정리</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">train_Y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'</span><span class="se">\t</span><span class="s">'</span><span class="p">)[</span><span class="mi">2</span><span class="p">])]</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">train_text</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span> <span class="k">if</span> <span class="n">row</span><span class="p">.</span><span class="n">count</span><span class="p">(</span><span class="s">'</span><span class="se">\t</span><span class="s">'</span><span class="p">)</span> <span class="o">&gt;</span><span class="mi">0</span><span class="p">])</span>
<span class="n">test_Y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="nb">int</span><span class="p">(</span><span class="n">row</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'</span><span class="se">\t</span><span class="s">'</span><span class="p">)[</span><span class="mi">2</span><span class="p">])]</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">test_text</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span> <span class="k">if</span> <span class="n">row</span><span class="p">.</span><span class="n">count</span><span class="p">(</span><span class="s">'</span><span class="se">\t</span><span class="s">'</span><span class="p">)</span> <span class="o">&gt;</span><span class="mi">0</span><span class="p">])</span>

<span class="k">print</span><span class="p">(</span><span class="n">train_Y</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">test_Y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">train_Y</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre>(150000, 1) (50000, 1)
[[0]
 [1]
 [0]
 [0]
 [1]]
</pre></table></code></div></div><ul><li>일단 타겟이 되는 0(부정), 1(긍정) 데이터를 따로 모아놨음</li></ul><p><br /></p><h3 id="66-tokenization-cleaning">6.6 Tokenization, Cleaning</h3><ul><li>Tokenization : 자연어 처리 가능한 최소의 단위로 나누는 것, 이번에는 띄어쓰기</li><li>Cleaning : 불필요한 기호를 제거</li></ul><p><br /></p><h3 id="67-cleaning-함수-생성-및-데이터-전처리">6.7 Cleaning 함수 생성 및 데이터 전처리</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">re</span>
<span class="k">def</span> <span class="nf">clean_str</span><span class="p">(</span><span class="n">string</span><span class="p">):</span>
    <span class="n">string</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s">"[^가-힣A-Za-z0-9(),!?\'\`]"</span><span class="p">,</span> <span class="s">" "</span><span class="p">,</span> <span class="n">string</span><span class="p">)</span>
    <span class="n">string</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s">"\'s"</span><span class="p">,</span> <span class="s">" </span><span class="se">\'</span><span class="s">s"</span><span class="p">,</span> <span class="n">string</span><span class="p">)</span>
    <span class="n">string</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s">"\'ve"</span><span class="p">,</span> <span class="s">" </span><span class="se">\'</span><span class="s">ve"</span><span class="p">,</span> <span class="n">string</span><span class="p">)</span>
    <span class="n">string</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s">"n\'t"</span><span class="p">,</span> <span class="s">" n</span><span class="se">\'</span><span class="s">t"</span><span class="p">,</span> <span class="n">string</span><span class="p">)</span>
    <span class="n">string</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s">"\'re"</span><span class="p">,</span> <span class="s">" </span><span class="se">\'</span><span class="s">re"</span><span class="p">,</span> <span class="n">string</span><span class="p">)</span>
    <span class="n">string</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s">"\'d"</span><span class="p">,</span> <span class="s">" </span><span class="se">\'</span><span class="s">d"</span><span class="p">,</span> <span class="n">string</span><span class="p">)</span>
    <span class="n">string</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s">"\'ll"</span><span class="p">,</span> <span class="s">" </span><span class="se">\'</span><span class="s">ll"</span><span class="p">,</span> <span class="n">string</span><span class="p">)</span>
    <span class="n">string</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s">","</span><span class="p">,</span> <span class="s">" , "</span><span class="p">,</span> <span class="n">string</span><span class="p">)</span>
    <span class="n">string</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s">"!"</span><span class="p">,</span> <span class="s">" ! "</span><span class="p">,</span> <span class="n">string</span><span class="p">)</span>
    <span class="n">string</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s">"\("</span><span class="p">,</span> <span class="s">" \( "</span><span class="p">,</span> <span class="n">string</span><span class="p">)</span>
    <span class="n">string</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s">"\)"</span><span class="p">,</span> <span class="s">" \) "</span><span class="p">,</span> <span class="n">string</span><span class="p">)</span>
    <span class="n">string</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s">"\?"</span><span class="p">,</span> <span class="s">" \? "</span><span class="p">,</span> <span class="n">string</span><span class="p">)</span>
    <span class="n">string</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s">"\s{2,}"</span><span class="p">,</span> <span class="s">" "</span><span class="p">,</span> <span class="n">string</span><span class="p">)</span>
    <span class="n">string</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s">"\'{2,}"</span><span class="p">,</span> <span class="s">"</span><span class="se">\'</span><span class="s">"</span><span class="p">,</span> <span class="n">string</span><span class="p">)</span>
    <span class="n">string</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s">"\'"</span><span class="p">,</span> <span class="s">""</span><span class="p">,</span> <span class="n">string</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">string</span><span class="p">.</span><span class="n">lower</span><span class="p">()</span>
</pre></table></code></div></div><ul><li>불필요한 특수문자를 제거하는 함수 생성</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="n">train_text_X</span> <span class="o">=</span> <span class="p">[</span><span class="n">row</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'</span><span class="se">\t</span><span class="s">'</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">train_text</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span> <span class="k">if</span> <span class="n">row</span><span class="p">.</span><span class="n">count</span><span class="p">(</span><span class="s">'</span><span class="se">\t</span><span class="s">'</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">train_text_X</span> <span class="o">=</span> <span class="p">[</span><span class="n">clean_str</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">train_text_X</span><span class="p">]</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="n">sentence</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">' '</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">train_text_X</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="n">sentences</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>['아', '더빙', '진짜', '짜증나네요', '목소리']
['흠', '포스터보고', '초딩영화줄', '오버연기조차', '가볍지', '않구나']
['너무재밓었다그래서보는것을추천한다']
['교도소', '이야기구먼', '솔직히', '재미는', '없다', '평점', '조정']
['사이몬페그의', '익살스런', '연기가', '돋보였던', '영화', '!', '스파이더맨에서', '늙어보이기만', '했던', '커스틴', '던스트가', '너무나도', '이뻐보였다']
</pre></table></code></div></div><ul><li>train_text 리뷰에 ‘\t’가 있다면 split하는 코드</li><li>위에서 만든 clean_str을 적용하는 코드</li><li>공백(띄어쓰기)로 split하는 코드</li></ul><p><br /></p><h3 id="68-리뷰의-길이">6.8 리뷰의 길이</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">sentence_len</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
<span class="n">sentence_len</span><span class="p">.</span><span class="n">sort</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sentence_len</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s">'리뷰의 길이가 25자 미만인것 : '</span><span class="p">,</span> <span class="nb">sum</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">l</span> <span class="o">&lt;=</span> <span class="mi">25</span><span class="p">)</span><span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">sentence_len</span><span class="p">]))</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/97599989-edd59900-1a4b-11eb-92bc-eae216a8f9bc.png" /></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>리뷰의 길이가 25자 미만인것 :  142587
</pre></table></code></div></div><ul><li>학습을 위해 네트워크에 입력을 넣을땐 입력 데이터는 그 크기가 같아야함</li><li>입력 벡터의 크기를 맞추기위해 긴 문장을 줄이고, 짧은 문장은 공백으로 채우는 방법을 사용</li><li>15만개의 문장중에 대부분이 25단어 이하로 되어있음, 142587개</li></ul><p><br /></p><h3 id="69-데이터-전처리-25개-단어까지-넣기">6.9 데이터 전처리 25개 단어까지 넣기</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="n">sentences_new</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">:</span>
    <span class="n">sentences_new</span><span class="p">.</span><span class="n">append</span><span class="p">([</span><span class="n">word</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="p">][:</span><span class="mi">25</span><span class="p">])</span>
    
<span class="n">sentences</span> <span class="o">=</span> <span class="n">sentences_new</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="n">sentences_new</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>['아', '더빙', '진짜', '짜증나네요', '목소리']
['흠', '포스터보고', '초딩영화줄', '오버연기조', '가볍지', '않구나']
['너무재밓었']
['교도소', '이야기구먼', '솔직히', '재미는', '없다', '평점', '조정']
['사이몬페그', '익살스런', '연기가', '돋보였던', '영화', '!', '스파이더맨', '늙어보이기', '했던', '커스틴', '던스트가', '너무나도', '이뻐보였다']
</pre></table></code></div></div><p><br /></p><h3 id="610-토크나이징과-패딩">6.10 토크나이징과 패딩</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.text</span> <span class="kn">import</span> <span class="n">Tokenizer</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.sequence</span> <span class="kn">import</span> <span class="n">pad_sequences</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">num_words</span><span class="o">=</span><span class="mi">20000</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="p">.</span><span class="n">fit_on_texts</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>
<span class="n">train_X</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>
<span class="n">train_X</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span> <span class="s">'post'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">train_X</span><span class="p">[:</span><span class="mi">3</span><span class="p">])</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre>[[  25  884    8 5795 1111    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0]
 [ 588 5796 6697    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0    0    0    0    0    0    0    0    0]]
</pre></table></code></div></div><p><br /></p><h3 id="611-모델-구성">6.11 모델 구성</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">20000</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="n">input_length</span> <span class="o">=</span> <span class="mi">25</span><span class="p">),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">units</span> <span class="o">=</span> <span class="mi">50</span><span class="p">),</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">'softmax'</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="s">'adam'</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
<span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre><td class="rouge-code"><pre>Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, 25, 300)           6000000   
_________________________________________________________________
lstm_2 (LSTM)                (None, 50)                70200     
_________________________________________________________________
dense_4 (Dense)              (None, 2)                 102       
=================================================================
Total params: 6,070,302
Trainable params: 6,070,302
Non-trainable params: 0
_________________________________________________________________
</pre></table></code></div></div><p><br /></p><h3 id="612-임베딩-레이어embedding-layer">6.12 임베딩 레이어(Embedding Layer)</h3><ul><li>임베딩 레이어 : 자연어를 수치화된 정보로 바꾸기 위한 레이어</li><li>자연어는 시간의 흐름에 따라 정보가 연속적으로 이어지는 스퀀스 데이터</li><li>영어는 문자 단위, 한글은 문자를 넘어 자소 단위로도 쪼개기도 함, 혹은 형태소, 띄어쓰기로도 하기도함</li><li>여러 단어로 묶어서 사용하는 n-gram 방식도 있음</li><li>원핫인코딩까지 포함</li></ul><p><br /></p><h3 id="613-학습">6.13 학습</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">120</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre>Epoch 1/5
1000/1000 [==============================] - 50s 50ms/step - loss: 0.4301 - accuracy: 0.7884 - val_loss: 0.3805 - val_accuracy: 0.8224
Epoch 2/5
1000/1000 [==============================] - 51s 51ms/step - loss: 0.3263 - accuracy: 0.8467 - val_loss: 0.3903 - val_accuracy: 0.8211
Epoch 3/5
1000/1000 [==============================] - 47s 47ms/step - loss: 0.2766 - accuracy: 0.8662 - val_loss: 0.4175 - val_accuracy: 0.8196
Epoch 4/5
1000/1000 [==============================] - 47s 47ms/step - loss: 0.2357 - accuracy: 0.8836 - val_loss: 0.4570 - val_accuracy: 0.8113
Epoch 5/5
1000/1000 [==============================] - 47s 47ms/step - loss: 0.2016 - accuracy: 0.8990 - val_loss: 0.5628 - val_accuracy: 0.8102
</pre></table></code></div></div><p><br /></p><h3 id="614-테스트">6.14 테스트</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre><td class="rouge-code"><pre><span class="n">test_sentence</span> <span class="o">=</span> <span class="s">'재미있을 줄 알았는데 완전 실망했다. 너무 졸리고 돈이 아까웠다'</span>
<span class="n">test_sentence</span> <span class="o">=</span> <span class="n">test_sentence</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">' '</span><span class="p">)</span>
<span class="n">test_sentences</span> <span class="o">=</span><span class="p">[]</span>
<span class="n">now_sentence</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">test_sentence</span><span class="p">:</span>
    <span class="n">now_sentence</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
    <span class="n">test_sentences</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">now_sentence</span><span class="p">[:])</span>
    
<span class="n">test_X_1</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">test_sentences</span><span class="p">)</span>
<span class="n">test_X_1</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">test_X_1</span><span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="s">'post'</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X_1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_sentences</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">prediction</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre><td class="rouge-code"><pre>['재미있을']
[0.33282876 0.66717124]
['재미있을', '줄']
[0.3296478  0.67035216]
['재미있을', '줄', '알았는데']
[0.41936734 0.5806327 ]
['재미있을', '줄', '알았는데', '완전']
[0.36908486 0.6309151 ]
['재미있을', '줄', '알았는데', '완전', '실망했다.']
[0.36908486 0.6309151 ]
['재미있을', '줄', '알았는데', '완전', '실망했다.', '너무']
[0.375071 0.624929]
['재미있을', '줄', '알았는데', '완전', '실망했다.', '너무', '졸리고']
[0.989423   0.01057698]
['재미있을', '줄', '알았는데', '완전', '실망했다.', '너무', '졸리고', '돈이']
[0.9979898  0.00201018]
['재미있을', '줄', '알았는데', '완전', '실망했다.', '너무', '졸리고', '돈이', '아까웠다']
[0.9983991  0.00160098]
</pre></table></code></div></div><ul><li>처음에는 <code class="language-plaintext highlighter-rouge">재미있을</code> 이라는 단어 떄문에 긍정으로 판단되다가, <code class="language-plaintext highlighter-rouge">졸리고</code>가 나오자 바로 부정으로 바뀌었다.</li><li>앞에가 0(부정), 뒤에가 1(긍정)일 확률임</li></ul><p><br /></p><h2 id="7-요약">7. 요약</h2><hr /><h3 id="71-요약">7.1 요약</h3><ul><li>RNN의 종류와 이를 활용하여 감성분석을 진행했다.</li><li>솔직히 아직 공부가 부족해서 무슨 이야기인지 이해가 안가는 부분이 있음</li><li>딥러닝은 따로 인강을 들으며 더 공부를 해야겠다.</li></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/data-science/'>Data Science</a>, <a href='/categories/deep-learning/'>Deep Learning</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/tensorflow/" class="post-tag no-text-decoration" >Tensorflow</a> <a href="/tags/recurrent-neural-net/" class="post-tag no-text-decoration" >Recurrent Neural Net</a> <a href="/tags/rnn/" class="post-tag no-text-decoration" >RNN</a> <a href="/tags/simple-rnn/" class="post-tag no-text-decoration" >Simple RNN</a> <a href="/tags/lstm/" class="post-tag no-text-decoration" >LSTM</a> <a href="/tags/gru/" class="post-tag no-text-decoration" >GRU</a> <a href="/tags/tokenization/" class="post-tag no-text-decoration" >Tokenization</a> <a href="/tags/cleaning/" class="post-tag no-text-decoration" >Cleaning</a> <a href="/tags/embedding-layer/" class="post-tag no-text-decoration" >Embedding Layer</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><!-- Post sharing snippet v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=순환신경망 - RNN (Recurrent Neural Network) - Data Include Me&url=https://datainclude.me/posts/%EC%88%9C%ED%99%98%EC%8B%A0%EA%B2%BD%EB%A7%9D_RNN_(Recurrent_Neural_Network)/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=순환신경망 - RNN (Recurrent Neural Network) - Data Include Me&u=https://datainclude.me/posts/%EC%88%9C%ED%99%98%EC%8B%A0%EA%B2%BD%EB%A7%9D_RNN_(Recurrent_Neural_Network)/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=순환신경망 - RNN (Recurrent Neural Network) - Data Include Me&url=https://datainclude.me/posts/%EC%88%9C%ED%99%98%EC%8B%A0%EA%B2%BD%EB%A7%9D_RNN_(Recurrent_Neural_Network)/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><!-- The Panel on right side (Desktop views) v2.3 © 2024 Your Name MIT License --><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><h3 data-toc-skip>Recent Update</h3><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li class="recent-item"> <a href="/posts/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C_%EC%BB%B4%ED%93%A8%ED%8C%85_%EA%B0%80%EC%83%81%ED%99%94/">클라우드 컴퓨팅 - 가상화</a> <span class="text-muted small">2024-10-28</span></li><li class="recent-item"> <a href="/posts/gemini_api_%EC%82%AC%EC%9A%A9%ED%95%B4%EB%B3%B4%EA%B8%B0/">Gemini API 사용해보기</a> <span class="text-muted small">2024-03-12</span></li><li class="recent-item"> <a href="/posts/Ollama%EC%99%80_Python_%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC_LLaMa2%EB%A5%BC_%EB%A1%9C%EC%BB%AC%EC%97%90%EC%84%9C_%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/">Ollama와 Python 라이브러리를 이용하여 LLaMa2를 로컬에서 사용하기</a> <span class="text-muted small">2024-02-13</span></li><li class="recent-item"> <a href="/posts/Mistral_7B_Fine_Tuning/">Mistral 7B 파인튜닝(Fine Tuning)하기</a> <span class="text-muted small">2023-10-25</span></li><li class="recent-item"> <a href="/posts/Penn_Fudan%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EA%B0%9D%EC%B2%B4_%ED%83%90%EC%A7%80_%EB%B6%84%ED%95%A0/">Penn-Fudan으로 알아보는 객체 탐지(Object Detection), 분할(Segmentation) with FasterRCNN</a> <span class="text-muted small">2023-10-23</span></li></ul></div><div id="access-tags"><h3 data-toc-skip>Trending Tags</h3><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/tensorflow/">Tensorflow</a> <a class="post-tag" href="/tags/sklearn/">Sklearn</a> <a class="post-tag" href="/tags/round/">Round</a> <a class="post-tag" href="/tags/python-lv0/">Python Lv0</a> <a class="post-tag" href="/tags/pca/">PCA</a> <a class="post-tag" href="/tags/eda/">EDA</a> <a class="post-tag" href="/tags/distinct/">Distinct</a> <a class="post-tag" href="/tags/random-forest/">Random Forest</a> <a class="post-tag" href="/tags/beautifulsoup/">Beautifulsoup</a> <a class="post-tag" href="/tags/baekjoon/">Baekjoon</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><h3 data-toc-skip class="pl-3 pt-2 mb-2">Contents</h3><nav id="toc" data-toggle="toc"></nav></div></div><style> .recent-item { margin-bottom: 0.5rem; } .recent-item a { color: var(--link-color); } .recent-item .small { font-size: 0.75rem; margin-left: 0.5rem; }</style></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"> <!-- Recommend the other 3 posts according to the tags and categories of the current post, if the number is not enough, use the other latest posts to supplement. v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/%EA%B3%A0%EC%96%91%EC%9D%B4_%EA%B0%95%EC%95%84%EC%A7%80_%EC%82%AC%EC%A7%84%EC%9C%BC%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_CNN/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Nov 1, 2020 <i class="unloaded">2020-11-01T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>고양이, 강아지 사진으로 해보는 CNN</h3><div class="text-muted small"><p> 1. Cat and Dogs 1.1 Cat and Dgos PCA 할때 사용했던 데이터. https://hmkim312.github.io/posts/강아지와_고양이_분류기_on_PCA/ kaggle : https://www.kaggle.com/c/dogs-vs-cats/data 위의 링크에서 Donwload all 버튼을 눌러 dogs...</p></div></div></a></div><div class="card"> <a href="/posts/%EB%94%A5%EB%9F%AC%EB%8B%9D_%EA%B8%B0%EC%B4%88_(1)_(Basic_of_Deeplearning_1)/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Oct 28, 2020 <i class="unloaded">2020-10-28T10:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>딥러닝 기초 (1) (Basic of Deeplearning 1)</h3><div class="text-muted small"><p> 1. Tensorflow 설치 1.1 Pip Upgrade pip install –upgrade pip Tensorflow 설치를 위해선 pip 버전이 19.X 이상이어야함 1.2 Tensorflow 설치 pip install tensorflow 2. Tensorflow 2.1 Tensorflow란? 머신러닝...</p></div></div></a></div><div class="card"> <a href="/posts/MNIST_%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_%EB%94%A5%EB%9F%AC%EB%8B%9D_(Deep_Learning)/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Oct 29, 2020 <i class="unloaded">2020-10-29T10:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>MNIST 데이터로 해보는 딥러닝 (Deep Learning)</h3><div class="text-muted small"><p> 1. MNIST 1.1 MNIST Data NIST는 미국 국립표준기술연구소(National Institute of Standards and Technology)의 약자입니다. 여기서 진행한 미션 중에 손글씨 데이터를 모았는데, 그중 숫자로 된 데이터를 MNIST라고 합니다. 28 * 28 픽셀의 0 ~ 9 사이의 숫자 이미지와 레이블로...</p></div></div></a></div></div></div><!-- Navigation buttons at the bottom of the post. v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --><div class="post-navigation d-flex justify-content-between"> <a href="/posts/MNIST_%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_CNN(Convolution_Neral_Network)/" class="btn btn-outline-primary"><p>MNIST 데이터로 해보는 CNN (Convolution Neral Network)</p></a> <a href="/posts/%EA%B3%A0%EC%96%91%EC%9D%B4_%EA%B0%95%EC%95%84%EC%A7%80_%EC%82%AC%EC%A7%84%EC%9C%BC%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_CNN/" class="btn btn-outline-primary"><p>고양이, 강아지 사진으로 해보는 CNN</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('#post-wrapper img'); const observer = lozad(imgs); observer.observe(); </script></div><!-- The Search results v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/tensorflow/">Tensorflow</a> <a class="post-tag" href="/tags/sklearn/">Sklearn</a> <a class="post-tag" href="/tags/round/">Round</a> <a class="post-tag" href="/tags/python-lv0/">Python Lv0</a> <a class="post-tag" href="/tags/pca/">PCA</a> <a class="post-tag" href="/tags/eda/">EDA</a> <a class="post-tag" href="/tags/distinct/">Distinct</a> <a class="post-tag" href="/tags/random-forest/">Random Forest</a> <a class="post-tag" href="/tags/beautifulsoup/">Beautifulsoup</a> <a class="post-tag" href="/tags/baekjoon/">Baekjoon</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <!-- The GA snippet v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <!-- Jekyll Simple Search loader v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://datainclude.me{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script>
