<!DOCTYPE html><html lang="ko" mode="light" > <!-- The Head v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>교차검증(Kfold) | Data Include Me</title><meta name="generator" content="Jekyll v3.9.3" /><meta property="og:title" content="교차검증(Kfold)" /><meta name="author" content="HyunMin Kim" /><meta property="og:locale" content="ko" /><meta name="description" content="1. 교차 검증 과적합 : 모델이 학습 데이터에마 과도하게 최적화된 현상. 그로인해 일반화된 데이터에서는 예측 성능이 과하게 떨어지는 현상 지난번 와인 맛 평가에서 훈련용 데이터의 Acc는 72.94, 테스트용 데이터는 Acc가 71.61%였는데, 누가 이결과가 정말 괜찮은 것인지 묻는다면? 나에게 주어진 데이터에 적용한 모델의 성능을 정확히 표현하기 위해서도 유용하다 train 데이터를 다시 나누어 validation 데이터로 사용함으로써 과적합을 막는 방법 검증이 끝나면 다시 train데이터로 학습 한 뒤 test로 마지막 결과를 확인한다" /><meta property="og:description" content="1. 교차 검증 과적합 : 모델이 학습 데이터에마 과도하게 최적화된 현상. 그로인해 일반화된 데이터에서는 예측 성능이 과하게 떨어지는 현상 지난번 와인 맛 평가에서 훈련용 데이터의 Acc는 72.94, 테스트용 데이터는 Acc가 71.61%였는데, 누가 이결과가 정말 괜찮은 것인지 묻는다면? 나에게 주어진 데이터에 적용한 모델의 성능을 정확히 표현하기 위해서도 유용하다 train 데이터를 다시 나누어 validation 데이터로 사용함으로써 과적합을 막는 방법 검증이 끝나면 다시 train데이터로 학습 한 뒤 test로 마지막 결과를 확인한다" /><link rel="canonical" href="https://datainclude.me/posts/%EA%B5%90%EC%B0%A8%EA%B2%80%EC%A6%9D(Kfold)/" /><meta property="og:url" content="https://datainclude.me/posts/%EA%B5%90%EC%B0%A8%EA%B2%80%EC%A6%9D(Kfold)/" /><meta property="og:site_name" content="Data Include Me" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-09-21T14:30:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="교차검증(Kfold)" /><meta name="twitter:site" content="@" /><meta name="twitter:creator" content="@HyunMin Kim" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"HyunMin Kim"},"dateModified":"2020-09-21T14:30:00+09:00","datePublished":"2020-09-21T14:30:00+09:00","description":"1. 교차 검증 과적합 : 모델이 학습 데이터에마 과도하게 최적화된 현상. 그로인해 일반화된 데이터에서는 예측 성능이 과하게 떨어지는 현상 지난번 와인 맛 평가에서 훈련용 데이터의 Acc는 72.94, 테스트용 데이터는 Acc가 71.61%였는데, 누가 이결과가 정말 괜찮은 것인지 묻는다면? 나에게 주어진 데이터에 적용한 모델의 성능을 정확히 표현하기 위해서도 유용하다 train 데이터를 다시 나누어 validation 데이터로 사용함으로써 과적합을 막는 방법 검증이 끝나면 다시 train데이터로 학습 한 뒤 test로 마지막 결과를 확인한다","headline":"교차검증(Kfold)","mainEntityOfPage":{"@type":"WebPage","@id":"https://datainclude.me/posts/%EA%B5%90%EC%B0%A8%EA%B2%80%EC%A6%9D(Kfold)/"},"url":"https://datainclude.me/posts/%EA%B5%90%EC%B0%A8%EA%B2%80%EC%A6%9D(Kfold)/"}</script><meta property="og:image" content="https://datainclude.me/assets/img/sample/avatar.jpg" /> <!-- The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps Generated by: https://www.favicon-generator.org/ v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT license --><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="36x36" href="/assets/img/favicons/android-icon-36x36.png"><link rel="icon" type="image/png" sizes="48x48" href="/assets/img/favicons/android-icon-48x48.png"><link rel="icon" type="image/png" sizes="72x72" href="/assets/img/favicons/android-icon-72x72.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/android-icon-96x96.png"><link rel="icon" type="image/png" sizes="144x144" href="/assets/img/favicons/android-icon-144x144.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="70x70" href="/assets/img/favicons/ms-icon-70x70.png"><link rel="icon" type="image/png" sizes="144x144" href="/assets/img/favicons/ms-icon-144x144.png"><link rel="icon" type="image/png" sizes="150x150" href="/assets/img/favicons/ms-icon-150x150.png"><link rel="icon" type="image/png" sizes="310x310" href="/assets/img/favicons/ms-icon-310x310.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preload" href="https://www.googletagmanager.com/gtm.js?id=GTM-MW9VRMW9" as="script"> <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src= 'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f); })(window,document,'script','dataLayer','GTM-MW9VRMW9');</script><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="preload" as="style" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous" media="print" onload="this.media='all'"> <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"> </noscript> <!-- CSS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --><link rel="preload" as="style" href="/assets/css/post.css"><link rel="stylesheet" href="/assets/css/post.css"><link rel="preload" as="style" href="/assets/css/lib/bootstrap-toc.min.css"><link rel="stylesheet" href="/assets/css/lib/bootstrap-toc.min.css" /><link rel="preload" as="script" href="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" async></script> <!-- JS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --> <script src="/assets/js/post.min.js" async></script> <script src="/app.js" defer></script><body data-spy="scroll" data-target="#toc"> <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MW9VRMW9" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="sidebar" class="d-flex flex-column"> <!-- The Side Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="nav-wrapper"><div id="profile-wrapper" class="d-flex flex-column"><div id="avatar" class="d-flex justify-content-center"> <a href="/" alt="avatar"> <img src="/assets/img/sample/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="profile-text mt-3"><div class="site-title"> <a href="/">Data Include Me</a></div><div class="site-subtitle font-italic">Data Science Blog</div></div></div><ul class="nav flex-column"><li class="nav-item d-flex justify-content-center "> <a href="/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/categories/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/tags/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/archives/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/about/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></li></ul></div><div class="sidebar-bottom d-flex flex-wrap justify-content-around mt-4"> <a href="https://github.com/hmkim312" target="_blank"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/" target="_blank"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:window.open('mailto:' + ['sanarial312','gmail.com'].join('@'))" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" > <i class="fas fa-rss"></i> </a></div></div><!-- The Top Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>교차검증(Kfold)</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"> <!-- Refactor the HTML structure. --> <!-- Suroundding the markdown table with '<div class="table-wrapper">. and '</div>' --> <!-- Fixed kramdown code highlight rendering: https://github.com/penibelst/jekyll-compress-html/issues/101 https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901 --><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"> <script type="text/javascript"> var lazyloadads = false; function loadAds() { if (!lazyloadads) { var script = document.createElement("script"); script.type = "text/javascript"; script.async = true; script.src = "https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7594406644928408"; document.body.appendChild(script); lazyloadads = true; } } window.addEventListener("mousemove", loadAds, { once: true }); window.addEventListener('touchstart', loadAds, { once: true }); </script><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>교차검증(Kfold)</h1><div class="post-meta text-muted d-flex flex-column"><div> Posted <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Mon, Sep 21, 2020, 2:30 PM +0900" > Sep 21, 2020 <i class="unloaded">2020-09-21T14:30:00+09:00</i> </span> by <span class="author"> HyunMin Kim </span></div><a href="https://hits.seeyoufarm.com"> <img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https://datainclude.me/posts/%EA%B5%90%EC%B0%A8%EA%B2%80%EC%A6%9D(Kfold)/%2F&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=views&edge_flat=false" alt="페이지 조회수 뱃지", width: 100%;, height: 100%;/> </a></div><div class="post-content"><h2 id="1-교차-검증">1. 교차 검증</h2><ul><li>과적합 : 모델이 학습 데이터에마 과도하게 최적화된 현상. 그로인해 일반화된 데이터에서는 예측 성능이 과하게 떨어지는 현상</li><li>지난번 와인 맛 평가에서 훈련용 데이터의 Acc는 72.94, 테스트용 데이터는 Acc가 71.61%였는데, 누가 이결과가 정말 괜찮은 것인지 묻는다면?</li><li>나에게 주어진 데이터에 적용한 모델의 성능을 정확히 표현하기 위해서도 유용하다</li><li>train 데이터를 다시 나누어 validation 데이터로 사용함으로써 과적합을 막는 방법</li><li>검증이 끝나면 다시 train데이터로 학습 한 뒤 test로 마지막 결과를 확인한다</li></ul><h2 id="2-교차검증-구현하기">2. 교차검증 구현하기</h2><h3 id="21-simple-example">2.1 simple example</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">kf</span><span class="p">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">kf</span><span class="p">)</span>
<span class="k">for</span> <span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span> <span class="ow">in</span> <span class="n">kf</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'-----idx'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'-----train data'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">train_idx</span><span class="p">])</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'-----test data'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">test_idx</span><span class="p">])</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre><td class="rouge-code"><pre>2
KFold(n_splits=2, random_state=None, shuffle=False)
-----idx
[2 3] [0 1]
-----train data
[[1 2]
 [3 4]]
-----test data
[[1 2]
 [3 4]]
-----idx
[0 1] [2 3]
-----train data
[[1 2]
 [3 4]]
-----test data
[[1 2]
 [3 4]]
</pre></table></code></div></div><ul><li>Kfold는 sklearn에 포함되어 있음.</li></ul><h3 id="22-와인맛-분류">2.2 와인맛 분류</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>


<span class="n">red_wine</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">red_url</span><span class="p">,</span> <span class="n">sep</span> <span class="o">=</span> <span class="s">';'</span><span class="p">)</span>
<span class="n">white_wine</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">white_url</span><span class="p">,</span> <span class="n">sep</span> <span class="o">=</span> <span class="s">';'</span><span class="p">)</span>

<span class="n">red_wine</span><span class="p">[</span><span class="s">'color'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">white_wine</span><span class="p">[</span><span class="s">'color'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">wine</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span><span class="n">red_wine</span><span class="p">,</span> <span class="n">white_wine</span><span class="p">])</span>
</pre></table></code></div></div><h3 id="23-와인맛-분류기를-위한-데이터-정리">2.3 와인맛 분류기를 위한 데이터 정리</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">wine</span><span class="p">[</span><span class="s">'taste'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.</span> <span class="k">if</span> <span class="n">grade</span> <span class="o">&gt;</span> <span class="mi">5</span> <span class="k">else</span> <span class="mf">0.</span> <span class="k">for</span> <span class="n">grade</span> <span class="ow">in</span> <span class="n">wine</span><span class="p">[</span><span class="s">'quality'</span><span class="p">]]</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">wine</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'taste'</span><span class="p">,</span> <span class="s">'quality'</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">wine</span><span class="p">[</span><span class="s">'taste'</span><span class="p">]</span>
</pre></table></code></div></div><h3 id="24-의사결정-나무-모델">2.4 의사결정 나무 모델</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>

<span class="n">wine_tree</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">wine_tree</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">y_pred_tr</span> <span class="o">=</span> <span class="n">wine_tree</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">wine_tree</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'Train Acc : '</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred_tr</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Test Acc : '</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>Train Acc :  0.7294593034442948
Test Acc :  0.7161538461538461
</pre></table></code></div></div><ul><li>Kfold를 진행하지 않고 바로 train으로 데이터를 학습 한뒤 결과를 도출해냄</li><li>데이터를 train_test_split으로 랜덤하게 분리하는게 맞는것인지? 혹은 이것이 최선인건가?</li><li>또한, 저 acc는 신뢰할수 있는지에 대한 검증이 필요함</li></ul><h3 id="25-kfold">2.5 KFold</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>

<span class="n">kfold</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">wine_tree_cv</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
</pre></table></code></div></div><ul><li>Kfold를 만들고, 분류기도 다시 생성</li><li>cv = cross validation의 약자</li></ul><h3 id="26-kfold는-index를-반환함">2.6 KFold는 index를 반환함</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="k">for</span> <span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span> <span class="ow">in</span> <span class="n">kfold</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_idx</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_idx</span><span class="p">))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>5197 1300
5197 1300
5198 1299
5198 1299
5198 1299
</pre></table></code></div></div><h3 id="27-각각의-fold에-대한-학습후-acc">2.7 각각의 fold에 대한 학습후 acc</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="n">cv_accuracy</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span> <span class="ow">in</span> <span class="n">kfold</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">X</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">y</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>
    <span class="n">wine_tree_cv</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">wine_tree_cv</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">cv_accuracy</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
    
<span class="n">cv_accuracy</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>[0.6007692307692307,
 0.6884615384615385,
 0.7090069284064665,
 0.7628945342571208,
 0.7867590454195535]
</pre></table></code></div></div><h3 id="28-각-acc의-분산이-크지-않다면-평균을-대표값으로">2.8 각 acc의 분산이 크지 않다면 평균을 대표값으로</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_accuracy</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>0.709578255462782
</pre></table></code></div></div><h3 id="29-stratifiedkfold">2.9 StratifiedKFold</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>

<span class="n">skfold</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">wine_tree_cv</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>

<span class="n">cv_accuracy</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span> <span class="ow">in</span> <span class="n">skfold</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">X</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>
    <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">y</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>
    <span class="n">wine_tree_cv</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">wine_tree_cv</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">cv_accuracy</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
    
<span class="n">cv_accuracy</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>[0.5523076923076923,
 0.6884615384615385,
 0.7143956889915319,
 0.7321016166281755,
 0.7567359507313318]
</pre></table></code></div></div><h3 id="210-acc의-평균이-더-나쁨">2.10 acc의 평균이 더 나쁨</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_accuracy</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>0.6888004974240539
</pre></table></code></div></div><ul><li>인덱스를 반환하기 때문에 for문으로 각각 데이터를 validation하였다.</li><li>하지만 이렇게 불편하게 코드를 하나하나 짜가면서 해야하는것일까?</li></ul><h3 id="211-cross-validation을-보다-더-간편하게">2.11 cross validation을 보다 더 간편하게</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="n">skfold</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">wine_tree_cv</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>

<span class="n">cross_val_score</span><span class="p">(</span><span class="n">wine_tree_cv</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">skfold</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>array([0.55230769, 0.68846154, 0.71439569, 0.73210162, 0.75673595])
</pre></table></code></div></div><ul><li>위의 예제처럼 for문 코드를 짜서 돌리는것이 아닌 이미 Sklean에 cross_val_score로 한다</li><li>sklearn에 cross_val_score에 분류기, X, y, Fold객체를 넣어주면된다</li><li>skfold의 n_splits = 5는 데이터를 5개로 나누어 validation한다는 뜻</li></ul><h3 id="212-depth가-높다고-무조건-acc가-높은것도-아님">2.12 depth가 높다고 무조건 acc가 높은것도 아님</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="n">skfold</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">wine_tree_cv</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>

<span class="n">cross_val_score</span><span class="p">(</span><span class="n">wine_tree_cv</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">skfold</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>array([0.50076923, 0.62615385, 0.69745958, 0.7582756 , 0.74903772])
</pre></table></code></div></div><ul><li>의사결정 나무의 max_depth를 늘려서 accuracy를 보았으나, 무조건 높아지는것도 아님을 확인</li></ul><h3 id="213-train-score와-함께-보고싶다면">2.13 train score와 함께 보고싶다면</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span>
<span class="n">cross_validate</span><span class="p">(</span><span class="n">wine_tree_cv</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">skfold</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>{'fit_time': array([0.01485896, 0.01390481, 0.01378489, 0.01321983, 0.0129869 ]),
 'score_time': array([0.00206208, 0.00191903, 0.00187325, 0.00179911, 0.00170922]),
 'test_score': array([0.50076923, 0.62615385, 0.69745958, 0.7582756 , 0.74903772]),
 'train_score': array([0.78795459, 0.78045026, 0.77568295, 0.76356291, 0.76279338])}
</pre></table></code></div></div><ul><li>cross_validate의 return_train_score를 쓰면됨</li><li>train과 test의 격차를 보니 과적합이 있는듯 하다.</li></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/data-science/'>Data Science</a>, <a href='/categories/machine-learning/'>Machine Learning</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/kfold/" class="post-tag no-text-decoration" >Kfold</a> <a href="/tags/stratifiedkfold/" class="post-tag no-text-decoration" >StratifiedKFold</a> <a href="/tags/cross_val_score/" class="post-tag no-text-decoration" >Cross_val_score</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><!-- Post sharing snippet v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=교차검증(Kfold) - Data Include Me&url=https://datainclude.me/posts/%EA%B5%90%EC%B0%A8%EA%B2%80%EC%A6%9D(Kfold)/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=교차검증(Kfold) - Data Include Me&u=https://datainclude.me/posts/%EA%B5%90%EC%B0%A8%EA%B2%80%EC%A6%9D(Kfold)/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=교차검증(Kfold) - Data Include Me&url=https://datainclude.me/posts/%EA%B5%90%EC%B0%A8%EA%B2%80%EC%A6%9D(Kfold)/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><!-- The Panel on right side (Desktop views) v2.3 © 2024 Your Name MIT License --><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><h3 data-toc-skip>Recent Update</h3><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li class="recent-item"> <a href="/posts/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C_%EC%BB%B4%ED%93%A8%ED%8C%85_%EA%B0%80%EC%83%81%ED%99%94/">클라우드 컴퓨팅 - 가상화</a> <span class="text-muted small">2024-10-28</span></li><li class="recent-item"> <a href="/posts/gemini_api_%EC%82%AC%EC%9A%A9%ED%95%B4%EB%B3%B4%EA%B8%B0/">Gemini API 사용해보기</a> <span class="text-muted small">2024-03-12</span></li><li class="recent-item"> <a href="/posts/Ollama%EC%99%80_Python_%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC_LLaMa2%EB%A5%BC_%EB%A1%9C%EC%BB%AC%EC%97%90%EC%84%9C_%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/">Ollama와 Python 라이브러리를 이용하여 LLaMa2를 로컬에서 사용하기</a> <span class="text-muted small">2024-02-13</span></li><li class="recent-item"> <a href="/posts/Mistral_7B_Fine_Tuning/">Mistral 7B 파인튜닝(Fine Tuning)하기</a> <span class="text-muted small">2023-10-25</span></li><li class="recent-item"> <a href="/posts/Penn_Fudan%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EA%B0%9D%EC%B2%B4_%ED%83%90%EC%A7%80_%EB%B6%84%ED%95%A0/">Penn-Fudan으로 알아보는 객체 탐지(Object Detection), 분할(Segmentation) with FasterRCNN</a> <span class="text-muted small">2023-10-23</span></li></ul></div><div id="access-tags"><h3 data-toc-skip>Trending Tags</h3><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/tensorflow/">Tensorflow</a> <a class="post-tag" href="/tags/sklearn/">Sklearn</a> <a class="post-tag" href="/tags/round/">Round</a> <a class="post-tag" href="/tags/python-lv0/">Python Lv0</a> <a class="post-tag" href="/tags/pca/">PCA</a> <a class="post-tag" href="/tags/eda/">EDA</a> <a class="post-tag" href="/tags/distinct/">Distinct</a> <a class="post-tag" href="/tags/random-forest/">Random Forest</a> <a class="post-tag" href="/tags/beautifulsoup/">Beautifulsoup</a> <a class="post-tag" href="/tags/baekjoon/">Baekjoon</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><h3 data-toc-skip class="pl-3 pt-2 mb-2">Contents</h3><nav id="toc" data-toggle="toc"></nav></div></div><style> .recent-item { margin-bottom: 0.5rem; } .recent-item a { color: var(--link-color); } .recent-item .small { font-size: 0.75rem; margin-left: 0.5rem; }</style></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"> <!-- Recommend the other 3 posts according to the tags and categories of the current post, if the number is not enough, use the other latest posts to supplement. v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/PCA_tSNE_LDA%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EC%B0%A8%EC%9B%90_%EC%B6%95%EC%86%8C/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Sep 8, 2023 <i class="unloaded">2023-09-08T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>PCA, t-SNE, LDA으로 알아보는 차원 축소</h3><div class="text-muted small"><p> 차원 축소는 데이터의 차원을 줄여서 데이터를 간결하게 만드는 기술이다. 시각화, 데이터 축소, 노이즈 제거, 성능 향상 및 계산 시간 감소를 위해 사용한다. 대표적인 차원 축소 알고리즘으로는 PCA, t-SNE, LDA가 있으며, 각 알고리즘은 장점과 단점이 있다. 차원 축소는 머신 러닝 모델의 성능에 긍부적 적인 영향을 미치며, 특성 선택과 차원 축...</p></div></div></a></div><div class="card"> <a href="/posts/%EC%9D%98%EC%82%AC%EA%B2%B0%EC%A0%95%EB%82%98%EB%AC%B4(Decision_Tree)_-1/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Sep 20, 2020 <i class="unloaded">2020-09-20T21:30:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>의사결정나무(Decision Tree) -1</h3><div class="text-muted small"><p> 1. 머신 러닝이란? 1.1 머신러닝의 교과서적 정의 명시적으로 프로그래밍을 하지 않고 컴퓨터에 학습할 수 있는 능력을 부여여한 학문 과거의 데이터로부터 얻은 경험이 쌓여 감에 따라 주어진 태스크의 성능이 점점 좋아질 때 컴퓨터 프로그램은 경험으로부터 학습한다. Machine이 주어진 데이터를 통해 규칙을 찾는것 2. 의사결정나무(De...</p></div></div></a></div><div class="card"> <a href="/posts/%EC%9D%98%EC%82%AC%EA%B2%B0%EC%A0%95%EB%82%98%EB%AC%B4(Decision_Tree)_-2/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Sep 20, 2020 <i class="unloaded">2020-09-20T22:30:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>의사결정나무(Decision Tree) -2</h3><div class="text-muted small"><p> 1. 머신러닝 1.1 지도학습이란 학습 대상이 되는 데이터에 정답(label)을 붙여서 학습 시키고 모델을 얻어서 완전히 새로운 데이터에 모델을 사용해서 ‘답’을 얻고자 하는것 1.2 데이터의 분리 (훈련(train)/ 검증(validation)/ 평가(test)) 전체 데이터에서 train / test 로 데이터를 분리하고 tr...</p></div></div></a></div></div></div><!-- Navigation buttons at the bottom of the post. v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --><div class="post-navigation d-flex justify-content-between"> <a href="/posts/%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8(Pipeline)/" class="btn btn-outline-primary"><p>파이프라인(Pipeline)</p></a> <a href="/posts/%ED%95%98%EC%9D%B4%ED%8D%BC%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0_%ED%8A%9C%EB%8B%9D(Hyperparameter_Tuning)/" class="btn btn-outline-primary"><p>하이퍼파라미터 튜닝(Hyperparameter Tuning)</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('#post-wrapper img'); const observer = lozad(imgs); observer.observe(); </script></div><!-- The Search results v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/tensorflow/">Tensorflow</a> <a class="post-tag" href="/tags/sklearn/">Sklearn</a> <a class="post-tag" href="/tags/round/">Round</a> <a class="post-tag" href="/tags/python-lv0/">Python Lv0</a> <a class="post-tag" href="/tags/pca/">PCA</a> <a class="post-tag" href="/tags/eda/">EDA</a> <a class="post-tag" href="/tags/distinct/">Distinct</a> <a class="post-tag" href="/tags/random-forest/">Random Forest</a> <a class="post-tag" href="/tags/beautifulsoup/">Beautifulsoup</a> <a class="post-tag" href="/tags/baekjoon/">Baekjoon</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <!-- The GA snippet v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <!-- Jekyll Simple Search loader v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://datainclude.me{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script>
