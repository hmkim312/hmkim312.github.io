<!DOCTYPE html><html lang="ko" mode="light" > <!-- The Head v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Prediction을 위한 Titanic EDA | Data Include Me</title><meta name="generator" content="Jekyll v3.9.3" /><meta property="og:title" content="Prediction을 위한 Titanic EDA" /><meta name="author" content="HyunMin Kim" /><meta property="og:locale" content="ko" /><meta name="description" content="The sinking of the Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. That’s why the name DieTanic. This is a very unforgetable disaster that no one in the world can forget." /><meta property="og:description" content="The sinking of the Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. That’s why the name DieTanic. This is a very unforgetable disaster that no one in the world can forget." /><link rel="canonical" href="https://datainclude.me/posts/Prediction%EC%9D%84_%EC%9C%84%ED%95%9C_Titanic_EDA/" /><meta property="og:url" content="https://datainclude.me/posts/Prediction%EC%9D%84_%EC%9C%84%ED%95%9C_Titanic_EDA/" /><meta property="og:site_name" content="Data Include Me" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-11-05T00:30:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Prediction을 위한 Titanic EDA" /><meta name="twitter:site" content="@" /><meta name="twitter:creator" content="@HyunMin Kim" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"HyunMin Kim"},"dateModified":"2020-11-05T00:30:00+09:00","datePublished":"2020-11-05T00:30:00+09:00","description":"The sinking of the Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. That’s why the name DieTanic. This is a very unforgetable disaster that no one in the world can forget.","headline":"Prediction을 위한 Titanic EDA","mainEntityOfPage":{"@type":"WebPage","@id":"https://datainclude.me/posts/Prediction%EC%9D%84_%EC%9C%84%ED%95%9C_Titanic_EDA/"},"url":"https://datainclude.me/posts/Prediction%EC%9D%84_%EC%9C%84%ED%95%9C_Titanic_EDA/"}</script><meta property="og:image" content="https://datainclude.me/assets/img/sample/avatar.jpg" /> <!-- The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps Generated by: https://www.favicon-generator.org/ v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT license --><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="36x36" href="/assets/img/favicons/android-icon-36x36.png"><link rel="icon" type="image/png" sizes="48x48" href="/assets/img/favicons/android-icon-48x48.png"><link rel="icon" type="image/png" sizes="72x72" href="/assets/img/favicons/android-icon-72x72.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/android-icon-96x96.png"><link rel="icon" type="image/png" sizes="144x144" href="/assets/img/favicons/android-icon-144x144.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="70x70" href="/assets/img/favicons/ms-icon-70x70.png"><link rel="icon" type="image/png" sizes="144x144" href="/assets/img/favicons/ms-icon-144x144.png"><link rel="icon" type="image/png" sizes="150x150" href="/assets/img/favicons/ms-icon-150x150.png"><link rel="icon" type="image/png" sizes="310x310" href="/assets/img/favicons/ms-icon-310x310.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preload" href="https://www.googletagmanager.com/gtm.js?id=GTM-MW9VRMW9" as="script"> <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src= 'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f); })(window,document,'script','dataLayer','GTM-MW9VRMW9');</script><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="preload" as="style" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous" media="print" onload="this.media='all'"> <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"> </noscript> <!-- CSS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --><link rel="preload" as="style" href="/assets/css/post.css"><link rel="stylesheet" href="/assets/css/post.css"><link rel="preload" as="style" href="/assets/css/lib/bootstrap-toc.min.css"><link rel="stylesheet" href="/assets/css/lib/bootstrap-toc.min.css" /><link rel="preload" as="script" href="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" async></script> <!-- JS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --> <script src="/assets/js/post.min.js" async></script> <script src="/app.js" defer></script><body data-spy="scroll" data-target="#toc"> <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MW9VRMW9" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="sidebar" class="d-flex flex-column"> <!-- The Side Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="nav-wrapper"><div id="profile-wrapper" class="d-flex flex-column"><div id="avatar" class="d-flex justify-content-center"> <a href="/" alt="avatar"> <img src="/assets/img/sample/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="profile-text mt-3"><div class="site-title"> <a href="/">Data Include Me</a></div><div class="site-subtitle font-italic">Data Science Blog</div></div></div><ul class="nav flex-column"><li class="nav-item d-flex justify-content-center "> <a href="/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/categories/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/tags/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/archives/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/about/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></li></ul></div><div class="sidebar-bottom d-flex flex-wrap justify-content-around mt-4"> <a href="https://github.com/hmkim312" target="_blank"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/" target="_blank"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:window.open('mailto:' + ['sanarial312','gmail.com'].join('@'))" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" > <i class="fas fa-rss"></i> </a></div></div><!-- The Top Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Prediction을 위한 Titanic EDA</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"> <!-- Refactor the HTML structure. --> <!-- Suroundding the markdown table with '<div class="table-wrapper">. and '</div>' --> <!-- Fixed kramdown code highlight rendering: https://github.com/penibelst/jekyll-compress-html/issues/101 https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901 --><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"> <script type="text/javascript"> var lazyloadads = false; function loadAds() { if (!lazyloadads) { var script = document.createElement("script"); script.type = "text/javascript"; script.async = true; script.src = "https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7594406644928408"; document.body.appendChild(script); lazyloadads = true; } } window.addEventListener("mousemove", loadAds, { once: true }); window.addEventListener('touchstart', loadAds, { once: true }); </script><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Prediction을 위한 Titanic EDA</h1><div class="post-meta text-muted d-flex flex-column"><div> Posted <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Thu, Nov 5, 2020, 12:30 AM +0900" > Nov 5, 2020 <i class="unloaded">2020-11-05T00:30:00+09:00</i> </span> by <span class="author"> HyunMin Kim </span></div><a href="https://hits.seeyoufarm.com"> <img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https://datainclude.me/posts/Prediction%EC%9D%84_%EC%9C%84%ED%95%9C_Titanic_EDA/%2F&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=views&edge_flat=false" alt="페이지 조회수 뱃지", width: 100%;, height: 100%;/> </a></div><div class="post-content"><ul><li><p>The sinking of the Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. That’s why the name DieTanic. This is a very unforgetable disaster that no one in the world can forget.</p></li><li><p>It took about $7.5 million to build the Titanic and it sunk under the ocean due to collision. The Titanic Dataset is a very good dataset for begineers to start a journey in data science and participate in competitions in Kaggle.</p></li><li><p>The Objective of this notebook is to give an idea how is the workflow in any predictive modeling problem. How do we check features, how do we add new features and some Machine Learning Concepts. I have tried to keep the notebook as basic as possible so that even newbies can understand every phase of it.</p></li><li><p>If You Like the notebook and think that it helped you..PLEASE UPVOTE. It will keep me motivated.</p></li><li><p>출처 : <a href="https://www.kaggle.com/ash316/eda-to-prediction-dietanic" target="_blank">https://www.kaggle.com/ash316/eda-to-prediction-dietanic</a></p></li></ul><h3 id="contents-of-the-notebook">Contents of the Notebook:</h3><h4 id="part1-exploratory-data-analysiseda">Part1: Exploratory Data Analysis(EDA):</h4><ul><li>1)Analysis of the features.</li><li>2)Finding any relations or trends considering multiple features.</li></ul><h4 id="part2-feature-engineering-and-data-cleaning">Part2: Feature Engineering and Data Cleaning:</h4><ul><li>1)Adding any few features.</li><li>2)Removing redundant features.</li><li>3)Converting features into suitable form for modeling.</li></ul><h4 id="part3-predictive-modeling">Part3: Predictive Modeling</h4><ul><li>1)Running Basic Algorithms.</li><li>2)Cross Validation.</li><li>3)Ensembling.</li><li>4)Important Features Extraction.</li></ul><hr /><p><br /></p><h3 id="part1-exploratory-data-analysiseda-1">Part1: Exploratory Data Analysis(EDA)</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="c1"># 기본설정
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="n">use</span><span class="p">(</span><span class="s">'fivethirtyeight'</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="p">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s">'ignore'</span><span class="p">)</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="c1"># 데이터 로드
</span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'data/train.csv'</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="c1"># 데이터 확인
</span><span class="n">data</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</pre></table></code></div></div><div style="width:100%; height:200px; overflow:auto"><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>PassengerId<th>Survived<th>Pclass<th>Name<th>Sex<th>Age<th>SibSp<th>Parch<th>Ticket<th>Fare<th>Cabin<th>Embarked<tbody><tr><th>0<td>1<td>0<td>3<td>Braund, Mr. Owen Harris<td>male<td>22.0<td>1<td>0<td>A/5 21171<td>7.2500<td>NaN<td>S<tr><th>1<td>2<td>1<td>1<td>Cumings, Mrs. John Bradley (Florence Briggs Th...<td>female<td>38.0<td>1<td>0<td>PC 17599<td>71.2833<td>C85<td>C<tr><th>2<td>3<td>1<td>3<td>Heikkinen, Miss. Laina<td>female<td>26.0<td>0<td>0<td>STON/O2. 3101282<td>7.9250<td>NaN<td>S<tr><th>3<td>4<td>1<td>1<td>Futrelle, Mrs. Jacques Heath (Lily May Peel)<td>female<td>35.0<td>1<td>0<td>113803<td>53.1000<td>C123<td>S<tr><th>4<td>5<td>0<td>3<td>Allen, Mr. William Henry<td>male<td>35.0<td>0<td>0<td>373450<td>8.0500<td>NaN<td>S</table></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="c1"># null 값 확인
# age와 cabin에 null값이 있음
</span><span class="n">data</span><span class="p">.</span><span class="n">isnull</span><span class="p">().</span><span class="nb">sum</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre>PassengerId      0
Survived         0
Pclass           0
Name             0
Sex              0
Age            177
SibSp            0
Parch            0
Ticket           0
Fare             0
Cabin          687
Embarked         2
dtype: int64
</pre></table></code></div></div><p><br /></p><h4 id="how-many-survived">How many Survived</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s">'Survived'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">().</span><span class="n">plot</span><span class="p">.</span><span class="n">pie</span><span class="p">(</span><span class="n">explode</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.1</span><span class="p">],</span> <span class="n">autopct</span> <span class="o">=</span> <span class="s">'%1.1f%%'</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shadow</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Survived'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">''</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="s">'Survived'</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Survived'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234590-05f56d00-1fa4-11eb-987d-bb470a322e44.png" /></p><ul><li>Observations<ul><li>891명의 승객중 350명이 살았으며, 이는 38.4%에 해당한다.</li><li>누가 살고 죽었는지 확인하기 위해 Sex, Port of Embarcation, Age, etc를 살펴보겠다</li></ul></li></ul><p><br /></p><h4 id="analysing-the-features">Analysing The Features</h4><ul><li>Sex–&gt; Categorical Feature</li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">data</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'Sex'</span><span class="p">,</span> <span class="s">'Survived'</span><span class="p">])[</span><span class="s">'Survived'</span><span class="p">].</span><span class="n">count</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre>Sex     Survived
female  0            81
        1           233
male    0           468
        1           109
Name: Survived, dtype: int64
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">data</span><span class="p">[[</span><span class="s">'Sex'</span><span class="p">,</span> <span class="s">'Survived'</span><span class="p">]].</span><span class="n">groupby</span><span class="p">([</span><span class="s">'Sex'</span><span class="p">]).</span><span class="n">mean</span><span class="p">().</span><span class="n">plot</span><span class="p">.</span><span class="n">bar</span><span class="p">(</span><span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Survived vs Sex'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="s">'Sex'</span><span class="p">,</span> <span class="n">hue</span> <span class="o">=</span> <span class="s">'Survived'</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Sex : Survived vs Dead'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234600-0aba2100-1fa4-11eb-8c27-6c187831ad2e.png" /></p><ul><li>Observations<ul><li>남자보다 여자가 생존율이 2배 이상 좋음</li></ul></li><li>Pclass -&gt; Ordinal Feature</li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">pd</span><span class="p">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">Pclass</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">Survived</span><span class="p">,</span> <span class="n">margins</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">style</span><span class="p">.</span><span class="n">background_gradient</span><span class="p">(</span><span class="n">cmap</span> <span class="o">=</span> <span class="s">'summer_r'</span><span class="p">)</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98235160-cb400480-1fa4-11eb-96bd-fd5c03f20b41.png" /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">18</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s">'Pclass'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">().</span><span class="n">plot</span><span class="p">.</span><span class="n">bar</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s">'#CD7F32'</span><span class="p">,</span> <span class="s">'#FFDF00'</span><span class="p">,</span> <span class="s">'#D3D3D3'</span><span class="p">],</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Number Of Passengers By Pclass'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'Count'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="s">'Pclass'</span><span class="p">,</span> <span class="n">hue</span> <span class="o">=</span> <span class="s">'Survived'</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Pclass : Survived vs Dead'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234605-0beb4e00-1fa4-11eb-8f3a-77064f328ea2.png" /></p><ul><li>Observations<ul><li>pclass가 낮을수록 생존율이 높음을 알수있다</li></ul></li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="c1"># 성별과 pclass를 같이 살펴보기
</span><span class="n">pd</span><span class="p">.</span><span class="n">crosstab</span><span class="p">([</span><span class="n">data</span><span class="p">.</span><span class="n">Sex</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">Survived</span><span class="p">],</span> <span class="n">data</span><span class="p">.</span><span class="n">Pclass</span><span class="p">,</span> <span class="n">margins</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">style</span><span class="p">.</span><span class="n">background_gradient</span><span class="p">(</span><span class="n">cmap</span> <span class="o">=</span> <span class="s">'summer_r'</span><span class="p">)</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98235229-e90d6980-1fa4-11eb-9609-71f8f95689f7.png" /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">sns</span><span class="p">.</span><span class="n">factorplot</span><span class="p">(</span><span class="s">'Pclass'</span><span class="p">,</span> <span class="s">'Survived'</span><span class="p">,</span> <span class="n">hue</span> <span class="o">=</span> <span class="s">'Sex'</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234607-0d1c7b00-1fa4-11eb-8657-988c4205e7b6.png" /></p><ul><li>Observations<ul><li>Pclass 또한 생존율에 영향을 미친 중요한 feature이다</li></ul></li><li>Age -&gt; Continous Feature</li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="k">print</span><span class="p">(</span><span class="s">'Oldset Passenger was of:'</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s">'Age'</span><span class="p">].</span><span class="nb">max</span><span class="p">(),</span> <span class="s">'Years'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Youngest Passenger was of:'</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s">'Age'</span><span class="p">].</span><span class="nb">min</span><span class="p">(),</span> <span class="s">'Years'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Average Age on the ship:'</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s">'Age'</span><span class="p">].</span><span class="n">mean</span><span class="p">(),</span> <span class="s">'Years'</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>Oldset Passenger was of: 80.0 Years
Youngest Passenger was of: 0.42 Years
Average Age on the ship: 29.69911764705882 Years
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">violinplot</span><span class="p">(</span><span class="s">'Pclass'</span><span class="p">,</span> <span class="s">'Age'</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'Survived'</span><span class="p">,</span>
               <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Pclass and Age vs Survived'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">110</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">violinplot</span><span class="p">(</span><span class="s">'Sex'</span><span class="p">,</span> <span class="s">'Age'</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'Survived'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Sex and Age vs Survived'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">110</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234612-0db51180-1fa4-11eb-9827-4a203aed7d28.png" /></p><ul><li>Observations<ul><li>10세 미만 어린이는 생존율이 높고, 20~50대는 1등급을 제외하곤 모두 생존율이 낮다.</li></ul></li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="c1"># 이름앞에 mr mrs 등을 추출
</span><span class="n">data</span><span class="p">[</span><span class="s">'Initial'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
    <span class="n">data</span><span class="p">[</span><span class="s">'Initial'</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">Name</span><span class="p">.</span><span class="nb">str</span><span class="p">.</span><span class="n">extract</span><span class="p">(</span><span class="s">'([A-Za-z]+)\.'</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s">'Initial'</span><span class="p">]</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre>0        Mr
1       Mrs
2      Miss
3       Mrs
4        Mr
       ... 
886     Rev
887    Miss
888    Miss
889      Mr
890      Mr
Name: Initial, Length: 891, dtype: object
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">pd</span><span class="p">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">Initial</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">Sex</span><span class="p">).</span><span class="n">T</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="n">background_gradient</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="s">'summer_r'</span><span class="p">)</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98235539-443f5c00-1fa5-11eb-9bd7-09d7283837dd.png" /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="c1"># miss, mr, mrs, other로 변경
</span><span class="n">data</span><span class="p">[</span><span class="s">'Initial'</span><span class="p">].</span><span class="n">replace</span><span class="p">([</span><span class="s">'Mlle'</span><span class="p">,</span> <span class="s">'Mme'</span><span class="p">,</span> <span class="s">'Ms'</span><span class="p">,</span> <span class="s">'Dr'</span><span class="p">,</span> <span class="s">'Major'</span><span class="p">,</span> <span class="s">'Lady'</span><span class="p">,</span> <span class="s">'Countess'</span><span class="p">,</span> <span class="s">'Jonkheer'</span><span class="p">,</span> <span class="s">'Col'</span><span class="p">,</span> <span class="s">'Rev'</span><span class="p">,</span> <span class="s">'Capt'</span><span class="p">,</span> <span class="s">'Sir'</span><span class="p">,</span> <span class="s">'Don'</span><span class="p">],</span> <span class="p">[</span>
                        <span class="s">'Miss'</span><span class="p">,</span> <span class="s">'Miss'</span><span class="p">,</span> <span class="s">'Miss'</span><span class="p">,</span> <span class="s">'Mr'</span><span class="p">,</span> <span class="s">'Mr'</span><span class="p">,</span> <span class="s">'Mrs'</span><span class="p">,</span> <span class="s">'Mrs'</span><span class="p">,</span> <span class="s">'Other'</span><span class="p">,</span> <span class="s">'Other'</span><span class="p">,</span> <span class="s">'Other'</span><span class="p">,</span> <span class="s">'Mr'</span><span class="p">,</span> <span class="s">'Mr'</span><span class="p">,</span> <span class="s">'Mr'</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="c1"># 칭호별 평균 나이
</span><span class="n">data</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'Initial'</span><span class="p">)[</span><span class="s">'Age'</span><span class="p">].</span><span class="n">mean</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre>Initial
Master     4.574167
Miss      21.860000
Mr        32.739609
Mrs       35.981818
Other     45.888889
Name: Age, dtype: float64
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="c1"># NaN Age 채우기
</span><span class="n">data</span><span class="p">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">data</span><span class="p">.</span><span class="n">Age</span><span class="p">.</span><span class="n">isnull</span><span class="p">())</span><span class="o">&amp;</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">Initial</span> <span class="o">==</span> <span class="s">'Mr'</span><span class="p">),</span> <span class="s">'Age'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">33</span>
<span class="n">data</span><span class="p">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">data</span><span class="p">.</span><span class="n">Age</span><span class="p">.</span><span class="n">isnull</span><span class="p">())</span><span class="o">&amp;</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">Initial</span> <span class="o">==</span> <span class="s">'Master'</span><span class="p">),</span> <span class="s">'Age'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">data</span><span class="p">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">data</span><span class="p">.</span><span class="n">Age</span><span class="p">.</span><span class="n">isnull</span><span class="p">())</span><span class="o">&amp;</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">Initial</span> <span class="o">==</span> <span class="s">'Miss'</span><span class="p">),</span> <span class="s">'Age'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">22</span>
<span class="n">data</span><span class="p">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">data</span><span class="p">.</span><span class="n">Age</span><span class="p">.</span><span class="n">isnull</span><span class="p">())</span><span class="o">&amp;</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">Initial</span> <span class="o">==</span> <span class="s">'Mrs'</span><span class="p">),</span> <span class="s">'Age'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">36</span>
<span class="n">data</span><span class="p">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">data</span><span class="p">.</span><span class="n">Age</span><span class="p">.</span><span class="n">isnull</span><span class="p">())</span><span class="o">&amp;</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">Initial</span> <span class="o">==</span> <span class="s">'Other'</span><span class="p">),</span> <span class="s">'Age'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">46</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="c1"># Nan 확인 any()를 사용, Null이 한개라도 있으면 True를 반환
</span><span class="n">data</span><span class="p">.</span><span class="n">Age</span><span class="p">.</span><span class="n">isnull</span><span class="p">().</span><span class="nb">any</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>False
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">.</span><span class="n">Survived</span> <span class="o">==</span> <span class="mi">0</span><span class="p">].</span><span class="n">Age</span><span class="p">.</span><span class="n">plot</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s">'black'</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">'red'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Survived = 0'</span><span class="p">)</span>
<span class="n">x1</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">85</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>

<span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">.</span><span class="n">Survived</span> <span class="o">==</span> <span class="mi">1</span><span class="p">].</span><span class="n">Age</span><span class="p">.</span><span class="n">plot</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span> <span class="o">=</span> <span class="s">'green'</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s">'black'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Survived = 1'</span><span class="p">)</span>
<span class="n">x2</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">85</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234620-0f7ed500-1fa4-11eb-8933-f547eafc65f8.png" /></p><ul><li>Observations<ul><li>5세 미만 아이는 살았다</li><li>80세 노인도 살았다</li><li>가장 많이 죽은 나이는 30-40대</li></ul></li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">sns</span><span class="p">.</span><span class="n">factorplot</span><span class="p">(</span><span class="s">'Pclass'</span><span class="p">,</span> <span class="s">'Survived'</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="s">'Initial'</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234623-10176b80-1fa4-11eb-9dde-8bba945b01d2.png" /></p><ul><li>Observations<ul><li>객실 등급을 무시하고 어린이와 아이가 가장 먼저 구조되었다</li></ul></li><li>Embarked -&gt; Categorical Value</li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">pd</span><span class="p">.</span><span class="n">crosstab</span><span class="p">([</span><span class="n">data</span><span class="p">.</span><span class="n">Embarked</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">Pclass</span><span class="p">],</span> <span class="p">[</span><span class="n">data</span><span class="p">.</span><span class="n">Sex</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">Survived</span><span class="p">],</span> <span class="n">margins</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">style</span><span class="p">.</span><span class="n">background_gradient</span><span class="p">(</span><span class="n">cmap</span> <span class="o">=</span> <span class="s">'summer_r'</span><span class="p">)</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98235718-8d8fab80-1fa5-11eb-8b31-100c9f1f4dc4.png" /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">sns</span><span class="p">.</span><span class="n">factorplot</span><span class="p">(</span><span class="s">'Embarked'</span><span class="p">,</span><span class="s">'Survived'</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234624-10b00200-1fa4-11eb-8278-c9634fc50d12.png" /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="s">'Embarked'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'No Of Passengers Boarded'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="s">'Embarked'</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'Sex'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Male - Female Split for Embarked'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="s">'Embarked'</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'Survived'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Embarked vs Survived'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="s">'Embarked'</span><span class="p">,</span> <span class="n">hue</span> <span class="o">=</span> <span class="s">'Pclass'</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Embarked vs Pclass'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234626-10b00200-1fa4-11eb-8815-7fda3903d57b.png" /></p><ul><li>Observations<ul><li>S 항구에서 많이 탔고 대부분 3등급객실임</li><li>C 항구는 1등급과 2등급 승객을 구조한것으로 예상됨</li><li>S 항구에서는 1등급 객실 인원이 많이 탔음</li><li>Q 항구는 95%의 승객이 3등급인원임</li></ul></li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">sns</span><span class="p">.</span><span class="n">factorplot</span><span class="p">(</span><span class="s">'Pclass'</span><span class="p">,</span> <span class="s">'Survived'</span><span class="p">,</span> <span class="n">hue</span> <span class="o">=</span> <span class="s">'Sex'</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="s">'Embarked'</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234629-11489880-1fa4-11eb-85c2-bd4c5669923d.png" /></p><ul><li>Observations<ul><li>1)Pclass1과 Pclass2의 여성은 Pclass와 관계없이 생존 확률은 거의 1이다.</li><li>2)남녀 모두의 생존율이 매우 낮기 때문에 Pclass3 Passenger에게는 포트S가 매우 불행해 보인다.(돈 문제)</li><li>3)포트 Q는 거의 모두가 Pclass 3에서 온 것처럼 남자에게는 가장 어울리지 않는 것 같다.</li></ul></li><li>Filling Embarked NaN</li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="c1"># Embarked NaN은 갯수가 가장 많은 S로 바꿈
</span><span class="n">data</span><span class="p">[</span><span class="s">'Embarked'</span><span class="p">].</span><span class="n">fillna</span><span class="p">(</span><span class="s">'S'</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="c1">#isnull().any()로 null값 확인 any로 인해 True가 나오면 1개라도 Null이 있는것
</span><span class="n">data</span><span class="p">[</span><span class="s">'Embarked'</span><span class="p">].</span><span class="n">isnull</span><span class="p">().</span><span class="nb">any</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>False
</pre></table></code></div></div><ul><li>SibSip -&gt; Discrete Feature<ul><li>Sibling = brother, sister, stepbrother, stepsister</li></ul></li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">pd</span><span class="p">.</span><span class="n">crosstab</span><span class="p">([</span><span class="n">data</span><span class="p">.</span><span class="n">SibSp</span><span class="p">],</span> <span class="n">data</span><span class="p">.</span><span class="n">Survived</span><span class="p">).</span><span class="n">style</span><span class="p">.</span><span class="n">background_gradient</span><span class="p">(</span><span class="n">cmap</span> <span class="o">=</span> <span class="s">'summer_r'</span><span class="p">)</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98235907-d6dffb00-1fa5-11eb-8216-2efb6b0b0e41.png" /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">(</span><span class="s">'SibSp'</span><span class="p">,</span> <span class="s">'Survived'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'SibSp vs Survived'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">factorplot</span><span class="p">(</span><span class="s">'SibSp'</span><span class="p">,</span> <span class="s">'Survived'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'SibSp vs Survived'</span><span class="p">)</span>
<span class="c1"># plt.close(2)
</span><span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234631-11e12f00-1fa4-11eb-80a8-6100d33f7dac.png" /> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234632-1279c580-1fa4-11eb-8973-2995844a70e0.png" /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">pd</span><span class="p">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">SibSp</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">Pclass</span><span class="p">).</span><span class="n">style</span><span class="p">.</span><span class="n">background_gradient</span><span class="p">(</span><span class="n">cmap</span> <span class="o">=</span> <span class="s">'summer_r'</span><span class="p">)</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98236016-055dd600-1fa6-11eb-9846-1cffc4676908.png" /></p><ul><li>Observations<ul><li>barplot과 factorplot에서 보이듯이 혼자온 탑승객은 34.5%의 생존율을 보임</li><li>대가족은 3클래스에 많이 있어서 많이 죽음</li></ul></li><li>Parch</li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">pd</span><span class="p">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">Parch</span><span class="p">,</span> <span class="n">data</span><span class="p">.</span><span class="n">Pclass</span><span class="p">).</span><span class="n">style</span><span class="p">.</span><span class="n">background_gradient</span><span class="p">(</span><span class="n">cmap</span> <span class="o">=</span> <span class="s">'summer_r'</span><span class="p">)</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98236095-23c3d180-1fa6-11eb-852f-dceb34395ae4.png" /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">(</span><span class="s">'Parch'</span><span class="p">,</span> <span class="s">'Survived'</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Parch vs Survived'</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">factorplot</span><span class="p">(</span><span class="s">'Parch'</span><span class="p">,</span> <span class="s">'Survived'</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Parch vs Survived'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234635-1279c580-1fa4-11eb-9a44-df716fa5f6d4.png" /> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234637-13125c00-1fa4-11eb-82ee-ce11f57615af.png" /></p><ul><li>Observations<ul><li>1 ~ 3명의 부모를 둔 가족의 생존율이 높고, 그 이상은 생존율이 작아진다.</li></ul></li><li>Fare -&gt; continous Feature</li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="k">print</span><span class="p">(</span><span class="s">'Highest Fare was:'</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s">'Fare'</span><span class="p">].</span><span class="nb">max</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Lowest Fare was:'</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s">'Fare'</span><span class="p">].</span><span class="nb">min</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Average Fare was:'</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s">'Fare'</span><span class="p">].</span><span class="n">mean</span><span class="p">())</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>Highest Fare was: 512.3292
Lowest Fare was: 0.0
Average Fare was: 32.2042079685746
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s">'Pclass'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">].</span><span class="n">Fare</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Fare in Pclass 1'</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s">'Pclass'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span><span class="p">].</span><span class="n">Fare</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Fare in Pclass 2'</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s">'Pclass'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">3</span><span class="p">].</span><span class="n">Fare</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Fare in Pclass 3'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234640-13aaf280-1fa4-11eb-9390-10a77484cb1f.png" /></p><ul><li>Observations in a Nutshell for all features:<ul><li>Sex: 여자가 남자보다 생존율이 높음</li><li>Pclass: 1등급객실이면 생존율이 높음</li><li>Age: 15 - 35 살 그룹 대비 5-10세 아이들의 생존율이 높다</li><li>Embarked: Pclass1 승객 대다수가 S에서 일어났음에도 불구하고 C에서 생존할 가능성은 더 좋아 보인다.</li><li>Parch+SibSp: 1-2명의 형제자매, 배우자 또는 1-3명의 부모들이 혼자 있거나 대가족이 당신과 함께 여행하는 것보다 생존할 가능성이 더 높다.</li></ul></li></ul><p><br /></p><h4 id="correlation-between-the-features">Correlation Between The Features</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">corr</span><span class="p">(),</span> <span class="n">annot</span><span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="s">'RdYlGn'</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">8</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234643-14438900-1fa4-11eb-88ee-c022ebcb79c8.png" /></p><ul><li>interpreting The Heatmap<ul><li><h2 id="pclass-fare와-상관관계가-있음">Pclass, Fare와 상관관계가 있음</h2><p><br /></p></li></ul></li></ul><h3 id="part2-feature-engineering-and-data-cleaning-1">Part2: Feature Engineering and Data Cleaning</h3><ul><li>Feature의 중복을 제거하거나, 새로운 Feature를 만들어내는것</li><li>이름에서 Initail을 만들어내는 것과 같은것</li></ul><p><br /></p><h4 id="age_band">Age_band</h4><ul><li>나이 변수는 지속적인 변수이며 이는 머신러닝에 적합하지 않음</li><li>Age_band를 만들어 그룹화 시켜줄것임</li><li>max age가 80세이고 5개로 그룹화하니 80/5 = 16이므로 16으로 나눔</li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="n">data</span><span class="p">[</span><span class="s">'Age_band'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">data</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s">'Age'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">16</span><span class="p">,</span> <span class="s">'Age_band'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">data</span><span class="p">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">data</span><span class="p">[</span><span class="s">'Age'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">16</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">'Age'</span><span class="p">]</span> <span class="o">&lt;=</span><span class="mi">32</span><span class="p">),</span> <span class="s">'Age_band'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">data</span><span class="p">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">data</span><span class="p">[</span><span class="s">'Age'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">32</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">'Age'</span><span class="p">]</span> <span class="o">&lt;=</span><span class="mi">48</span><span class="p">),</span> <span class="s">'Age_band'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">data</span><span class="p">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">data</span><span class="p">[</span><span class="s">'Age'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">48</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">'Age'</span><span class="p">]</span> <span class="o">&lt;=</span><span class="mi">64</span><span class="p">),</span> <span class="s">'Age_band'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">data</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s">'Age'</span><span class="p">]</span> <span class="o">&gt;</span><span class="mi">64</span><span class="p">,</span> <span class="s">'Age_band'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">data</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</pre></table></code></div></div><div style="width:100%; height:200px; overflow:auto"><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>PassengerId<th>Survived<th>Pclass<th>Name<th>Sex<th>Age<th>SibSp<th>Parch<th>Ticket<th>Fare<th>Cabin<th>Embarked<th>Initial<th>Age_band<tbody><tr><th>0<td>1<td>0<td>3<td>Braund, Mr. Owen Harris<td>male<td>22.0<td>1<td>0<td>A/5 21171<td>7.2500<td>NaN<td>S<td>Mr<td>1<tr><th>1<td>2<td>1<td>1<td>Cumings, Mrs. John Bradley (Florence Briggs Th...<td>female<td>38.0<td>1<td>0<td>PC 17599<td>71.2833<td>C85<td>C<td>Mrs<td>2<tr><th>2<td>3<td>1<td>3<td>Heikkinen, Miss. Laina<td>female<td>26.0<td>0<td>0<td>STON/O2. 3101282<td>7.9250<td>NaN<td>S<td>Miss<td>1<tr><th>3<td>4<td>1<td>1<td>Futrelle, Mrs. Jacques Heath (Lily May Peel)<td>female<td>35.0<td>1<td>0<td>113803<td>53.1000<td>C123<td>S<td>Mrs<td>2<tr><th>4<td>5<td>0<td>3<td>Allen, Mr. William Henry<td>male<td>35.0<td>0<td>0<td>373450<td>8.0500<td>NaN<td>S<td>Mr<td>2</table></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">data</span><span class="p">[</span><span class="s">'Age_band'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">().</span><span class="n">to_frame</span><span class="p">().</span><span class="n">style</span><span class="p">.</span><span class="n">background_gradient</span><span class="p">(</span><span class="n">cmap</span> <span class="o">=</span> <span class="s">'summer_r'</span><span class="p">)</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98236289-77ceb600-1fa6-11eb-9cc0-d35c4abf96da.png" /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">sns</span><span class="p">.</span><span class="n">factorplot</span><span class="p">(</span><span class="s">'Age_band'</span><span class="p">,</span> <span class="s">'Survived'</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="s">'Pclass'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234645-14dc1f80-1fa4-11eb-97db-32a3482bded4.png" /></p><ul><li>Observations<ul><li>생존율은 객실등급과 무관하게 나이가 많을수록 떨어짐</li></ul></li></ul><p><br /></p><h4 id="family_size-and-alone">Family_Size and Alone</h4><ul><li>새로운 Family_size와 Alone 변수를 만들것</li><li>두개의 변수는 Parch와 SibSP를 더해서 만듬</li><li>생존율이 탑승객 Family_size와 관련이 있는지 확인할 수 있도록 종합 데이터를 준다.</li><li>Alone 라는 것은 승객이 혼자인지 아닌지를 나타내는 것이다.</li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="n">data</span><span class="p">[</span><span class="s">'Family_Size'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">data</span><span class="p">[</span><span class="s">'Family_Size'</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'Parch'</span><span class="p">]</span> <span class="o">+</span> <span class="n">data</span><span class="p">[</span><span class="s">'SibSp'</span><span class="p">]</span>

<span class="n">data</span><span class="p">[</span><span class="s">'Alone'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">data</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">data</span><span class="p">.</span><span class="n">Family_Size</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">,</span> <span class="s">'Alone'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="n">sns</span><span class="p">.</span><span class="n">factorplot</span><span class="p">(</span><span class="s">'Family_Size'</span><span class="p">,</span> <span class="s">'Survived'</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Family_Size vs Survived'</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">factorplot</span><span class="p">(</span><span class="s">'Alone'</span><span class="p">,</span> <span class="s">'Survived'</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Alone vs Survived'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234648-160d4c80-1fa4-11eb-9f96-d1b46badbc08.png" /></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234651-160d4c80-1fa4-11eb-89e5-481585a342b9.png" /></p><ul><li>Observation<ul><li>Family_size가 0인것은 Alone이 1이다.</li><li>Family_size가 0과 4이상인것은 생존확률이 낮다</li><li>다만 1~3은 생존확률이 높다</li></ul></li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">sns</span><span class="p">.</span><span class="n">factorplot</span><span class="p">(</span><span class="s">'Alone'</span><span class="p">,</span> <span class="s">'Survived'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span> <span class="n">data</span><span class="p">,</span> <span class="n">hue</span> <span class="o">=</span> <span class="s">'Sex'</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="s">'Pclass'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234653-16a5e300-1fa4-11eb-8a68-d23e0a6252ab.png" /></p><ul><li>Observation<ul><li>pclass3을 제외하면 성별과 객실등급과는 무관하게 혼자온것은 생존율이 낮다</li></ul></li></ul><p><br /></p><h4 id="fare_range">Fare_Range</h4><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>- Fare도 연속적 수치이므로, 바꿔주도록 한다
- pandas의 qcut을 이용하면 범위를 만들수 있음
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">data</span><span class="p">[</span><span class="s">'Fare_Range'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">qcut</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">'Fare'</span><span class="p">],</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">data</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'Fare_Range'</span><span class="p">])[</span><span class="s">'Survived'</span><span class="p">].</span><span class="n">mean</span><span class="p">().</span><span class="n">to_frame</span><span class="p">().</span><span class="n">style</span><span class="p">.</span><span class="n">background_gradient</span><span class="p">(</span><span class="n">cmap</span> <span class="o">=</span> <span class="s">'summer_r'</span><span class="p">)</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98236438-b06e8f80-1fa6-11eb-8b5b-8acab8009e4f.png" /></p><ul><li>Age_band를 만든거 처럼 Fare_cat도 만듬</li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="n">data</span><span class="p">[</span><span class="s">'Fare_cat'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">data</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s">'Fare'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mf">7.91</span><span class="p">,</span> <span class="s">'Fare_cat'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">data</span><span class="p">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">data</span><span class="p">[</span><span class="s">'Fare'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">7.91</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">'Fare'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mf">14.454</span><span class="p">),</span> <span class="s">'Fare_cat'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">data</span><span class="p">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">data</span><span class="p">[</span><span class="s">'Fare'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">14.454</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">'Fare'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">31</span><span class="p">),</span> <span class="s">'Fare_cat'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">data</span><span class="p">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">data</span><span class="p">[</span><span class="s">'Fare'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">31</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">'Fare'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">513</span><span class="p">),</span> <span class="s">'Fare_cat'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">3</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">sns</span><span class="p">.</span><span class="n">factorplot</span><span class="p">(</span><span class="s">'Fare_cat'</span><span class="p">,</span><span class="s">'Survived'</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">,</span> <span class="n">hue</span> <span class="o">=</span> <span class="s">'Sex'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234655-16a5e300-1fa4-11eb-8d2f-74511eaa1bd6.png" /></p><ul><li>Observation<ul><li>요금이 높을수록 생존율이 높아짐</li></ul></li></ul><p><br /></p><h4 id="converting-string-values-into-numeric">Converting String Values into Numeric</h4><ul><li>Sex, Embarked, Initial 을 숫자로 변경</li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">data</span><span class="p">[</span><span class="s">'Sex'</span><span class="p">].</span><span class="n">replace</span><span class="p">([</span><span class="s">'male'</span><span class="p">,</span> <span class="s">'female'</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s">'Embarked'</span><span class="p">].</span><span class="n">replace</span><span class="p">([</span><span class="s">'S'</span><span class="p">,</span> <span class="s">'C'</span><span class="p">,</span> <span class="s">'Q'</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s">'Initial'</span><span class="p">].</span><span class="n">replace</span><span class="p">([</span><span class="s">'Mr'</span><span class="p">,</span> <span class="s">'Mrs'</span><span class="p">,</span> <span class="s">'Miss'</span><span class="p">,</span> <span class="s">'Master'</span><span class="p">,</span> <span class="s">'Other'</span><span class="p">,</span> <span class="p">],</span> <span class="p">[</span>
                        <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></table></code></div></div><p><br /></p><h4 id="dropping-unneeded-features">Dropping UnNeeded Features</h4><ul><li>Name, Age, Ticket, Fare, Cabin, Fare_Range, PassengerId</li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="n">data</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'Name'</span><span class="p">,</span><span class="s">'Age'</span><span class="p">,</span><span class="s">'Ticket'</span><span class="p">,</span><span class="s">'Fare'</span><span class="p">,</span><span class="s">'Cabin'</span><span class="p">,</span><span class="s">'Fare_Range'</span><span class="p">,</span><span class="s">'PassengerId'</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">corr</span><span class="p">(),</span> <span class="n">annot</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="s">'RdYlGn'</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">annot_kws</span><span class="o">=</span><span class="p">{</span><span class="s">'size'</span><span class="p">:</span> <span class="mi">20</span><span class="p">})</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span> <span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span> <span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234658-173e7980-1fa4-11eb-9615-9ccde8a67659.png" /></p><hr /><p><br /></p><h3 id="part3-predictive-modeling-1">Part3: Predictive Modeling</h3><ul><li>위의 EDA를 토대로 아래의 모델들에 적용시켜 보도록함<ul><li>1)Logistic Regression</li><li>2)Support Vector Machines(Linear and radial)</li><li>3)Random Forest</li><li>4)K-Nearest Neighbours</li><li>5)Naive Bayes</li><li>6)Decision Tree</li><li>7)Logistic Regression</li></ul></li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span> 
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s">'Survived'</span><span class="p">])</span>
<span class="n">train_X</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>
<span class="n">train_Y</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="p">.</span><span class="n">columns</span><span class="p">[:</span><span class="mi">1</span><span class="p">]]</span>
<span class="n">test_X</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="n">test</span><span class="p">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>
<span class="n">test_Y</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="n">test</span><span class="p">.</span><span class="n">columns</span><span class="p">[:</span><span class="mi">1</span><span class="p">]]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'Survived'</span><span class="p">]</span>
</pre></table></code></div></div><p><br /></p><h4 id="radial-support-vector-machinesrbf-svm">Radial Support Vector Machines(rbf-SVM)</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">model</span> <span class="o">=</span> <span class="n">svm</span><span class="p">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span> <span class="s">'rbf'</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="n">prediction1</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Accuracy for rbf SVM is'</span><span class="p">,</span> <span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">prediction1</span><span class="p">,</span> <span class="n">test_Y</span><span class="p">))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>Accuracy for rbf SVM is 0.835820895522388
</pre></table></code></div></div><p><br /></p><h4 id="linear-support-vector-machinelinear-svm">Linear Support Vector Machine(linear-SVM)</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">model</span> <span class="o">=</span> <span class="n">svm</span><span class="p">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">'linear'</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="n">prediction2</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Accuracy for linear SVM is'</span><span class="p">,</span> <span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">prediction2</span><span class="p">,</span> <span class="n">test_Y</span><span class="p">))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>Accuracy for linear SVM is 0.8171641791044776
</pre></table></code></div></div><p><br /></p><h4 id="logistic-regression">Logistic Regression</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span><span class="n">train_Y</span><span class="p">)</span>
<span class="n">prediction3</span><span class="o">=</span><span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The accuracy of the Logistic Regression is'</span><span class="p">,</span><span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">prediction3</span><span class="p">,</span><span class="n">test_Y</span><span class="p">))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>The accuracy of the Logistic Regression is 0.8134328358208955
</pre></table></code></div></div><p><br /></p><h4 id="decision-tree">Decision Tree</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">model</span><span class="o">=</span><span class="n">DecisionTreeClassifier</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span><span class="n">train_Y</span><span class="p">)</span>
<span class="n">prediction4</span><span class="o">=</span><span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The accuracy of the Decision Tree is'</span><span class="p">,</span><span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">prediction4</span><span class="p">,</span><span class="n">test_Y</span><span class="p">))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>The accuracy of the Decision Tree is 0.7985074626865671
</pre></table></code></div></div><p><br /></p><h4 id="k-nearest-neighboursknn">K-Nearest Neighbours(KNN)</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">model</span><span class="o">=</span><span class="n">KNeighborsClassifier</span><span class="p">()</span> 
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span><span class="n">train_Y</span><span class="p">)</span>
<span class="n">prediction5</span><span class="o">=</span><span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The accuracy of the KNN is'</span><span class="p">,</span><span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">prediction5</span><span class="p">,</span><span class="n">test_Y</span><span class="p">))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>The accuracy of the KNN is 0.832089552238806
</pre></table></code></div></div><ul><li>KNN의 경우 N을 몇개로 두냐에 따라서 accuracy가 달라진다.</li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre><td class="rouge-code"><pre><span class="n">a_index</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">))</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">11</span><span class="p">)):</span>
    <span class="n">model</span><span class="o">=</span><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">i</span><span class="p">)</span> 
    <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span><span class="n">train_Y</span><span class="p">)</span>
    <span class="n">prediction</span><span class="o">=</span><span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">test_Y</span><span class="p">)))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">a_index</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Accuracies for different values of n ar :'</span><span class="p">,</span> <span class="n">a</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="s">'with the max value as'</span><span class="p">,</span> <span class="n">a</span><span class="p">.</span><span class="n">values</span><span class="p">.</span><span class="nb">max</span><span class="p">())</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234664-186fa680-1fa4-11eb-9b78-ab9520219156.png" /></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>Accuracies for different values of n ar : [0.75746269 0.79104478 0.80970149 0.80223881 0.83208955 0.81716418
 0.82835821 0.83208955 0.8358209  0.83208955] with the max value as 0.835820895522388
</pre></table></code></div></div><p><br /></p><h4 id="gaussian-naive-bayes">Gaussian Naive Bayes</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="n">prediction6</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The accuracy of the NaiveBayes is'</span><span class="p">,</span> <span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">prediction6</span><span class="p">,</span> <span class="n">test_Y</span><span class="p">))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>The accuracy of the NaiveBayes is 0.8134328358208955
</pre></table></code></div></div><p><br /></p><h4 id="random-forests">Random Forests</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>
<span class="n">prediction7</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The accuracy of the Random Forest is'</span><span class="p">,</span> <span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">prediction7</span><span class="p">,</span> <span class="n">test_Y</span><span class="p">))</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>The accuracy of the Random Forest is 0.8134328358208955
</pre></table></code></div></div><ul><li>result<ul><li>accuracy가 절대적인것은 아니다</li><li>test accuracy가 90%는 나와야한다</li><li>지금은 90%가 나오니까 실패한것인가? 아니다 cross validation을 하면된다</li></ul></li></ul><p><br /></p><h4 id="cross-validation">Cross Validation</h4><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>- K-fold검증은 데이터를 5개로 나누고, 그중 1개만 검증에 사용하고 나머지 4개로 훈련한다
- 위의 과정을 여러번 반복하는것
- 과적합을 방지한다
- 데이터가 모자를수도 있다(5개로 나누고 1개를 검증용으로 쓰기때문)
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_predict</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre><td class="rouge-code"><pre><span class="n">kfold</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">22</span><span class="p">)</span>
<span class="n">xyz</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">std</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">classifiers</span> <span class="o">=</span> <span class="p">[</span><span class="s">'Linear Svm'</span><span class="p">,</span> <span class="s">'Radial Svm'</span><span class="p">,</span> <span class="s">'Logistic Regression'</span><span class="p">,</span>
               <span class="s">'KNN'</span><span class="p">,</span> <span class="s">'Decision Tree'</span><span class="p">,</span> <span class="s">'Naive Bayes'</span><span class="p">,</span> <span class="s">'Random Forest'</span><span class="p">]</span>
<span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="n">svm</span><span class="p">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">'linear'</span><span class="p">),</span> <span class="n">svm</span><span class="p">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">'rbf'</span><span class="p">),</span> <span class="n">LogisticRegression</span><span class="p">(</span>
<span class="p">),</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">9</span><span class="p">),</span> <span class="n">DecisionTreeClassifier</span><span class="p">(),</span> <span class="n">GaussianNB</span><span class="p">(),</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">i</span>
    <span class="n">cv_result</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="n">kfold</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span> <span class="s">'accuracy'</span><span class="p">)</span>
    <span class="n">cv_result</span> <span class="o">=</span> <span class="n">cv_result</span>
    <span class="n">xyz</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">cv_result</span><span class="p">.</span><span class="n">mean</span><span class="p">())</span>
    <span class="n">std</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">cv_result</span><span class="p">.</span><span class="n">std</span><span class="p">())</span>
    <span class="n">accuracy</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">cv_result</span><span class="p">)</span>
<span class="n">new_models_dataframe2</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">'CV Mean'</span> <span class="p">:</span> <span class="n">xyz</span><span class="p">,</span> <span class="s">'Std'</span> <span class="p">:</span> <span class="n">std</span><span class="p">},</span> <span class="n">index</span><span class="o">=</span><span class="n">classifiers</span><span class="p">)</span>
<span class="n">new_models_dataframe2</span>
</pre></table></code></div></div><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>CV Mean<th>Std<tbody><tr><th>Linear Svm<td>0.793471<td>0.047797<tr><th>Radial Svm<td>0.828290<td>0.034427<tr><th>Logistic Regression<td>0.805843<td>0.024061<tr><th>KNN<td>0.813783<td>0.041210<tr><th>Decision Tree<td>0.810362<td>0.027879<tr><th>Naive Bayes<td>0.801386<td>0.028999<tr><th>Random Forest<td>0.817066<td>0.027947</table></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">box</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">accuracy</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="n">classifiers</span><span class="p">])</span>
<span class="n">box</span><span class="p">.</span><span class="n">T</span><span class="p">.</span><span class="n">boxplot</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234666-19083d00-1fa4-11eb-80a0-419da34e320a.png" /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="n">new_models_dataframe2</span><span class="p">[</span><span class="s">'CV Mean'</span><span class="p">].</span><span class="n">plot</span><span class="p">.</span><span class="n">barh</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Average CV Mean Accuracy'</span><span class="p">)</span>
<span class="n">fig</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234667-19083d00-1fa4-11eb-894a-cf99ed064894.png" /></p><ul><li>classification accuracy는 불균형으로 인해 때때로 오도될 수 있다.</li><li>우리는 confusion matrix의 도움으로 요약된 결과를 얻을 수 있는데, 이 매트릭스는 모델이 어디에서 잘못 되었는지 또는 모델이 잘못 예측한 클래스를 보여준다.</li></ul><p><br /></p><h4 id="confusion-matrix">Confusion Matrix</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
</pre><td class="rouge-code"><pre><span class="n">f</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">svm</span><span class="p">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">'rbf'</span><span class="p">),</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">y_pred</span><span class="p">),</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span><span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">fmt</span><span class="o">=</span><span class="s">'2.0f'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Matrix for rbf-SVM'</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">svm</span><span class="p">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">'linear'</span><span class="p">),</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">y_pred</span><span class="p">),</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">fmt</span><span class="o">=</span><span class="s">'2.0f'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Matrix for Linear-SVM'</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">9</span><span class="p">),</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">y_pred</span><span class="p">),</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span><span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">fmt</span><span class="o">=</span><span class="s">'2.0f'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Matrix for KNN'</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">),</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">y_pred</span><span class="p">),</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span><span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">fmt</span><span class="o">=</span><span class="s">'2.0f'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Matrix for Random-Forests'</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">(),</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">y_pred</span><span class="p">),</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">fmt</span><span class="o">=</span><span class="s">'2.0f'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Matrix for Logistic Regression'</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">DecisionTreeClassifier</span><span class="p">(),</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">y_pred</span><span class="p">),</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span><span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">fmt</span><span class="o">=</span><span class="s">'2.0f'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Matrix for Decision Tree'</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">GaussianNB</span><span class="p">(),</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">y_pred</span><span class="p">),</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span><span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">fmt</span><span class="o">=</span><span class="s">'2.0f'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Matrix for Naive Bayes'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234669-19a0d380-1fa4-11eb-885a-8e39bb2a173d.png" /></p><ul><li>Interpreting Confusion Matrix</li><li><p>왼쪽 대각선은 각 클래스에 대해 올바른 예측의 수를 나타내고 오른쪽 대각선은 잘못된 예측의 수를 나타낸다. rbf-SVM에 대한 첫 번째 그림을 고려해 보십시오.</p></li><li><p>1)정확한 예측의 수는 491(죽은 경우) + 247(생존한 경우)이며, 평균 CV 정확도는 (491+247)/891 = 82.8%로 우리가 앞서 얻은 것이다.</p></li><li><p>2)Errors–&gt; 58명의 사망자를 생존자로 잘못 분류하고 95명은 사망자로 생존했다. 그래서 그것은 죽은 사람이 살아남을 것이라고 예측함으로써 더 많은 실수를 저질렀다.</p></li><li>모든 행렬을 보면, 우리는 rbf-SVM이 죽은 승객을 정확하게 예측할 수 있는 더 높은 가능성을 가지고 있다고 말할 수 있지만, NaiveBayes는 생존한 승객을 정확하게 예측할 수 있는 더 높은 가능성을 가지고 있다.</li></ul><p><br /></p><h4 id="hyper-parameters-tuning">Hyper-Parameters Tuning</h4><ul><li>기본 Parameter를 조정하거나 변경하여 더 나은 모델을 얻을 수 있다.</li><li>SVM 모델의 C와 감마처럼, 그리고 유사하게 다른 분류자에 대한 다른 매개변수들을 Hyper- Parameter라고 한다.</li><li>알고리즘의 학습 속도를 변경하고 더 나은 모델을 얻기 위해 튜닝할 수 있다. 이를 하이퍼 파라미터 튜닝(Hyper-Parameter Tuning이라고 한다.</li><li>SVM과 RandomForests와 같은 두 가지 최고의 분류자에 대한 하이퍼 파라미터를 조정할 것이다.</li></ul><p><br /></p><h4 id="svm">SVM</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="n">C</span><span class="o">=</span><span class="p">[</span><span class="mf">0.05</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.3</span><span class="p">,</span><span class="mf">0.25</span><span class="p">,</span><span class="mf">0.4</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.6</span><span class="p">,</span><span class="mf">0.7</span><span class="p">,</span><span class="mf">0.8</span><span class="p">,</span><span class="mf">0.9</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">gamma</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.3</span><span class="p">,</span><span class="mf">0.4</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.6</span><span class="p">,</span><span class="mf">0.7</span><span class="p">,</span><span class="mf">0.8</span><span class="p">,</span><span class="mf">0.9</span><span class="p">,</span><span class="mf">1.0</span><span class="p">]</span>
<span class="n">kernel</span><span class="o">=</span><span class="p">[</span><span class="s">'rbf'</span><span class="p">,</span><span class="s">'linear'</span><span class="p">]</span>
<span class="n">hyper</span><span class="o">=</span><span class="p">{</span><span class="s">'kernel'</span><span class="p">:</span><span class="n">kernel</span><span class="p">,</span><span class="s">'C'</span><span class="p">:</span><span class="n">C</span><span class="p">,</span><span class="s">'gamma'</span><span class="p">:</span><span class="n">gamma</span><span class="p">}</span>
<span class="n">gd</span><span class="o">=</span><span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">svm</span><span class="p">.</span><span class="n">SVC</span><span class="p">(),</span><span class="n">param_grid</span><span class="o">=</span><span class="n">hyper</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">gd</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">gd</span><span class="p">.</span><span class="n">best_score_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">gd</span><span class="p">.</span><span class="n">best_estimator_</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre><td class="rouge-code"><pre>Fitting 5 folds for each of 240 candidates, totalling 1200 fits


[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.


0.8282593685267716
SVC(C=0.4, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma=0.3, kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)


[Parallel(n_jobs=1)]: Done 1200 out of 1200 | elapsed:   13.9s finished
</pre></table></code></div></div><p><br /></p><h4 id="random-forests-1">Random Forests</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">n_estimators</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">1000</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">hyper</span><span class="o">=</span><span class="p">{</span><span class="s">'n_estimators'</span><span class="p">:</span><span class="n">n_estimators</span><span class="p">}</span>
<span class="n">gd</span><span class="o">=</span><span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span><span class="n">param_grid</span><span class="o">=</span><span class="n">hyper</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">gd</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">gd</span><span class="p">.</span><span class="n">best_score_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">gd</span><span class="p">.</span><span class="n">best_estimator_</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre><td class="rouge-code"><pre>Fitting 5 folds for each of 9 candidates, totalling 45 fits


[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   30.5s finished


0.819327098110602
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=0, verbose=0,
                       warm_start=False)
</pre></table></code></div></div><ul><li>SVM은 0.828, Random Forest는 0.819의 정확도를 가진다, Random Forest는 n_estimators = 300으로 나왔다</li></ul><p><br /></p><h4 id="ensembling">Ensembling</h4><ul><li>Ensembling은 모델의 정확성이나 성능을 높이는 좋은 방법이다. 간단히 말해서, 그것은 하나의 강력한 모델을 만들기 위한 다양한 단순한 모델들의 결합이다.</li><li><p>Ensembling은 아래와 같은 방법으로 할수 있음</p><ul><li>1)Voting Classifier</li><li>2)Bagging</li><li>3)Boosting.</li></ul></li><li>Voting Classifier<ul><li>모든 서브모듈의 예측을 바탕으로 평균 예측 결과를 제공한다</li></ul></li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">VotingClassifier</span>
<span class="n">ensemble_lin_rbf</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="p">[(</span><span class="s">'KNN'</span><span class="p">,</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">)),</span>
                                               <span class="p">(</span><span class="s">'RBF'</span><span class="p">,</span> <span class="n">svm</span><span class="p">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                                               <span class="n">kernel</span><span class="o">=</span><span class="s">'rbf'</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)),</span>
                                               <span class="p">(</span><span class="s">'RFor'</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(</span>
                                                   <span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span>
                                               <span class="p">(</span><span class="s">'LR'</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)),</span>
                                               <span class="p">(</span><span class="s">'DT'</span><span class="p">,</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span>
                                                   <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)),</span>
                                               <span class="p">(</span><span class="s">'NB'</span><span class="p">,</span> <span class="n">GaussianNB</span><span class="p">()),</span>
                                               <span class="p">(</span><span class="s">'svm'</span><span class="p">,</span> <span class="n">svm</span><span class="p">.</span><span class="n">SVC</span><span class="p">(</span>
                                                   <span class="n">kernel</span><span class="o">=</span><span class="s">'linear'</span><span class="p">,</span> <span class="n">probability</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
                                               <span class="p">],</span>
                                   <span class="n">voting</span><span class="o">=</span><span class="s">'soft'</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_Y</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'The accuracy for ensembled model is:'</span><span class="p">,</span><span class="n">ensemble_lin_rbf</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">test_X</span><span class="p">,</span><span class="n">test_Y</span><span class="p">))</span>
<span class="n">cross</span><span class="o">=</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">ensemble_lin_rbf</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span><span class="n">scoring</span> <span class="o">=</span> <span class="s">"accuracy"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The cross validated score is'</span><span class="p">,</span><span class="n">cross</span><span class="p">.</span><span class="n">mean</span><span class="p">())</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>The accuracy for ensembled model is: 0.8208955223880597
The cross validated score is 0.8249188514357053
</pre></table></code></div></div><ul><li>Bagging<ul><li>데이터 집합의 작은 파티션에 유사한 분류자를 적용한 다음 모든 예측의 평균을 취함으로써 작동한다. 평균값 때문에, 분산이 감소한다. Voting Classifier와는 달리, Bagging은 유사한 분류자를 사용한다.</li></ul></li><li>Bagged KNN<ul><li>Bagging은 분산성이 높은 모델과 함께 가장 잘 작동한다. 이에 대한 예로는 Decision Tree 또는 Random Forest가 있다. 우리는 n_neighbours의 작은 값을 가진 KNN을 n_neighbours의 작은 값으로 사용할 수 있다.</li></ul></li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingClassifier</span>
<span class="n">model</span><span class="o">=</span><span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">base_estimator</span><span class="o">=</span><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">700</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span><span class="n">train_Y</span><span class="p">)</span>
<span class="n">prediction</span><span class="o">=</span><span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The accuracy for bagged KNN is:'</span><span class="p">,</span><span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span><span class="n">test_Y</span><span class="p">))</span>
<span class="n">result</span><span class="o">=</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s">'accuracy'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The cross validated score for bagged KNN is:'</span><span class="p">,</span><span class="n">result</span><span class="p">.</span><span class="n">mean</span><span class="p">())</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>The accuracy for bagged KNN is: 0.835820895522388
The cross validated score for bagged KNN is: 0.8160424469413232
</pre></table></code></div></div><ul><li>Bagged DecisionTree</li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">model</span><span class="o">=</span><span class="n">BaggingClassifier</span><span class="p">(</span><span class="n">base_estimator</span><span class="o">=</span><span class="n">DecisionTreeClassifier</span><span class="p">(),</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span><span class="n">train_Y</span><span class="p">)</span>
<span class="n">prediction</span><span class="o">=</span><span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The accuracy for bagged Decision Tree is:'</span><span class="p">,</span><span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span><span class="n">test_Y</span><span class="p">))</span>
<span class="n">result</span><span class="o">=</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s">'accuracy'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The cross validated score for bagged Decision Tree is:'</span><span class="p">,</span><span class="n">result</span><span class="p">.</span><span class="n">mean</span><span class="p">())</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>The accuracy for bagged Decision Tree is: 0.8246268656716418
The cross validated score for bagged Decision Tree is: 0.8227590511860174
</pre></table></code></div></div><ul><li>Boosting<ul><li>Boosting 분류자의 순차적 학습을 사용하는 앙상블 기법이다. 약한 모델의 단계적 고도화다.Boosting 다음과 같이 작동한다.</li><li>모델은 먼저 완전한 데이터 집합에 대해 교육된다. 이제 그 모델은 몇몇 사례를 맞힐 것이고 몇몇은 틀릴 것이다. 이제 다음 반복에서 학습자는 잘못 예측된 사례에 더 초점을 맞추거나 더 비중 있게 다룰 것이다. 따라서 잘못된 사례를 정확하게 예측하려고 할 것이다. 이제 이 반복적인 과정은 계속되며, 정확도에 대한 한계에 도달할 때까지 모델에 새로운 분류기가 추가된다.</li></ul></li><li>AdaBoost(Adaptive Boosting)<ul><li>이 경우 학습자 또는 평가자가 약한 사람은 의사결정 나무다. 그러나 우리는 dafault base_estimator를 우리가 선택한 어떤 알고리즘으로도 바꿀 수 있다.</li></ul></li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>
<span class="n">ada</span><span class="o">=</span><span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">result</span><span class="o">=</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">ada</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s">'accuracy'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The cross validated score for AdaBoost is:'</span><span class="p">,</span><span class="n">result</span><span class="p">.</span><span class="n">mean</span><span class="p">())</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>The cross validated score for AdaBoost is: 0.8249188514357055
</pre></table></code></div></div><ul><li>Stochastic Gradient Boosting<ul><li>Here too the weak learner is a Decision Tree.</li></ul></li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>
<span class="n">grad</span><span class="o">=</span><span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">result</span><span class="o">=</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s">'accuracy'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The cross validated score for Gradient Boosting is:'</span><span class="p">,</span><span class="n">result</span><span class="p">.</span><span class="n">mean</span><span class="p">())</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>The cross validated score for Gradient Boosting is: 0.8115230961298376
</pre></table></code></div></div><ul><li>XGBoost</li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="n">xg</span>
<span class="n">xgboost</span><span class="o">=</span><span class="n">xg</span><span class="p">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">900</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">result</span><span class="o">=</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">xgboost</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s">'accuracy'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The cross validated score for XGBoost is:'</span><span class="p">,</span><span class="n">result</span><span class="p">.</span><span class="n">mean</span><span class="p">())</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>The cross validated score for XGBoost is: 0.8160299625468165
</pre></table></code></div></div><p><br /></p><h4 id="hyper-parameter-tuning-for-adaboost">Hyper-Parameter Tuning for AdaBoost</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="n">n_estimators</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">1100</span><span class="p">,</span><span class="mi">100</span><span class="p">))</span>
<span class="n">learn_rate</span><span class="o">=</span><span class="p">[</span><span class="mf">0.05</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.3</span><span class="p">,</span><span class="mf">0.25</span><span class="p">,</span><span class="mf">0.4</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.6</span><span class="p">,</span><span class="mf">0.7</span><span class="p">,</span><span class="mf">0.8</span><span class="p">,</span><span class="mf">0.9</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">hyper</span><span class="o">=</span><span class="p">{</span><span class="s">'n_estimators'</span><span class="p">:</span><span class="n">n_estimators</span><span class="p">,</span><span class="s">'learning_rate'</span><span class="p">:</span><span class="n">learn_rate</span><span class="p">}</span>
<span class="n">gd</span><span class="o">=</span><span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">AdaBoostClassifier</span><span class="p">(),</span><span class="n">param_grid</span><span class="o">=</span><span class="n">hyper</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">gd</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">gd</span><span class="p">.</span><span class="n">best_score_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">gd</span><span class="p">.</span><span class="n">best_estimator_</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre>Fitting 5 folds for each of 120 candidates, totalling 600 fits


[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.


0.8293892411022534
AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.1,
                   n_estimators=100, random_state=None)


[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed:  7.0min finished
</pre></table></code></div></div><p><br /></p><h4 id="confusion-matrix-for-the-best-model">Confusion Matrix for the Best Model</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">ada</span><span class="o">=</span><span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="n">result</span><span class="o">=</span><span class="n">cross_val_predict</span><span class="p">(</span><span class="n">ada</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">result</span><span class="p">),</span><span class="n">cmap</span><span class="o">=</span><span class="s">'winter'</span><span class="p">,</span><span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">fmt</span><span class="o">=</span><span class="s">'2.0f'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234670-19a0d380-1fa4-11eb-99ed-a605f2fee227.png" /></p><p><br /></p><h4 id="feature-importance">Feature Importance</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre><td class="rouge-code"><pre><span class="n">f</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">12</span><span class="p">))</span>
<span class="n">model</span><span class="o">=</span><span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
<span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">,</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">).</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">plot</span><span class="p">.</span><span class="n">barh</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Feature Importance in Random Forests'</span><span class="p">)</span>
<span class="n">model</span><span class="o">=</span><span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
<span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">,</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">).</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">plot</span><span class="p">.</span><span class="n">barh</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s">'#ddff11'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Feature Importance in AdaBoost'</span><span class="p">)</span>
<span class="n">model</span><span class="o">=</span><span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
<span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">,</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">).</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">plot</span><span class="p">.</span><span class="n">barh</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span><span class="n">cmap</span><span class="o">=</span><span class="s">'RdYlGn_r'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Feature Importance in Gradient Boosting'</span><span class="p">)</span>
<span class="n">model</span><span class="o">=</span><span class="n">xg</span><span class="p">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">900</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
<span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">,</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">).</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">plot</span><span class="p">.</span><span class="n">barh</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="n">color</span><span class="o">=</span><span class="s">'#FD0F00'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Feature Importance in XgBoost'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/98234671-1a396a00-1fa4-11eb-8d83-94080287ae7f.png" /></p><p><br /></p><h4 id="result">Result:</h4><ul><li><p>일반적으로 중요한 기능으로는 Initial,Par_cat,Pclass,Family_Size 등이 있다.</p></li><li>Sex 특성은 전혀 중요성을 부여하지 않는 것 같은데, 앞서 살펴본 바와 같이 Sex와 Pclass의 결합이 매우 좋은 차별화 요소를 주고 있었다는 점에서 충격적이다. 성은 랜덤 포레스트에서만 중요하게 보인다.</li><li><p>그러나, 우리는 많은 분류자에서 맨 위에 있는 Initial을 볼 수 있다.우리는 이미 성별(Sex)과 이니셜(Initial)의 긍정적인 상관관계를 보았기 때문에 둘 다 성별을 가리킨다.</p></li><li>P클래스 및 Fair_cat과 비슷하게 승객 및 Family_Size with Alone, Parch, SibSp의 상태를 말한다.</li></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/kaggle/'>Kaggle</a>, <a href='/categories/titanic/'>Titanic</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/kaggle-transcription/" class="post-tag no-text-decoration" >Kaggle Transcription</a> <a href="/tags/titanic/" class="post-tag no-text-decoration" >Titanic</a> <a href="/tags/eda/" class="post-tag no-text-decoration" >EDA</a> <a href="/tags/sklearn/" class="post-tag no-text-decoration" >Sklearn</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><!-- Post sharing snippet v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Prediction을 위한 Titanic EDA - Data Include Me&url=https://datainclude.me/posts/Prediction%EC%9D%84_%EC%9C%84%ED%95%9C_Titanic_EDA/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Prediction을 위한 Titanic EDA - Data Include Me&u=https://datainclude.me/posts/Prediction%EC%9D%84_%EC%9C%84%ED%95%9C_Titanic_EDA/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Prediction을 위한 Titanic EDA - Data Include Me&url=https://datainclude.me/posts/Prediction%EC%9D%84_%EC%9C%84%ED%95%9C_Titanic_EDA/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><!-- The Panel on right side (Desktop views) v2.3 © 2024 Your Name MIT License --><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><h3 data-toc-skip>Recent Update</h3><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li class="recent-item"> <a href="/posts/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C_%EC%BB%B4%ED%93%A8%ED%8C%85_%EA%B0%80%EC%83%81%ED%99%94/">클라우드 컴퓨팅 - 가상화</a> <span class="text-muted small">2024-10-28</span></li><li class="recent-item"> <a href="/posts/gemini_api_%EC%82%AC%EC%9A%A9%ED%95%B4%EB%B3%B4%EA%B8%B0/">Gemini API 사용해보기</a> <span class="text-muted small">2024-03-12</span></li><li class="recent-item"> <a href="/posts/Ollama%EC%99%80_Python_%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC_LLaMa2%EB%A5%BC_%EB%A1%9C%EC%BB%AC%EC%97%90%EC%84%9C_%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/">Ollama와 Python 라이브러리를 이용하여 LLaMa2를 로컬에서 사용하기</a> <span class="text-muted small">2024-02-13</span></li><li class="recent-item"> <a href="/posts/Mistral_7B_Fine_Tuning/">Mistral 7B 파인튜닝(Fine Tuning)하기</a> <span class="text-muted small">2023-10-25</span></li><li class="recent-item"> <a href="/posts/Penn_Fudan%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EA%B0%9D%EC%B2%B4_%ED%83%90%EC%A7%80_%EB%B6%84%ED%95%A0/">Penn-Fudan으로 알아보는 객체 탐지(Object Detection), 분할(Segmentation) with FasterRCNN</a> <span class="text-muted small">2023-10-23</span></li></ul></div><div id="access-tags"><h3 data-toc-skip>Trending Tags</h3><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/tensorflow/">Tensorflow</a> <a class="post-tag" href="/tags/sklearn/">Sklearn</a> <a class="post-tag" href="/tags/round/">Round</a> <a class="post-tag" href="/tags/python-lv0/">Python Lv0</a> <a class="post-tag" href="/tags/pca/">PCA</a> <a class="post-tag" href="/tags/eda/">EDA</a> <a class="post-tag" href="/tags/distinct/">Distinct</a> <a class="post-tag" href="/tags/random-forest/">Random Forest</a> <a class="post-tag" href="/tags/beautifulsoup/">Beautifulsoup</a> <a class="post-tag" href="/tags/baekjoon/">Baekjoon</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><h3 data-toc-skip class="pl-3 pt-2 mb-2">Contents</h3><nav id="toc" data-toggle="toc"></nav></div></div><style> .recent-item { margin-bottom: 0.5rem; } .recent-item a { color: var(--link-color); } .recent-item .small { font-size: 0.75rem; margin-left: 0.5rem; }</style></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"> <!-- Recommend the other 3 posts according to the tags and categories of the current post, if the number is not enough, use the other latest posts to supplement. v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/%ED%83%80%EC%9D%B4%ED%83%80%EB%8B%89_%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC_with_Kaggle/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Sep 19, 2020 <i class="unloaded">2020-09-19T20:30:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>타이타닉 튜토리얼</h3><div class="text-muted small"><p> 타이타닉 튜토리얼 만약 데이터 사이언스, 머신러닝 또는 캐글에서 어떤 것을 해야하는 지 잘 모르는 newbie 라면, 타이타닉을 하시는 게 가장 좋은 선택입니다. 타이타닉은 아시다시피, 사상 최대 해난사고로써, 1,500여명의 희생자가 생겼습니다. 우리는 이 튜토리얼에서 타이타닉에 탑승한 사람들의 신상정보를 활용하여, 승선한 사람들의 생존...</p></div></div></a></div><div class="card"> <a href="/posts/%ED%83%80%EC%9D%B4%ED%83%80%EB%8B%89_%ED%83%914_%EC%95%99%EC%83%81%EB%B8%94_%EB%AA%A8%EB%8D%B8%EB%A7%81/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Nov 5, 2020 <i class="unloaded">2020-11-05T00:30:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>타이타닉 탑4% 앙상블 모델링</h3><div class="text-muted small"><p> 1 Introduction 2 Load and check data 2.1 load data 2.2 Outlier detection 2.3 joining train and test set 2.4 check for null and missing values 3 Feature a...</p></div></div></a></div><div class="card"> <a href="/posts/Data_Preparation_and_Exploration/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Nov 9, 2020 <i class="unloaded">2020-11-09T00:30:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Porto Seguro’s Safe Driver Prediction 데이터 Preparation & Exploration</h3><div class="text-muted small"><p> 1. Porto Seguro Safe Driver Prediction 1.1 Porto Seguro Safe Driver Prediction Porto Seguro는 브라질의 자동차 보험회사로, 어떤 차주가 내년에 보험을 청구할지에 대한 예측을 하는것 https://www.kaggle.com/c/porto-seguro-safe-driver-...</p></div></div></a></div></div></div><!-- Navigation buttons at the bottom of the post. v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --><div class="post-navigation d-flex justify-content-between"> <a href="/posts/%EC%8B%A0%EA%B2%BD_%EC%8A%A4%ED%83%80%EC%9D%BC_%EC%A0%84%EC%9D%B4(Neural_Style_Transfer)/" class="btn btn-outline-primary"><p>신경 스타일 전이 (Neural Style Transfer)</p></a> <a href="/posts/%ED%83%80%EC%9D%B4%ED%83%80%EB%8B%89_%ED%83%914_%EC%95%99%EC%83%81%EB%B8%94_%EB%AA%A8%EB%8D%B8%EB%A7%81/" class="btn btn-outline-primary"><p>타이타닉 탑4% 앙상블 모델링</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('#post-wrapper img'); const observer = lozad(imgs); observer.observe(); </script></div><!-- The Search results v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/tensorflow/">Tensorflow</a> <a class="post-tag" href="/tags/sklearn/">Sklearn</a> <a class="post-tag" href="/tags/round/">Round</a> <a class="post-tag" href="/tags/python-lv0/">Python Lv0</a> <a class="post-tag" href="/tags/pca/">PCA</a> <a class="post-tag" href="/tags/eda/">EDA</a> <a class="post-tag" href="/tags/distinct/">Distinct</a> <a class="post-tag" href="/tags/random-forest/">Random Forest</a> <a class="post-tag" href="/tags/beautifulsoup/">Beautifulsoup</a> <a class="post-tag" href="/tags/baekjoon/">Baekjoon</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <!-- The GA snippet v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <!-- Jekyll Simple Search loader v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://datainclude.me{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script>
