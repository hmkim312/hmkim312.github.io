<!DOCTYPE html><html lang="ko" mode="light" > <!-- The Head v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>IBM HR Data로 해보는 퇴사자 예측 | Data Include Me</title><meta name="generator" content="Jekyll v3.9.3" /><meta property="og:title" content="IBM HR Data로 해보는 퇴사자 예측" /><meta name="author" content="HyunMin Kim" /><meta property="og:locale" content="ko" /><meta name="description" content="Predicting Employee Attrition IBM 데이터 과학자들이 만든 가상의 HR 데이터셋입니다. 1,470명에 대한 35개의 변수가 기록되어 있고, 종속변수는 Attrition, 즉 0 또는 1의 퇴사 여부입니다. Data Source: https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset" /><meta property="og:description" content="Predicting Employee Attrition IBM 데이터 과학자들이 만든 가상의 HR 데이터셋입니다. 1,470명에 대한 35개의 변수가 기록되어 있고, 종속변수는 Attrition, 즉 0 또는 1의 퇴사 여부입니다. Data Source: https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset" /><link rel="canonical" href="https://datainclude.me/posts/IBM_HR_Data%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_%ED%87%B4%EC%82%AC%EC%9E%90_%EC%98%88%EC%B8%A1/" /><meta property="og:url" content="https://datainclude.me/posts/IBM_HR_Data%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_%ED%87%B4%EC%82%AC%EC%9E%90_%EC%98%88%EC%B8%A1/" /><meta property="og:site_name" content="Data Include Me" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2021-06-02T00:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="IBM HR Data로 해보는 퇴사자 예측" /><meta name="twitter:site" content="@" /><meta name="twitter:creator" content="@HyunMin Kim" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"HyunMin Kim"},"dateModified":"2021-06-02T00:00:00+09:00","datePublished":"2021-06-02T00:00:00+09:00","description":"Predicting Employee Attrition IBM 데이터 과학자들이 만든 가상의 HR 데이터셋입니다. 1,470명에 대한 35개의 변수가 기록되어 있고, 종속변수는 Attrition, 즉 0 또는 1의 퇴사 여부입니다. Data Source: https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset","headline":"IBM HR Data로 해보는 퇴사자 예측","mainEntityOfPage":{"@type":"WebPage","@id":"https://datainclude.me/posts/IBM_HR_Data%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_%ED%87%B4%EC%82%AC%EC%9E%90_%EC%98%88%EC%B8%A1/"},"url":"https://datainclude.me/posts/IBM_HR_Data%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_%ED%87%B4%EC%82%AC%EC%9E%90_%EC%98%88%EC%B8%A1/"}</script><meta property="og:image" content="https://datainclude.me/assets/img/sample/avatar.jpg" /> <!-- The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps Generated by: https://www.favicon-generator.org/ v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT license --><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="36x36" href="/assets/img/favicons/android-icon-36x36.png"><link rel="icon" type="image/png" sizes="48x48" href="/assets/img/favicons/android-icon-48x48.png"><link rel="icon" type="image/png" sizes="72x72" href="/assets/img/favicons/android-icon-72x72.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/android-icon-96x96.png"><link rel="icon" type="image/png" sizes="144x144" href="/assets/img/favicons/android-icon-144x144.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="70x70" href="/assets/img/favicons/ms-icon-70x70.png"><link rel="icon" type="image/png" sizes="144x144" href="/assets/img/favicons/ms-icon-144x144.png"><link rel="icon" type="image/png" sizes="150x150" href="/assets/img/favicons/ms-icon-150x150.png"><link rel="icon" type="image/png" sizes="310x310" href="/assets/img/favicons/ms-icon-310x310.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preload" href="https://www.googletagmanager.com/gtm.js?id=GTM-MW9VRMW9" as="script"> <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src= 'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f); })(window,document,'script','dataLayer','GTM-MW9VRMW9');</script><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="preload" as="style" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous" media="print" onload="this.media='all'"> <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"> </noscript> <!-- CSS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --><link rel="preload" as="style" href="/assets/css/post.css"><link rel="stylesheet" href="/assets/css/post.css"><link rel="preload" as="style" href="/assets/css/lib/bootstrap-toc.min.css"><link rel="stylesheet" href="/assets/css/lib/bootstrap-toc.min.css" /><link rel="preload" as="script" href="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" async></script> <!-- JS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --> <script src="/assets/js/post.min.js" async></script> <script src="/app.js" defer></script><body data-spy="scroll" data-target="#toc"> <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MW9VRMW9" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="sidebar" class="d-flex flex-column"> <!-- The Side Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="nav-wrapper"><div id="profile-wrapper" class="d-flex flex-column"><div id="avatar" class="d-flex justify-content-center"> <a href="/" alt="avatar"> <img src="/assets/img/sample/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="profile-text mt-3"><div class="site-title"> <a href="/">Data Include Me</a></div><div class="site-subtitle font-italic">Data Science Blog</div></div></div><ul class="nav flex-column"><li class="nav-item d-flex justify-content-center "> <a href="/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/categories/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/tags/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/archives/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/about/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></li></ul></div><div class="sidebar-bottom d-flex flex-wrap justify-content-around mt-4"> <a href="https://github.com/hmkim312" target="_blank"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/" target="_blank"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:window.open('mailto:' + ['sanarial312','gmail.com'].join('@'))" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" > <i class="fas fa-rss"></i> </a></div></div><!-- The Top Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>IBM HR Data로 해보는 퇴사자 예측</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"> <!-- Refactor the HTML structure. --> <!-- Suroundding the markdown table with '<div class="table-wrapper">. and '</div>' --> <!-- Fixed kramdown code highlight rendering: https://github.com/penibelst/jekyll-compress-html/issues/101 https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901 --><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"> <script type="text/javascript"> var lazyloadads = false; function loadAds() { if (!lazyloadads) { var script = document.createElement("script"); script.type = "text/javascript"; script.async = true; script.src = "https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7594406644928408"; document.body.appendChild(script); lazyloadads = true; } } window.addEventListener("mousemove", loadAds, { once: true }); window.addEventListener('touchstart', loadAds, { once: true }); </script><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>IBM HR Data로 해보는 퇴사자 예측</h1><div class="post-meta text-muted d-flex flex-column"><div> Posted <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Wed, Jun 2, 2021, 12:00 AM +0900" > Jun 2, 2021 <i class="unloaded">2021-06-02T00:00:00+09:00</i> </span> by <span class="author"> HyunMin Kim </span></div><a href="https://hits.seeyoufarm.com"> <img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https://datainclude.me/posts/IBM_HR_Data%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_%ED%87%B4%EC%82%AC%EC%9E%90_%EC%98%88%EC%B8%A1/%2F&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=views&edge_flat=false" alt="페이지 조회수 뱃지", width: 100%;, height: 100%;/> </a></div><div class="post-content"><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120488576-e3201f80-c3f1-11eb-86a7-222f435fe4ff.png" /></p><h2 id="predicting-employee-attrition">Predicting Employee Attrition</h2><hr /><ul><li>IBM 데이터 과학자들이 만든 가상의 HR 데이터셋입니다.</li><li>1,470명에 대한 35개의 변수가 기록되어 있고, 종속변수는 <b>Attrition</b>, 즉 0 또는 1의 퇴사 여부입니다.</li><li>Data Source: <a href="https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset" target="_blank">https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset</a></li></ul><h2 id="순서">순서</h2><ol><li>패키지 import</li><li>데이터 설명 및 전처리</li><li>EDA</li><li>가설확인</li><li>Feature Engineering</li><li>예측을 위한 데이터 처리</li><li>머신러닝 알고리즘을 이용한 퇴사자 예측</li><li>이후의 방향</li></ol><h2 id="0-패키지-import">0. 패키지 import</h2><hr /><h3 id="01-필요한-패키지-import">0.1 필요한 패키지 import</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span>

<span class="c1"># Data preprocessing
</span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">LabelEncoder</span><span class="p">,</span> <span class="n">RobustScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">GridSearchCV</span><span class="p">,</span> <span class="n">learning_curve</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">precision_score</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">lightgbm</span> <span class="kn">import</span> <span class="n">LGBMClassifier</span>


<span class="c1"># 모델 import
</span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span><span class="p">,</span> <span class="n">export_graphviz</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="n">xgb</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="n">smf</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="n">sm</span>
<span class="kn">import</span> <span class="nn">graphviz</span>
<span class="kn">import</span> <span class="nn">pydotplus</span>

<span class="c1"># EDA package
</span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">missingno</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="n">mpl</span>


<span class="c1"># warnings 끄기
</span><span class="n">warnings</span><span class="p">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s">'ignore'</span><span class="p">)</span>

<span class="c1"># pandas display option view row &amp; columns
</span><span class="n">pd</span><span class="p">.</span><span class="n">set_option</span><span class="p">(</span><span class="s">'display.max_row'</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
<span class="n">pd</span><span class="p">.</span><span class="n">set_option</span><span class="p">(</span><span class="s">'display.max_columns'</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">pd</span><span class="p">.</span><span class="n">set_option</span><span class="p">(</span><span class="s">'display.max_colwidth'</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="c1"># # matplotlib set
</span><span class="n">plt</span><span class="p">.</span><span class="n">rc</span><span class="p">(</span><span class="s">'font'</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="s">'DejaVu Sans'</span><span class="p">)</span>  <span class="c1"># For MacOS
</span><span class="n">plt</span><span class="p">.</span><span class="n">rc</span><span class="p">(</span><span class="s">'axes'</span><span class="p">,</span> <span class="n">unicode_minus</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</pre></table></code></div></div><p><br /></p><h2 id="1-데이터-설명-및-전처리">1. 데이터 설명 및 전처리</h2><hr /><h3 id="11-데이터-로드-및-체크">1.1 데이터 로드 및 체크</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'WA_Fn-UseC_-HR-Employee-Attrition.csv'</span><span class="p">)</span>
<span class="n">data</span><span class="p">.</span><span class="n">tail</span><span class="p">()</span>
</pre></table></code></div></div><div style="width:100%; height:300px; overflow:auto"><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>Age<th>Attrition<th>BusinessTravel<th>DailyRate<th>Department<th>DistanceFromHome<th>Education<th>EducationField<th>EmployeeCount<th>EmployeeNumber<th>EnvironmentSatisfaction<th>Gender<th>HourlyRate<th>JobInvolvement<th>JobLevel<th>JobRole<th>JobSatisfaction<th>MaritalStatus<th>MonthlyIncome<th>MonthlyRate<th>NumCompaniesWorked<th>Over18<th>OverTime<th>PercentSalaryHike<th>PerformanceRating<th>RelationshipSatisfaction<th>StandardHours<th>StockOptionLevel<th>TotalWorkingYears<th>TrainingTimesLastYear<th>WorkLifeBalance<th>YearsAtCompany<th>YearsInCurrentRole<th>YearsSinceLastPromotion<th>YearsWithCurrManager<tbody><tr><th>1465<td>36<td>No<td>Travel_Frequently<td>884<td>Research &amp; Development<td>23<td>2<td>Medical<td>1<td>2061<td>3<td>Male<td>41<td>4<td>2<td>Laboratory Technician<td>4<td>Married<td>2571<td>12290<td>4<td>Y<td>No<td>17<td>3<td>3<td>80<td>1<td>17<td>3<td>3<td>5<td>2<td>0<td>3<tr><th>1466<td>39<td>No<td>Travel_Rarely<td>613<td>Research &amp; Development<td>6<td>1<td>Medical<td>1<td>2062<td>4<td>Male<td>42<td>2<td>3<td>Healthcare Representative<td>1<td>Married<td>9991<td>21457<td>4<td>Y<td>No<td>15<td>3<td>1<td>80<td>1<td>9<td>5<td>3<td>7<td>7<td>1<td>7<tr><th>1467<td>27<td>No<td>Travel_Rarely<td>155<td>Research &amp; Development<td>4<td>3<td>Life Sciences<td>1<td>2064<td>2<td>Male<td>87<td>4<td>2<td>Manufacturing Director<td>2<td>Married<td>6142<td>5174<td>1<td>Y<td>Yes<td>20<td>4<td>2<td>80<td>1<td>6<td>0<td>3<td>6<td>2<td>0<td>3<tr><th>1468<td>49<td>No<td>Travel_Frequently<td>1023<td>Sales<td>2<td>3<td>Medical<td>1<td>2065<td>4<td>Male<td>63<td>2<td>2<td>Sales Executive<td>2<td>Married<td>5390<td>13243<td>2<td>Y<td>No<td>14<td>3<td>4<td>80<td>0<td>17<td>3<td>2<td>9<td>6<td>0<td>8<tr><th>1469<td>34<td>No<td>Travel_Rarely<td>628<td>Research &amp; Development<td>8<td>3<td>Medical<td>1<td>2068<td>2<td>Male<td>82<td>4<td>2<td>Laboratory Technician<td>3<td>Married<td>4404<td>10228<td>2<td>Y<td>No<td>12<td>3<td>1<td>80<td>0<td>6<td>3<td>4<td>4<td>3<td>1<td>2</table></div><ol><li>Age : 해당 직원의 나이</li><li>Attrition : 퇴직 여부 Target값 (종속변수)</li><li>BusinessTravel : 출장의 빈도</li><li>DailyRate : 일 대비 급여의 수준</li><li>Department : 업무분야</li><li>DistanceFromHome : 집과의 거리</li><li>Education : 교육의 정도<ul><li>1 : ‘Below College’ : 대학 이하</li><li>2 : ‘College’ : 전문대</li><li>3 : ‘Bachelor’ : 학사</li><li>4 : ‘Master’ : 석사</li><li>5 : ‘Doctor’ : 박사</li></ul></li><li>EducationField : 전공</li><li>EmployeeCount : 직원 숫자</li><li>EmployeeNumber : 직원 ID</li><li>EnvironmentSatisfaction : 업무 환경에 대한 만족도<ul><li>1 : ‘Low’</li><li>2 : ‘Medium’</li><li>3 : ‘High’</li><li>4 : ‘Very High’</li></ul></li><li>Gender : 성별</li><li>HourlyRate : 시간 대비 급여의 수준</li><li>JobInvolvement : 업무 참여도<ul><li>1 : ‘Low’</li><li>2 : ‘Medium’</li><li>3 : ‘High’</li><li>4 : ‘Very High’</li></ul></li><li>JobLevel : 업무의 수준</li><li>JobRole : 업무 종류</li><li>JobSatisfaction : 업무 만족도<ul><li>1 : ‘Low’</li><li>2 : ‘Medium’</li><li>3 : ‘High’</li><li>4 : ‘Very High’</li></ul></li><li>MaritalStatus : 결혼 여부</li><li>MonthlyIncome : 월 소득</li><li>MonthlyRate : 월 대비 급여 수준</li><li>NumCompaniesWorked : 일한 회사의 수</li><li>Over18 : 18세 이상</li><li>OverTime : 규정외 노동시간</li><li>PercentSalaryHike : 급여의 증가분 백분율</li><li>PerformanceRating : 업무 성과<ul><li>1 : ‘Low’</li><li>2 : ‘Good’</li><li>3 : ‘Excellent’</li><li>4 : ‘Outstanding’</li></ul></li><li>RelationshipSatisfaction : 대인관계 만족도<ul><li>1 : ‘Low’</li><li>2 : ‘Medium’</li><li>3 : ‘High’</li><li>4 : ‘Very High’</li></ul></li><li>StandardHours : 표준 시간</li><li>StockOptionLevel : 스톡옵션 정도</li><li>TotalWorkingYears : 경력 기간</li><li>TrainingTimesLastYear : 교육 시간</li><li>WorkLifeBalance : 일과 생활의 균형 정도<ul><li>1 : ‘Bad’</li><li>2 : ‘Good’</li><li>3 : ‘Better’</li><li>4 : ‘Best’</li></ul></li><li>YearsAtCompany : 근속 연수</li><li>YearsInCurrentRole : 현재 역할의 년수</li><li>YearsSinceLastPromotion : 마지막 프로모션</li><li>YearsWithCurrManager : 현재 관리자와 함께 보낸 시간</li></ol><ul><li>총 독립변수 : 34개, 종속변수 1개 확인 됩니다.</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">data</span><span class="p">.</span><span class="n">info</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
</pre><td class="rouge-code"><pre>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 1470 entries, 0 to 1469
Data columns (total 35 columns):
 #   Column                    Non-Null Count  Dtype 
---  ------                    --------------  ----- 
 0   Age                       1470 non-null   int64 
 1   Attrition                 1470 non-null   object
 2   BusinessTravel            1470 non-null   object
 3   DailyRate                 1470 non-null   int64 
 4   Department                1470 non-null   object
 5   DistanceFromHome          1470 non-null   int64 
 6   Education                 1470 non-null   int64 
 7   EducationField            1470 non-null   object
 8   EmployeeCount             1470 non-null   int64 
 9   EmployeeNumber            1470 non-null   int64 
 10  EnvironmentSatisfaction   1470 non-null   int64 
 11  Gender                    1470 non-null   object
 12  HourlyRate                1470 non-null   int64 
 13  JobInvolvement            1470 non-null   int64 
 14  JobLevel                  1470 non-null   int64 
 15  JobRole                   1470 non-null   object
 16  JobSatisfaction           1470 non-null   int64 
 17  MaritalStatus             1470 non-null   object
 18  MonthlyIncome             1470 non-null   int64 
 19  MonthlyRate               1470 non-null   int64 
 20  NumCompaniesWorked        1470 non-null   int64 
 21  Over18                    1470 non-null   object
 22  OverTime                  1470 non-null   object
 23  PercentSalaryHike         1470 non-null   int64 
 24  PerformanceRating         1470 non-null   int64 
 25  RelationshipSatisfaction  1470 non-null   int64 
 26  StandardHours             1470 non-null   int64 
 27  StockOptionLevel          1470 non-null   int64 
 28  TotalWorkingYears         1470 non-null   int64 
 29  TrainingTimesLastYear     1470 non-null   int64 
 30  WorkLifeBalance           1470 non-null   int64 
 31  YearsAtCompany            1470 non-null   int64 
 32  YearsInCurrentRole        1470 non-null   int64 
 33  YearsSinceLastPromotion   1470 non-null   int64 
 34  YearsWithCurrManager      1470 non-null   int64 
dtypes: int64(26), object(9)
memory usage: 402.1+ KB
</pre></table></code></div></div><ul><li>Education, EnvironmentSatisfaction, JobInvolvement, JobSatisfaction, PerformanceRating, RelationshipSatisfaction, WorkLifeBalance, JobLevel, StockOptionLevel, NumCompaniesWorked</li><li>위의 컬럼들이 실제론 Category column인데, int형으로 되어있습니다.</li><li>int형 컬럼들을 Category 컬럼으로 바꿔주어야 EDA 할때 조금더 편합니다. &lt;int형 26개, category형 9개&gt;</li></ul><p><br /></p><h3 id="12-eda를-쉽게하기-위해-데이터값을-object로-변경">1.2 EDA를 쉽게하기 위해 데이터값을 Object로 변경</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="c1"># Education
</span><span class="n">change_dict</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="s">'Below College'</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s">'College'</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="s">'Bachelor'</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="s">'Master'</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span> <span class="s">'Doctor'</span><span class="p">}</span>
<span class="n">data</span><span class="p">.</span><span class="n">replace</span><span class="p">({</span><span class="s">'Education'</span><span class="p">:</span> <span class="n">change_dict</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s">'Education'</span><span class="p">].</span><span class="n">unique</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>array(['College', 'Below College', 'Master', 'Bachelor', 'Doctor'],
      dtype=object)
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="c1"># EnvironmentSatisfaction
</span><span class="n">change_dict</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="s">'Low'</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s">'Medium'</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="s">'High'</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="s">'Very High'</span><span class="p">}</span>
<span class="n">data</span><span class="p">.</span><span class="n">replace</span><span class="p">({</span><span class="s">'EnvironmentSatisfaction'</span><span class="p">:</span> <span class="n">change_dict</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s">'EnvironmentSatisfaction'</span><span class="p">].</span><span class="n">unique</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>array(['Medium', 'High', 'Very High', 'Low'], dtype=object)
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="c1"># JobInvolvement
</span><span class="n">change_dict</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="s">'Low'</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s">'Medium'</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="s">'High'</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="s">'Very High'</span><span class="p">}</span>
<span class="n">data</span><span class="p">.</span><span class="n">replace</span><span class="p">({</span><span class="s">'JobInvolvement'</span><span class="p">:</span> <span class="n">change_dict</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s">'JobInvolvement'</span><span class="p">].</span><span class="n">unique</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>array(['High', 'Medium', 'Very High', 'Low'], dtype=object)
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="c1"># JobSatisfaction
</span><span class="n">change_dict</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="s">'Low'</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s">'Medium'</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="s">'High'</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="s">'Very High'</span><span class="p">}</span>
<span class="n">data</span><span class="p">.</span><span class="n">replace</span><span class="p">({</span><span class="s">'JobSatisfaction'</span><span class="p">:</span> <span class="n">change_dict</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s">'JobSatisfaction'</span><span class="p">].</span><span class="n">unique</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>array(['Very High', 'Medium', 'High', 'Low'], dtype=object)
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="c1"># PerformanceRating
</span><span class="n">change_dict</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="s">'Low'</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s">'Good'</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="s">'Excellent'</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="s">'Outstanding'</span><span class="p">}</span>
<span class="n">data</span><span class="p">.</span><span class="n">replace</span><span class="p">({</span><span class="s">'PerformanceRating'</span><span class="p">:</span> <span class="n">change_dict</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s">'PerformanceRating'</span><span class="p">].</span><span class="n">unique</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>array(['Excellent', 'Outstanding'], dtype=object)
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="c1"># RelationshipSatisfaction
</span><span class="n">change_dict</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="s">'Low'</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s">'Medium'</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="s">'High'</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="s">'Very High'</span><span class="p">}</span>
<span class="n">data</span><span class="p">.</span><span class="n">replace</span><span class="p">({</span><span class="s">'RelationshipSatisfaction'</span><span class="p">:</span> <span class="n">change_dict</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s">'RelationshipSatisfaction'</span><span class="p">].</span><span class="n">unique</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>array(['Low', 'Very High', 'Medium', 'High'], dtype=object)
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="c1"># WorkLifeBalance
</span><span class="n">change_dict</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="s">'Bad'</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s">'Good'</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="s">'Better'</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="s">'Best'</span><span class="p">}</span>
<span class="n">data</span><span class="p">.</span><span class="n">replace</span><span class="p">({</span><span class="s">'WorkLifeBalance'</span><span class="p">:</span> <span class="n">change_dict</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s">'WorkLifeBalance'</span><span class="p">].</span><span class="n">unique</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>array(['Bad', 'Better', 'Good', 'Best'], dtype=object)
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="c1"># JobLevel, StockOptionLevel, TrainingTimesLastYear, NumCompaniesWorked, TotalWorkingYears
</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">astype</span><span class="p">({</span><span class="s">'JobLevel'</span><span class="p">:</span> <span class="nb">object</span><span class="p">,</span> <span class="s">'StockOptionLevel'</span><span class="p">:</span> <span class="nb">object</span><span class="p">,</span> <span class="s">'NumCompaniesWorked'</span><span class="p">:</span> <span class="nb">object</span><span class="p">})</span>
<span class="n">data</span>
</pre></table></code></div></div><div style="width:100%; height:300px; overflow:auto"><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>Age<th>Attrition<th>BusinessTravel<th>DailyRate<th>Department<th>DistanceFromHome<th>Education<th>EducationField<th>EmployeeCount<th>EmployeeNumber<th>EnvironmentSatisfaction<th>Gender<th>HourlyRate<th>JobInvolvement<th>JobLevel<th>JobRole<th>JobSatisfaction<th>MaritalStatus<th>MonthlyIncome<th>MonthlyRate<th>NumCompaniesWorked<th>Over18<th>OverTime<th>PercentSalaryHike<th>PerformanceRating<th>RelationshipSatisfaction<th>StandardHours<th>StockOptionLevel<th>TotalWorkingYears<th>TrainingTimesLastYear<th>WorkLifeBalance<th>YearsAtCompany<th>YearsInCurrentRole<th>YearsSinceLastPromotion<th>YearsWithCurrManager<tbody><tr><th>0<td>41<td>Yes<td>Travel_Rarely<td>1102<td>Sales<td>1<td>College<td>Life Sciences<td>1<td>1<td>Medium<td>Female<td>94<td>High<td>2<td>Sales Executive<td>Very High<td>Single<td>5993<td>19479<td>8<td>Y<td>Yes<td>11<td>Excellent<td>Low<td>80<td>0<td>8<td>0<td>Bad<td>6<td>4<td>0<td>5<tr><th>1<td>49<td>No<td>Travel_Frequently<td>279<td>Research &amp; Development<td>8<td>Below College<td>Life Sciences<td>1<td>2<td>High<td>Male<td>61<td>Medium<td>2<td>Research Scientist<td>Medium<td>Married<td>5130<td>24907<td>1<td>Y<td>No<td>23<td>Outstanding<td>Very High<td>80<td>1<td>10<td>3<td>Better<td>10<td>7<td>1<td>7<tr><th>2<td>37<td>Yes<td>Travel_Rarely<td>1373<td>Research &amp; Development<td>2<td>College<td>Other<td>1<td>4<td>Very High<td>Male<td>92<td>Medium<td>1<td>Laboratory Technician<td>High<td>Single<td>2090<td>2396<td>6<td>Y<td>Yes<td>15<td>Excellent<td>Medium<td>80<td>0<td>7<td>3<td>Better<td>0<td>0<td>0<td>0<tr><th>3<td>33<td>No<td>Travel_Frequently<td>1392<td>Research &amp; Development<td>3<td>Master<td>Life Sciences<td>1<td>5<td>Very High<td>Female<td>56<td>High<td>1<td>Research Scientist<td>High<td>Married<td>2909<td>23159<td>1<td>Y<td>Yes<td>11<td>Excellent<td>High<td>80<td>0<td>8<td>3<td>Better<td>8<td>7<td>3<td>0<tr><th>4<td>27<td>No<td>Travel_Rarely<td>591<td>Research &amp; Development<td>2<td>Below College<td>Medical<td>1<td>7<td>Low<td>Male<td>40<td>High<td>1<td>Laboratory Technician<td>Medium<td>Married<td>3468<td>16632<td>9<td>Y<td>No<td>12<td>Excellent<td>Very High<td>80<td>1<td>6<td>3<td>Better<td>2<td>2<td>2<td>2<tr><th>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<tr><th>1465<td>36<td>No<td>Travel_Frequently<td>884<td>Research &amp; Development<td>23<td>College<td>Medical<td>1<td>2061<td>High<td>Male<td>41<td>Very High<td>2<td>Laboratory Technician<td>Very High<td>Married<td>2571<td>12290<td>4<td>Y<td>No<td>17<td>Excellent<td>High<td>80<td>1<td>17<td>3<td>Better<td>5<td>2<td>0<td>3<tr><th>1466<td>39<td>No<td>Travel_Rarely<td>613<td>Research &amp; Development<td>6<td>Below College<td>Medical<td>1<td>2062<td>Very High<td>Male<td>42<td>Medium<td>3<td>Healthcare Representative<td>Low<td>Married<td>9991<td>21457<td>4<td>Y<td>No<td>15<td>Excellent<td>Low<td>80<td>1<td>9<td>5<td>Better<td>7<td>7<td>1<td>7<tr><th>1467<td>27<td>No<td>Travel_Rarely<td>155<td>Research &amp; Development<td>4<td>Bachelor<td>Life Sciences<td>1<td>2064<td>Medium<td>Male<td>87<td>Very High<td>2<td>Manufacturing Director<td>Medium<td>Married<td>6142<td>5174<td>1<td>Y<td>Yes<td>20<td>Outstanding<td>Medium<td>80<td>1<td>6<td>0<td>Better<td>6<td>2<td>0<td>3<tr><th>1468<td>49<td>No<td>Travel_Frequently<td>1023<td>Sales<td>2<td>Bachelor<td>Medical<td>1<td>2065<td>Very High<td>Male<td>63<td>Medium<td>2<td>Sales Executive<td>Medium<td>Married<td>5390<td>13243<td>2<td>Y<td>No<td>14<td>Excellent<td>Very High<td>80<td>0<td>17<td>3<td>Good<td>9<td>6<td>0<td>8<tr><th>1469<td>34<td>No<td>Travel_Rarely<td>628<td>Research &amp; Development<td>8<td>Bachelor<td>Medical<td>1<td>2068<td>Medium<td>Male<td>82<td>Very High<td>2<td>Laboratory Technician<td>High<td>Married<td>4404<td>10228<td>2<td>Y<td>No<td>12<td>Excellent<td>Low<td>80<td>0<td>6<td>3<td>Best<td>4<td>3<td>1<td>2</table><p>1470 rows × 35 columns</p></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">data</span><span class="p">.</span><span class="n">info</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
</pre><td class="rouge-code"><pre>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 1470 entries, 0 to 1469
Data columns (total 35 columns):
 #   Column                    Non-Null Count  Dtype 
---  ------                    --------------  ----- 
 0   Age                       1470 non-null   int64 
 1   Attrition                 1470 non-null   object
 2   BusinessTravel            1470 non-null   object
 3   DailyRate                 1470 non-null   int64 
 4   Department                1470 non-null   object
 5   DistanceFromHome          1470 non-null   int64 
 6   Education                 1470 non-null   object
 7   EducationField            1470 non-null   object
 8   EmployeeCount             1470 non-null   int64 
 9   EmployeeNumber            1470 non-null   int64 
 10  EnvironmentSatisfaction   1470 non-null   object
 11  Gender                    1470 non-null   object
 12  HourlyRate                1470 non-null   int64 
 13  JobInvolvement            1470 non-null   object
 14  JobLevel                  1470 non-null   object
 15  JobRole                   1470 non-null   object
 16  JobSatisfaction           1470 non-null   object
 17  MaritalStatus             1470 non-null   object
 18  MonthlyIncome             1470 non-null   int64 
 19  MonthlyRate               1470 non-null   int64 
 20  NumCompaniesWorked        1470 non-null   object
 21  Over18                    1470 non-null   object
 22  OverTime                  1470 non-null   object
 23  PercentSalaryHike         1470 non-null   int64 
 24  PerformanceRating         1470 non-null   object
 25  RelationshipSatisfaction  1470 non-null   object
 26  StandardHours             1470 non-null   int64 
 27  StockOptionLevel          1470 non-null   object
 28  TotalWorkingYears         1470 non-null   int64 
 29  TrainingTimesLastYear     1470 non-null   int64 
 30  WorkLifeBalance           1470 non-null   object
 31  YearsAtCompany            1470 non-null   int64 
 32  YearsInCurrentRole        1470 non-null   int64 
 33  YearsSinceLastPromotion   1470 non-null   int64 
 34  YearsWithCurrManager      1470 non-null   int64 
dtypes: int64(16), object(19)
memory usage: 402.1+ KB
</pre></table></code></div></div><ul><li>EDA 과정을 하기 위해 Category Columns는 object 형식으로 변환함</li><li>&lt;int형 16개, Category형 19개&gt;</li></ul><p><br /></p><h3 id="13-결측치-확인">1.3 결측치 확인</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">missingno</span><span class="p">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120488671-f92de000-c3f1-11eb-9b1d-f555b5fc4e23.png" /></p><ul><li>Missingno 패키지를 통해 Null 데이터가 있는지 시각화 해보았습니다.</li><li>총 1470 데이터 중에 Null 데이터는 없는것으로 확인됩니다.</li><li>만일 있다면 중간값, 삭제, 평균 값 등으로 채워주거나 혹은 해당 데이터 행 자체를 삭제 해야합니다.</li><li>만일 Null data를 임의적으로 0혹은 999와 같이 일괄적인 값으로 채워넣었다면 여기서 확인은 어렵습니다.</li></ul><p><br /></p><h2 id="2-eda">2. EDA</h2><hr /><h3 id="21-가설-설정---누가-퇴사를-할것인가">2.1 가설 설정 - 누가 퇴사를 할것인가?</h3><ul><li>일단 퇴사를 할것 같은 사람들 간단한 도메인 지식을 활용하여 가설설정하였음.</li><li>가설1 : 집과 회사의 거리가 먼 사람들이 퇴사를 많이 할것이다.</li><li>가설2 : 월급여가 낮은 사람이 퇴사를 많이 할것이다.</li><li>가설3 : 업무환경이 안좋은 사람이 퇴사를 할것이다.</li><li>가설4 : 워라벨이 안좋은 사람들이 퇴사를 할것이다.</li><li>가설5 : 근무부서에 따른 퇴사의 비율이 다를것이다. 즉, 특정부서가 퇴사율이 높을것이다.</li><li>가설6 : 초기 경력자들이 퇴직을 많이 할것이다.</li></ul><p><br /></p><h3 id="22-target-확인">2.2 Target 확인</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="k">print</span><span class="p">(</span><span class="s">'Attrition 비율'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">data</span><span class="p">.</span><span class="n">Attrition</span><span class="p">.</span><span class="n">value_counts</span><span class="p">().</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s"> : </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">Attrition</span><span class="p">.</span><span class="n">value_counts</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="si">}</span><span class="s">%'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">data</span><span class="p">.</span><span class="n">Attrition</span><span class="p">.</span><span class="n">value_counts</span><span class="p">().</span><span class="n">index</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s"> : </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">Attrition</span><span class="p">.</span><span class="n">value_counts</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="si">}</span><span class="s">%'</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>Attrition 비율
No : 84.0%
Yes : 16.0%
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'Attrition'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Attrition의 분포'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120488695-fc28d080-c3f1-11eb-9937-1fbfb0572e7f.png" /></p><ul><li>퇴사자의 분포는 전체 데이터의 약 16%를 차지하는것을 알수 있었습니다.</li></ul><p><br /></p><h3 id="23-전체-컬럼-분포-확인">2.3 전체 컬럼 분포 확인</h3><h4 id="231-카테고리형-컬럼">2.3.1 카테고리형 컬럼</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="c1"># category column
</span><span class="n">cate_cols</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">data</span><span class="p">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">data</span><span class="p">[</span><span class="n">column</span><span class="p">].</span><span class="n">dtype</span> <span class="o">==</span> <span class="nb">object</span><span class="p">:</span>
        <span class="n">cate_cols</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">column</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'============================================================================================='</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">column</span><span class="si">}</span><span class="s"> : </span><span class="si">{</span><span class="n">data</span><span class="p">[</span><span class="n">column</span><span class="p">].</span><span class="n">unique</span><span class="p">()</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">data</span><span class="p">[</span><span class="n">column</span><span class="p">].</span><span class="n">value_counts</span><span class="p">()</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
        <span class="k">print</span><span class="p">()</span>
        
<span class="k">print</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'object column의 갯수 : </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">cate_cols</span><span class="p">)</span><span class="si">}</span><span class="s"> 개'</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
</pre><td class="rouge-code"><pre>=============================================================================================
Attrition : ['Yes' 'No']
No     1233
Yes     237
Name: Attrition, dtype: int64

=============================================================================================
BusinessTravel : ['Travel_Rarely' 'Travel_Frequently' 'Non-Travel']
Travel_Rarely        1043
Travel_Frequently     277
Non-Travel            150
Name: BusinessTravel, dtype: int64

=============================================================================================
Department : ['Sales' 'Research &amp; Development' 'Human Resources']
Research &amp; Development    961
Sales                     446
Human Resources            63
Name: Department, dtype: int64

=============================================================================================
Education : ['College' 'Below College' 'Master' 'Bachelor' 'Doctor']
Bachelor         572
Master           398
College          282
Below College    170
Doctor            48
Name: Education, dtype: int64

=============================================================================================
EducationField : ['Life Sciences' 'Other' 'Medical' 'Marketing' 'Technical Degree'
 'Human Resources']
Life Sciences       606
Medical             464
Marketing           159
Technical Degree    132
Other                82
Human Resources      27
Name: EducationField, dtype: int64

=============================================================================================
EnvironmentSatisfaction : ['Medium' 'High' 'Very High' 'Low']
High         453
Very High    446
Medium       287
Low          284
Name: EnvironmentSatisfaction, dtype: int64

=============================================================================================
Gender : ['Female' 'Male']
Male      882
Female    588
Name: Gender, dtype: int64

=============================================================================================
JobInvolvement : ['High' 'Medium' 'Very High' 'Low']
High         868
Medium       375
Very High    144
Low           83
Name: JobInvolvement, dtype: int64

=============================================================================================
JobLevel : [2 1 3 4 5]
1    543
2    534
3    218
4    106
5     69
Name: JobLevel, dtype: int64

=============================================================================================
JobRole : ['Sales Executive' 'Research Scientist' 'Laboratory Technician'
 'Manufacturing Director' 'Healthcare Representative' 'Manager'
 'Sales Representative' 'Research Director' 'Human Resources']
Sales Executive              326
Research Scientist           292
Laboratory Technician        259
Manufacturing Director       145
Healthcare Representative    131
Manager                      102
Sales Representative          83
Research Director             80
Human Resources               52
Name: JobRole, dtype: int64

=============================================================================================
JobSatisfaction : ['Very High' 'Medium' 'High' 'Low']
Very High    459
High         442
Low          289
Medium       280
Name: JobSatisfaction, dtype: int64

=============================================================================================
MaritalStatus : ['Single' 'Married' 'Divorced']
Married     673
Single      470
Divorced    327
Name: MaritalStatus, dtype: int64

=============================================================================================
NumCompaniesWorked : [8 1 6 9 0 4 5 2 7 3]
1    521
0    197
3    159
2    146
4    139
7     74
6     70
5     63
9     52
8     49
Name: NumCompaniesWorked, dtype: int64

=============================================================================================
Over18 : ['Y']
Y    1470
Name: Over18, dtype: int64

=============================================================================================
OverTime : ['Yes' 'No']
No     1054
Yes     416
Name: OverTime, dtype: int64

=============================================================================================
PerformanceRating : ['Excellent' 'Outstanding']
Excellent      1244
Outstanding     226
Name: PerformanceRating, dtype: int64

=============================================================================================
RelationshipSatisfaction : ['Low' 'Very High' 'Medium' 'High']
High         459
Very High    432
Medium       303
Low          276
Name: RelationshipSatisfaction, dtype: int64

=============================================================================================
StockOptionLevel : [0 1 3 2]
0    631
1    596
2    158
3     85
Name: StockOptionLevel, dtype: int64

=============================================================================================
WorkLifeBalance : ['Bad' 'Better' 'Good' 'Best']
Better    893
Good      344
Best      153
Bad        80
Name: WorkLifeBalance, dtype: int64


object column의 갯수 : 19 개
</pre></table></code></div></div><ul><li>총 19개의 Category형 컬럼의 값들을 확인해 보았습니다.</li><li>그중 Over18 컬럼이 Y값 하나만을 가지고 있을것을 알수 있었으며, 그 외 다른 컬럼은 큰 이상이 없어 보입니다.</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre><td class="rouge-code"><pre><span class="c1"># category column 그래프로 보기
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">constrained_layout</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s">'Attrition과 Category Column들의 분포'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cate_cols</span><span class="p">)):</span>
    <span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">cate_cols</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
                      <span class="n">hue</span><span class="o">=</span><span class="s">'Attrition'</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]).</span><span class="nb">set</span><span class="p">(</span><span class="n">xlabel</span> <span class="o">=</span> <span class="bp">None</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nb">set</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="n">cate_cols</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    
    <span class="k">if</span> <span class="n">data</span><span class="p">[</span><span class="n">cate_cols</span><span class="p">[</span><span class="mi">1</span><span class="p">]].</span><span class="n">nunique</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="mi">3</span><span class="p">:</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">tick_params</span><span class="p">(</span><span class="n">labelrotation</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
        
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120488699-fd59fd80-c3f1-11eb-91ef-746950683fbf.png" /></p><ul><li>요약 데이터를 그래프로 시각화 해보았습니다.</li><li>Department(근무부서) : 근무부서에 따라 퇴사 여부가 달라짐이 보입니다. 일단 눈으로 볼땐 HR부서가 가장 적어보이지만, 모수가 적기 때문에 자세히 확인해볼 필요가 있습니다.</li><li>EnvironmentSatisfaction(근무환경 만족도) : 근무환경 만족도에 따라서 퇴사 여부가 확인될듯 싶었는데, 아래에서 자세히 확인해봐야할듯 싶습니다.</li><li>JobSatisfaction(직업 만족도) : 직업 만족에 따른 퇴사 여부도 확인해 보아야겠습니다.</li><li>StockOptionLevel(스톡옵션 레벨) : 스톡옵션이 없거나 낮은 직원이 많이 떠나는것으로 보입니다. 확인해볼 필요가 있어 보입니다.</li><li>WorkLifeBalance(워라벨의 정도) : 워라벨이 중요한 사람들은 퇴사를 많이하는지 확인이 필요합니다. 만일 그렇다면 해당 회사는 워라벨이 좋지 않은 회사 인듯 합니다.</li></ul><p><br /></p><h4 id="232-연속형-컬럼-확인">2.3.2 연속형 컬럼 확인</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="c1"># continuous column
</span><span class="n">cont_cols</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">data</span><span class="p">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">data</span><span class="p">[</span><span class="n">column</span><span class="p">].</span><span class="n">dtype</span> <span class="o">!=</span> <span class="nb">object</span><span class="p">:</span>
        <span class="n">cont_cols</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">column</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'</span><span class="si">{</span><span class="n">column</span><span class="si">}</span><span class="s"> : </span><span class="si">{</span><span class="n">data</span><span class="p">[</span><span class="n">column</span><span class="p">].</span><span class="n">nunique</span><span class="p">()</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'=============================='</span><span class="p">)</span>
<span class="k">print</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'연속형 column의 갯수 : </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">cont_cols</span><span class="p">)</span><span class="si">}</span><span class="s"> 개'</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
</pre><td class="rouge-code"><pre>Age : 43
==============================
DailyRate : 886
==============================
DistanceFromHome : 29
==============================
EmployeeCount : 1
==============================
EmployeeNumber : 1470
==============================
HourlyRate : 71
==============================
MonthlyIncome : 1349
==============================
MonthlyRate : 1427
==============================
PercentSalaryHike : 15
==============================
StandardHours : 1
==============================
TotalWorkingYears : 40
==============================
TrainingTimesLastYear : 7
==============================
YearsAtCompany : 37
==============================
YearsInCurrentRole : 19
==============================
YearsSinceLastPromotion : 16
==============================
YearsWithCurrManager : 18
==============================

연속형 column의 갯수 : 16 개
</pre></table></code></div></div><ul><li>int형 컬럼을 요약해보니, EmployeeCount, StandardHours는 값이 1개로 되어 있어서, 삭제가 필요합니다.</li><li>EmployeeNumber는 값이 1470개로 모든 Row마다 값이 유니크함으로, 삭제가 필요합니다.</li><li>눈으로 쉽게 보기 위해 그래프로 그려보겠습니다.</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">14</span><span class="p">),</span> <span class="n">constrained_layout</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s">'Attrition과 continuous Column들의 분포'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cont_cols</span><span class="p">)):</span>
    <span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s">'Attrition'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'Yes'</span><span class="p">][</span><span class="n">cont_cols</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span> <span class="n">color</span><span class="o">=</span><span class="s">'Red'</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">hist</span> <span class="o">=</span> <span class="bp">False</span><span class="p">).</span><span class="nb">set</span><span class="p">(</span><span class="n">xlabel</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">ylabel</span> <span class="o">=</span> <span class="bp">None</span><span class="p">)</span>
    <span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s">'Attrition'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'No'</span><span class="p">][</span><span class="n">cont_cols</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="n">hist</span> <span class="o">=</span> <span class="bp">False</span><span class="p">).</span><span class="nb">set</span><span class="p">(</span><span class="n">xlabel</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">ylabel</span> <span class="o">=</span> <span class="bp">None</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nb">set</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="n">cont_cols</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120488715-ff23c100-c3f1-11eb-8853-403544469150.png" /></p><ul><li>밀도 그래프를 그려보았습니다. 빨간색은 퇴사한 사람들에 대한 그래프이고 파란색은 반대입니다.</li><li>밀도 그래프만으로는 부족해보여 박스그래프도 그려보겠습니다.</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="c1"># boxplot
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">14</span><span class="p">),</span> <span class="n">constrained_layout</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s">'Boxplot of Attrition'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cont_cols</span><span class="p">)):</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nb">set</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="n">cont_cols</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">data</span><span class="p">[</span><span class="s">'Attrition'</span><span class="p">],</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">cont_cols</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]).</span><span class="nb">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>  <span class="n">ylabel</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
    
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120488723-0054ee00-c3f2-11eb-9d7c-26e9e203cb1f.png" /></p><ul><li>int형 컬럼에 대해 밀도 그래프와 박스 그래프를 그려보니 이상한 컬럼이 눈에 확실히 띕니다.(위에서 이야기했던 3가지 컬럼)</li><li>Age (나이) : 나이가 어릴때 퇴사를 많이하는것으로 보입니다.</li><li>MonthlyIncome (월수입) : 월 급여가 적으면 퇴사합니다. 많아도 퇴사를 하는 극단치가 보입니다.</li><li>DistanceFromHome (집과 회사의 거리) : 집과 거리가 멀면 퇴사를 하는 경향이 보입니다.</li><li>YearsInCurrentRole (현재 역할의 연수) : 장기간 같은 역할을 할때 그대로 있고, 초창기에 퇴직을 많이 합니다. 이는 승진을 하고 퇴사를 한다는 이야기 같습니다.</li><li>PercentSalaryHike (연봉 상승률) : 연봉 상승률이 낮은 사람은들은 그렇지 않은 사람들에 비해 더 많이 퇴사하는것으로 봉비니다.</li><li>YearsWithCurrManager (현재 관리자와 같이 일한 연도) : 관리자와 오래일하면 퇴직하진 않지만 중간에 퇴사하는 사람이 들쭉날쭉합니다. 진짜 관리자 때문에 퇴사를 하는 것일지 궁금합니다.</li><li>TotalWorkingYears (총 경력) : 경력이 짧을때 퇴사를 많이 합니다. 경력이 많은 사람들이 퇴사를 하는것으로 보이는데, 아마 정년퇴임이 아닐까 싶긴 합니다.</li></ul><p><br /></p><h3 id="24-컬럼-삭제">2.4 컬럼 삭제</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="c1"># EmployeeCount, StandardHours, Over18, EmployeeNumber 
</span><span class="k">print</span><span class="p">(</span><span class="s">'Over18 :'</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s">'Over18'</span><span class="p">].</span><span class="n">unique</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'EmployeeCount :'</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s">'EmployeeCount'</span><span class="p">].</span><span class="n">unique</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'StandardHours :'</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s">'StandardHours'</span><span class="p">].</span><span class="n">unique</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">'EmployeeNumber :'</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s">'EmployeeNumber'</span><span class="p">].</span><span class="n">unique</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">data</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'EmployeeCount'</span><span class="p">,</span> <span class="s">'StandardHours'</span><span class="p">,</span> <span class="s">'Over18'</span><span class="p">,</span> <span class="s">'EmployeeNumber'</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">data</span><span class="p">.</span><span class="n">tail</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>Over18 : Y
EmployeeCount : 1
StandardHours : 80
EmployeeNumber : 1
(1470, 31)
</pre></table></code></div></div><div style="width:100%; height:300px; overflow:auto"><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>Age<th>Attrition<th>BusinessTravel<th>DailyRate<th>Department<th>DistanceFromHome<th>Education<th>EducationField<th>EnvironmentSatisfaction<th>Gender<th>HourlyRate<th>JobInvolvement<th>JobLevel<th>JobRole<th>JobSatisfaction<th>MaritalStatus<th>MonthlyIncome<th>MonthlyRate<th>NumCompaniesWorked<th>OverTime<th>PercentSalaryHike<th>PerformanceRating<th>RelationshipSatisfaction<th>StockOptionLevel<th>TotalWorkingYears<th>TrainingTimesLastYear<th>WorkLifeBalance<th>YearsAtCompany<th>YearsInCurrentRole<th>YearsSinceLastPromotion<th>YearsWithCurrManager<tbody><tr><th>1465<td>36<td>No<td>Travel_Frequently<td>884<td>Research &amp; Development<td>23<td>College<td>Medical<td>High<td>Male<td>41<td>Very High<td>2<td>Laboratory Technician<td>Very High<td>Married<td>2571<td>12290<td>4<td>No<td>17<td>Excellent<td>High<td>1<td>17<td>3<td>Better<td>5<td>2<td>0<td>3<tr><th>1466<td>39<td>No<td>Travel_Rarely<td>613<td>Research &amp; Development<td>6<td>Below College<td>Medical<td>Very High<td>Male<td>42<td>Medium<td>3<td>Healthcare Representative<td>Low<td>Married<td>9991<td>21457<td>4<td>No<td>15<td>Excellent<td>Low<td>1<td>9<td>5<td>Better<td>7<td>7<td>1<td>7<tr><th>1467<td>27<td>No<td>Travel_Rarely<td>155<td>Research &amp; Development<td>4<td>Bachelor<td>Life Sciences<td>Medium<td>Male<td>87<td>Very High<td>2<td>Manufacturing Director<td>Medium<td>Married<td>6142<td>5174<td>1<td>Yes<td>20<td>Outstanding<td>Medium<td>1<td>6<td>0<td>Better<td>6<td>2<td>0<td>3<tr><th>1468<td>49<td>No<td>Travel_Frequently<td>1023<td>Sales<td>2<td>Bachelor<td>Medical<td>Very High<td>Male<td>63<td>Medium<td>2<td>Sales Executive<td>Medium<td>Married<td>5390<td>13243<td>2<td>No<td>14<td>Excellent<td>Very High<td>0<td>17<td>3<td>Good<td>9<td>6<td>0<td>8<tr><th>1469<td>34<td>No<td>Travel_Rarely<td>628<td>Research &amp; Development<td>8<td>Bachelor<td>Medical<td>Medium<td>Male<td>82<td>Very High<td>2<td>Laboratory Technician<td>High<td>Married<td>4404<td>10228<td>2<td>No<td>12<td>Excellent<td>Low<td>0<td>6<td>3<td>Best<td>4<td>3<td>1<td>2</table></div><ul><li>EmployeeCount와 EmployeeNumber는 1, StandardHours는 80, Over18은 Y로 각각 하나의 값만 가지므로 분석 및 예측에 필요 없기에 삭제하였습니다.</li></ul><p><br /></p><h3 id="25-상관관계">2.5 상관관계</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="c1"># 상관계수 구하기
</span><span class="n">data_cp</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">data_cp</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data_cp</span><span class="p">,</span> <span class="n">drop_first</span><span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">data_cp</span> <span class="o">=</span> <span class="n">data_cp</span><span class="p">[[</span><span class="s">'Attrition_Yes'</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">data_cp</span><span class="p">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">column</span> <span class="o">!=</span> <span class="s">'Attrition_Yes'</span><span class="p">]]</span>
<span class="n">data_corr</span> <span class="o">=</span> <span class="n">data_cp</span><span class="p">.</span><span class="n">corr</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">data_corr</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>(71, 71)
</pre></table></code></div></div><h4 id="251-상관계수-히트맵으로-확인">2.5.1 상관계수 히트맵으로 확인</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">18</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Corr Heatmap'</span><span class="p">)</span>

<span class="c1"># 실제 히트맵 그리는 코드
</span><span class="n">sns</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.2</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">data_corr</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">annot_kws</span><span class="o">=</span><span class="p">{</span>
    <span class="s">"size"</span><span class="p">:</span> <span class="mi">90</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data_corr</span><span class="p">))},</span> <span class="n">fmt</span><span class="o">=</span><span class="s">'.2f'</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'RdYlBu_r'</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">'corrmap.png'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120488724-00ed8480-c3f2-11eb-95bb-0e1412b67b95.png" /></p><ul><li>변수가 너무많아서 상관계수를 히트맵으로 표현해도 잘 볼수가 없습니다.</li><li>물론 볼수는 있지만, 이럴땐 다른 방법으로 확인해야겠습니다.</li></ul><p><br /></p><h4 id="252-상관관계가-있는것들만-따로-보기">2.5.2 상관관계가 있는것들만 따로 보기</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="n">temps</span> <span class="o">=</span> <span class="n">data_corr</span><span class="p">[(</span><span class="n">data_corr</span> <span class="o">&gt;</span> <span class="mf">0.4</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">data_corr</span> <span class="o">&lt;</span> <span class="o">-</span><span class="mf">0.4</span><span class="p">)]</span>
<span class="n">high_corr</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">temps</span><span class="p">.</span><span class="n">columns</span><span class="p">:</span> 
    <span class="n">temp</span> <span class="o">=</span> <span class="n">temps</span><span class="p">[</span><span class="n">c</span><span class="p">].</span><span class="n">dropna</span><span class="p">()</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">continue</span>
    <span class="n">high_corr</span><span class="p">.</span><span class="n">append</span><span class="p">([</span><span class="n">temp</span><span class="p">.</span><span class="n">name</span><span class="p">,</span> <span class="n">temp</span><span class="p">.</span><span class="n">to_dict</span><span class="p">()])</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre><td class="rouge-code"><pre><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">36</span><span class="p">),</span> <span class="n">constrained_layout</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s">'Corr'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">high_corr</span><span class="p">):</span>
    <span class="n">ordered_d</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">high_corr</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span><span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
    <span class="n">title</span> <span class="o">=</span> <span class="n">ordered_d</span><span class="p">.</span><span class="n">popitem</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">ordered_d</span><span class="p">.</span><span class="n">keys</span><span class="p">()),</span> <span class="n">y</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">ordered_d</span><span class="p">.</span><span class="n">values</span><span class="p">()),</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="nb">set</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="n">title</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ordered_d</span><span class="p">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">tick_params</span><span class="p">(</span><span class="n">labelrotation</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">'corrbar.png'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120488732-034fde80-c3f2-11eb-93a6-6332d40d6aca.png" /></p><ul><li>월급여, 경력, 업무의 수준, 관리자, 나이에 상관계수가 높았습니다., 아무래도 경력이 쌓이고, 관리자의 직급, 어려운 업무일수록 급여를 많이주는것으로 파악됩니다.</li><li>만일 퇴사의 여부가 월 급여와 관련이 있다면 경력, 업무의 수준, 나이 등이 급여와 상관관계가 있으므로 같이 보아야 할듯 합니다.</li></ul><p><br /></p><h4 id="253-종속변수와의-상관관계">2.5.3 종속변수와의 상관관계</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="c1"># 잘안보여서 일단 종속변수 상관관계만 확인
</span><span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Attrition of Corr'</span><span class="p">)</span>
<span class="n">data_cp</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'Attrition_Yes'</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">).</span><span class="n">corrwith</span><span class="p">(</span><span class="n">data_cp</span><span class="p">.</span><span class="n">Attrition_Yes</span><span class="p">).</span><span class="n">sort_values</span><span class="p">().</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'barh'</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">24</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120488736-04810b80-c3f2-11eb-84e8-1854bcf1e697.png" /></p><ul><li>위에서 확인해보았던 히트맵에서는 종속변수는 다른 독립변수들과 비교하여 강한 상관관계를 가지는 변수는 없었습니다.</li><li>그래서 따로 확인을 해보았는데, 약하게 나마 OverTime, TotalWorkingYea, MonthlyIncome과 관계가 있어 보입니다.</li></ul><p><br /></p><h4 id="254-vif-확인">2.5.4 VIF 확인</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">statsmodels.stats.outliers_influence</span> <span class="kn">import</span> <span class="n">variance_inflation_factor</span>
<span class="c1"># 피처마다의 VIF 계수를 출력합니다.
</span><span class="n">vif</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">vif</span><span class="p">[</span><span class="s">"VIF Factor"</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">variance_inflation_factor</span><span class="p">(</span><span class="n">data_corr</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data_corr</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
<span class="n">vif</span><span class="p">[</span><span class="s">"features"</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_corr</span><span class="p">.</span><span class="n">columns</span>
<span class="n">vif</span><span class="p">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s">'VIF Factor'</span><span class="p">,</span> <span class="n">ascending</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
</pre></table></code></div></div><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>VIF Factor<th>features<tbody><tr><th>17<td>13640.716455<td>Department_Sales<tr><th>16<td>13522.448575<td>Department_Research &amp; Development<tr><th>22<td>3238.702786<td>EducationField_Life Sciences<tr><th>5<td>3212.315104<td>MonthlyIncome<tr><th>24<td>2882.516493<td>EducationField_Medical<tr><th>23<td>1749.979398<td>EducationField_Marketing<tr><th>44<td>1229.895130<td>JobRole_Sales Executive<tr><th>26<td>816.753726<td>EducationField_Technical Degree<tr><th>37<td>740.090127<td>JobLevel_5<tr><th>36<td>721.256599<td>JobLevel_4<tr><th>38<td>580.597267<td>JobRole_Human Resources<tr><th>25<td>503.944369<td>EducationField_Other<tr><th>35<td>344.522261<td>JobLevel_3<tr><th>45<td>249.398879<td>JobRole_Sales Representative<tr><th>8<td>235.109044<td>TotalWorkingYears<tr><th>40<td>196.264859<td>JobRole_Manager<tr><th>34<td>162.649949<td>JobLevel_2<tr><th>10<td>161.956363<td>YearsAtCompany<tr><th>43<td>107.302581<td>JobRole_Research Scientist<tr><th>39<td>91.089185<td>JobRole_Laboratory Technician<tr><th>69<td>88.607126<td>WorkLifeBalance_Better<tr><th>50<td>73.095522<td>MaritalStatus_Single<tr><th>70<td>65.434059<td>WorkLifeBalance_Good<tr><th>42<td>53.287587<td>JobRole_Research Director<tr><th>11<td>40.420495<td>YearsInCurrentRole<tr><th>65<td>38.927425<td>StockOptionLevel_1<tr><th>13<td>37.935563<td>YearsWithCurrManager<tr><th>68<td>29.813928<td>WorkLifeBalance_Best<tr><th>51<td>21.270629<td>NumCompaniesWorked_1<tr><th>1<td>20.328417<td>Age<tr><th>7<td>19.126971<td>PercentSalaryHike<tr><th>61<td>18.554877<td>PerformanceRating_Outstanding<tr><th>41<td>16.536042<td>JobRole_Manufacturing Director<tr><th>15<td>15.969357<td>BusinessTravel_Travel_Rarely<tr><th>14<td>15.703952<td>BusinessTravel_Travel_Frequently<tr><th>53<td>14.656369<td>NumCompaniesWorked_3<tr><th>66<td>14.637033<td>StockOptionLevel_2<tr><th>52<td>12.851189<td>NumCompaniesWorked_2<tr><th>49<td>12.089123<td>MaritalStatus_Married<tr><th>54<td>12.066410<td>NumCompaniesWorked_4<tr><th>12<td>10.986051<td>YearsSinceLastPromotion<tr><th>67<td>8.399376<td>StockOptionLevel_3<tr><th>56<td>6.210026<td>NumCompaniesWorked_6<tr><th>57<td>6.093062<td>NumCompaniesWorked_7<tr><th>55<td>5.382364<td>NumCompaniesWorked_5<tr><th>59<td>4.785775<td>NumCompaniesWorked_9<tr><th>0<td>4.706463<td>Attrition_Yes<tr><th>58<td>4.495559<td>NumCompaniesWorked_8<tr><th>48<td>3.975349<td>JobSatisfaction_Very High<tr><th>64<td>3.799682<td>RelationshipSatisfaction_Very High<tr><th>21<td>3.694006<td>Education_Master<tr><th>29<td>3.634595<td>EnvironmentSatisfaction_Very High<tr><th>62<td>3.628168<td>RelationshipSatisfaction_Low<tr><th>46<td>3.556749<td>JobSatisfaction_Low<tr><th>27<td>3.444139<td>EnvironmentSatisfaction_Low<tr><th>47<td>3.402401<td>JobSatisfaction_Medium<tr><th>28<td>3.310664<td>EnvironmentSatisfaction_Medium<tr><th>63<td>3.220096<td>RelationshipSatisfaction_Medium<tr><th>19<td>3.059469<td>Education_College<tr><th>18<td>2.625621<td>Education_Below College<tr><th>60<td>1.823511<td>OverTime_Yes<tr><th>31<td>1.796165<td>JobInvolvement_Low<tr><th>33<td>1.726490<td>JobInvolvement_Very High<tr><th>20<td>1.706147<td>Education_Doctor<tr><th>32<td>1.687609<td>JobInvolvement_Medium<tr><th>3<td>1.580221<td>DistanceFromHome<tr><th>2<td>1.447858<td>DailyRate<tr><th>6<td>1.379119<td>MonthlyRate<tr><th>4<td>1.349891<td>HourlyRate<tr><th>30<td>1.328611<td>Gender_Male<tr><th>9<td>1.318633<td>TrainingTimesLastYear</table></div><ul><li>다중공선성(vif) : 통계학의 회귀분석에서 독립변수들 간에 강한 상관관계가 나타나는 문제입니다.</li><li>보통은 10 미만이면 다중공선성이 없다고 하는데, HR 데이터에는 상당히 높은 특성들이 많습니다.</li><li>일단, vif가 13000으로 너무 높은 Department 컬럼은 제외시키겠습니다.</li><li>물론 vif가 높다고 다 드랍 시킬순 없으니(Department 제외, 압도적으로 높음), 어떤 특성을 드랍시켜야하는지는 후에 고민을 해봐야 할듯하다.</li></ul><h2 id="3-가설-확인">3. 가설 확인</h2><hr /><h3 id="31-가설">3.1 가설</h3><ul><li>가설1) 집과 회사의 거리가 먼 사람들이 퇴사를 많이 할것이다.</li><li>가설2) 월급여가 낮은 사람이 퇴사를 많이 할것이다.</li><li>가설3) 업무환경이 안좋은 사람이 퇴사를 할것이다.</li><li>가설4) 워라벨이 안좋은 사람들이 퇴사를 할것이다.</li><li>가설5) 근무부서에 따른 퇴사의 비율이 다를것이다. 즉, 특정부서가 퇴사율이 높을것이다.</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="c1"># 비율 확인할 pivot 테이블 만드는 함수
</span><span class="k">def</span> <span class="nf">make_pivot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">func</span><span class="p">):</span>
    <span class="n">table</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">pivot_table</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">,</span> <span class="n">values</span> <span class="o">=</span> <span class="s">'Age'</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">aggfunc</span><span class="o">=</span><span class="n">func</span><span class="p">)</span>
    <span class="n">table</span><span class="p">[</span><span class="s">'total'</span><span class="p">]</span> <span class="o">=</span> <span class="n">table</span><span class="p">[</span><span class="s">'No'</span><span class="p">]</span> <span class="o">+</span> <span class="n">table</span><span class="p">[</span><span class="s">'Yes'</span><span class="p">]</span>
    <span class="n">table</span><span class="p">[</span><span class="s">'Attrition_rate'</span><span class="p">]</span> <span class="o">=</span> <span class="n">table</span><span class="p">[</span><span class="s">'Yes'</span><span class="p">]</span> <span class="o">/</span> <span class="n">table</span><span class="p">[</span><span class="s">'total'</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span>
    <span class="k">return</span> <span class="n">table</span>
</pre></table></code></div></div><h3 id="32-가설1-집과-회사의-거리가-먼-사람들이-퇴사를-많이-할것이다">3.2 가설1) 집과 회사의 거리가 먼 사람들이 퇴사를 많이 할것이다.</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="n">rate</span> <span class="o">=</span> <span class="n">make_pivot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s">'DistanceFromHome'</span><span class="p">,</span> <span class="s">'Attrition'</span><span class="p">,</span> <span class="n">func</span><span class="o">=</span><span class="nb">len</span><span class="p">)</span>

<span class="c1"># plt.rc('font', family='AppleGothic') 
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'DistanceFromHome'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">rate</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">rate</span><span class="p">.</span><span class="n">Attrition_rate</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120488742-05b23880-c3f2-11eb-9eff-3d9768e84453.png" /></p><ul><li>확실히 집에서 먼 사람이 집에서 가까운 사람들보다 많이 퇴사를 합니다.</li><li>가장 높은 비율인 거리 24는 전체 28명중에, 12 퇴사하여 비율로는 42.8%이고 전체 퇴사인원의 5%를 차지합니다.</li><li>전체 퇴사인원중에서 집과의 거리가 가까운 사람의 비율이 제일 많지만, 사실 집과의 거리가 가까운 인원의 비율이 전체 비율에서 제일 많아서 그렇습니다.</li></ul><p><br /></p><h4 id="321-거리가-먼-사람-컬럼-추가">3.2.1 거리가 먼 사람 컬럼 추가</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="nb">round</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">.</span><span class="n">DistanceFromHome</span> <span class="o">&gt;=</span> <span class="mi">22</span><span class="p">][</span><span class="s">'DistanceFromHome'</span><span class="p">].</span><span class="n">count</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>0.13
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">data</span><span class="p">[</span><span class="s">'FarFromHome'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">DistanceFromHome</span> <span class="o">&gt;=</span> <span class="mi">22</span> <span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s">'FarFromHome'</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'FarFromHome'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="nb">object</span><span class="p">)</span>
</pre></table></code></div></div><ul><li>그래프 상에서 거리가 멀어서 퇴사비율이 많아보이는 22부터 집과 거리가 먼 컬럼을 새로 생성하고, 나중을 위해 type을 object로 변경</li></ul><p><br /></p><h3 id="33-가설2-월급여가-낮은-사람이-퇴사를-많이-할것이다">3.3 가설2) 월급여가 낮은 사람이 퇴사를 많이 할것이다.</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'월급여에 따른 퇴사율'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s">'Attrition'</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s">'MonthlyIncome'</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120488745-06e36580-c3f2-11eb-9b10-c28c135cc9e3.png" /></p><ul><li>박스그래프를 보면 월급여가 낮은 사람들이 퇴사가 있는것으로 보입니다.</li><li>또한 퇴사를 하지 않은 사람들의 중앙값이 퇴사를 한 사람들보다 위에 위치하고, 박스의 크기가 더 큰것으로 보아 분포도 넓은것으로 보입니다.</li><li>이는 월급여가 퇴사에 영향을 준다고 볼수 있다.</li></ul><p><br /></p><h4 id="331-월급여가-낮은-사람-추가">3.3.1 월급여가 낮은 사람 추가</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s">'Attrition'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'Yes'</span><span class="p">][</span><span class="s">'MonthlyIncome'</span><span class="p">].</span><span class="n">median</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>3202.0
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">data</span><span class="p">[</span><span class="s">'LowMonthlyIncome'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">MonthlyIncome</span> <span class="o">&lt;=</span> <span class="mi">3202</span> <span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s">'LowMonthlyIncome'</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'LowMonthlyIncome'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="nb">object</span><span class="p">)</span>
</pre></table></code></div></div><ul><li>박스그래프상에 퇴사한 사람들의 급여의 중앙값을 기준으로 작은 급여를 책성하여 0,1로 나누었습니다.</li><li>또한 추후 처리를 쉽게하기 위해 object형식으로바꿔주었습니다.</li></ul><h3 id="34-가설3-업무환경이-안좋은-사람이-퇴사를-할것이다">3.4 가설3) 업무환경이 안좋은 사람이 퇴사를 할것이다.</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">rate</span> <span class="o">=</span> <span class="n">make_pivot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s">'JobInvolvement'</span><span class="p">,</span> <span class="s">'Attrition'</span><span class="p">,</span> <span class="n">func</span><span class="o">=</span><span class="nb">len</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'업무 환경에 따른 퇴사인원 비율'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">rate</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">rate</span><span class="p">.</span><span class="n">Attrition_rate</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="p">[</span><span class="s">'Low'</span><span class="p">,</span> <span class="s">'Medium'</span><span class="p">,</span> <span class="s">'High'</span><span class="p">,</span> <span class="s">'Very High'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120488747-06e36580-c3f2-11eb-87d4-165796faafbb.png" /></p><ul><li>업무환경이 Low인 사람들은 총 83명이었고, 그 중 28명이 퇴사를 하였습니다. Low 인원의 비율로는 33%로 가장 높은 비율을 차지 합니다.</li><li>따라서 업무환경이 낮은 사람들이 더 많이 퇴사를 하는것으로 알수 있습니다.</li><li>Onehot Encoding을하면 자동으로 Low, Medium, High, Very High는 구별되기에 따로 컬럼을 만들진 않았습니다.</li></ul><p><br /></p><h3 id="35-가설4-워라벨이-안좋은-사람들이-퇴사를-할것이다">3.5 가설4) 워라벨이 안좋은 사람들이 퇴사를 할것이다.</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">rate</span> <span class="o">=</span> <span class="n">make_pivot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s">'WorkLifeBalance'</span><span class="p">,</span> <span class="s">'Attrition'</span><span class="p">,</span> <span class="n">func</span><span class="o">=</span> <span class="nb">len</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'워라벨 정도에 따른 퇴사 인원 비율'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">rate</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">rate</span><span class="p">.</span><span class="n">Attrition_rate</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="p">[</span><span class="s">'Bad'</span><span class="p">,</span> <span class="s">'Good'</span><span class="p">,</span> <span class="s">'Better'</span><span class="p">,</span> <span class="s">'Best'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120488750-077bfc00-c3f2-11eb-9e7e-10f16755955f.png" /></p><ul><li>워라벨이 Bad인 인원은 80명이고 그 중에 퇴사한 인원은 25명으로 총 비율로는 31%로 가장 높은 퇴사 비율을 보입니다.</li><li>의외인것은 Best인 인원도 꽤 많은 퇴사율을 보인다는 것입니다.</li><li>일단, 워라벨이 Bad인 사람들의 다른 사람들에 비해 퇴사율이 높습니다.</li></ul><p><br /></p><h3 id="36-가설5-근무부서에-따른-퇴사의-비율이-다를것이다-즉-특정부서가-퇴사율이-높을것이다">3.6 가설5) 근무부서에 따른 퇴사의 비율이 다를것이다. 즉, 특정부서가 퇴사율이 높을것이다.</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="n">rate</span> <span class="o">=</span> <span class="n">make_pivot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s">'Department'</span><span class="p">,</span> <span class="s">'Attrition'</span><span class="p">,</span> <span class="n">func</span><span class="o">=</span> <span class="nb">len</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>

<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">'Department'</span><span class="p">],</span> <span class="n">hue</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'Attrition'</span><span class="p">],</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">order</span> <span class="o">=</span> <span class="p">[</span><span class="s">'Sales'</span><span class="p">,</span> <span class="s">'Human Resources'</span><span class="p">,</span> <span class="s">'Research &amp; Development'</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nb">set</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="s">'Attrition of Department'</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">rate</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">rate</span><span class="p">.</span><span class="n">Attrition_rate</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">order</span> <span class="o">=</span> <span class="p">[</span><span class="s">'Sales'</span><span class="p">,</span> <span class="s">'Human Resources'</span><span class="p">,</span> <span class="s">'Research &amp; Development'</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nb">set</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="s">'Attrition of Department rate'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120488755-08149280-c3f2-11eb-8e8e-a0737244de35.png" /></p><ul><li>근무부서가 HR인곳은 전체 인력도 많지 않은데, 퇴사자가 생각보다 많음을 알수 있다, HR에 근무하는 인원 대비 약 18%정도가 퇴사를 하였습니다.</li><li>그렇다면 근무부서별로 월수입의 차이가 나서 HR 부서에서 퇴사 인력이 많은것 일까?</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'MonthlyIncome of Department'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'Department'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'MonthlyIncome'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120488758-08ad2900-c3f2-11eb-8050-2a115eb7ba5e.png" /></p><ul><li>근무 부서별로 월 수입이 차이가 많이 나는지 확인을 해보았으나 (HR이 가장 낮을까?) 사실살 Sales를 제외하고는 나머지 2부서는 큰 차이가 없어 보입니다.</li><li>또한 가장 많은 월소득 구간은 세개의 부서는 큰 차이가 없는것으로 보입니다.</li><li>전체적으로 Sale의 급여가 조금 더 높게 형성되어 있음을 알수 있습니다.</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">temp</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'Department'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">).</span><span class="n">agg</span><span class="p">([</span><span class="s">'min'</span><span class="p">,</span> <span class="s">'median'</span><span class="p">,</span> <span class="s">'mean'</span><span class="p">,</span> <span class="s">'max'</span><span class="p">,</span> <span class="s">'std'</span><span class="p">])[</span><span class="s">'MonthlyIncome'</span><span class="p">]</span>
<span class="n">temp</span>
</pre></table></code></div></div><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>min<th>median<th>mean<th>max<th>std<tr><th>Department<th><th><th><th><th><tbody><tr><th>Human Resources<td>1555<td>3886.0<td>6654.507937<td>19717<td>5788.732921<tr><th>Research &amp; Development<td>1009<td>4374.0<td>6281.252862<td>19999<td>4895.835087<tr><th>Sales<td>1052<td>5754.5<td>6959.172646<td>19847<td>4058.739322</table></div><ul><li>혹시 몰라 부서별 월수입에 대한 간단한 통계요약치를 보았습니다.</li><li>위에 박스그래프에서 적은 내용과 큰 차이는 없습니다.</li></ul><p><br /></p><h3 id="37-가설6-초기-경력자들이-퇴직을-많이-할것이다">3.7 가설6) 초기 경력자들이 퇴직을 많이 할것이다.</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">rate</span> <span class="o">=</span> <span class="n">make_pivot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s">'TotalWorkingYears'</span><span class="p">,</span> <span class="s">'Attrition'</span><span class="p">,</span> <span class="n">func</span><span class="o">=</span> <span class="nb">len</span><span class="p">).</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Attrition of TotalWorkingYears rate'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">(</span><span class="n">rate</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">rate</span><span class="p">.</span><span class="n">Attrition_rate</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120488764-09de5600-c3f2-11eb-81e7-fa8aa485bd4a.png" /></p><ul><li>예상대로 초기 경력자 (0년 ~ 2년사이)의 인원이 가장 많은 퇴직율을 보였습니다.</li><li>아마 처음 경력을 쌓고 다른곳으로 이직을 하기 위해 퇴사를 하는것이 아닐까 생각해 보았습니다.</li></ul><p><br /></p><h4 id="371-초기경력자-컬럼-생성">3.7.1 초기경력자 컬럼 생성</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">data</span><span class="p">[</span><span class="s">'LowWorkingYears'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">TotalWorkingYears</span> <span class="o">&lt;=</span> <span class="mi">2</span> <span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s">'LowWorkingYears'</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'LowWorkingYears'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="nb">object</span><span class="p">)</span>
</pre></table></code></div></div><h3 id="38-가설확인-결론">3.8 가설확인 결론</h3><ul><li>가설1) 집과 회사의 거리가 먼 사람들이 퇴사를 많이 할것이다. - 맞음 -&gt; 해당 컬럼 생성</li><li>가설2) 월급여가 낮은 사람이 퇴사를 많이 할것이다. - 맞음 -&gt; 해당 컬럼 생성</li><li>가설3) 업무환경이 안좋은 사람은 퇴사를 할것이다. - 맞음</li><li>가설4) 워라벨이 안좋은 사람들이 퇴사를 할것이다. - 맞음, 하지만 워라벨이 좋아도 퇴사를 함</li><li>가설5) 근무부서에 따른 퇴사의 비율이 다를것이다. 즉, 특정부서가 퇴사율이 높을것이다. - 틀림</li><li>가설6) 초기 경력자들이 퇴직을 많이 할것이다. - 맞음 -&gt; 해당 컬럼 생성</li></ul><p><br /></p><h2 id="4-feature-engineering">4. Feature Engineering</h2><hr /><h3 id="41-age">4.1 Age</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Age histogram'</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s">'Age'</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span> <span class="o">=</span> <span class="s">'hist'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120488766-0b0f8300-c3f2-11eb-8b25-0ab0eb3d8f0c.png" /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="c1"># [(17.958, 26.4] : 0,  (26.4, 34.8] : 1, (34.8, 43.2] : 2, (43.2, 51.6] : 3,  (51.6, 60.0] : 4]
# (미포함, 포함) 임
</span><span class="n">data</span><span class="p">[</span><span class="s">'Age_cut'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">cut</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">'Age'</span><span class="p">],</span> <span class="mi">5</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]).</span><span class="n">astype</span><span class="p">(</span><span class="nb">object</span><span class="p">)</span>
</pre></table></code></div></div><ul><li>나이는 연속적이긴하지만, 5개 구간으로 나누는 컬럼을 생성하였습니다. 이후 나이 컬럼은 삭제합니다.</li></ul><h3 id="42-numcompaniesworked">4.2 NumCompaniesWorked</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">NumCompaniesWorked</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120489386-8d984280-c3f2-11eb-8c19-b6ce6c282cdd.png" /></p><ul><li>일한 회사의 수가 0인게 이상합니다. 일한 회사의 수가 없을수가 없으니까요</li><li>만약 전체 일한 회사의수가 현재 IBM을 제외시킨거라면 이해는 갑니다.</li><li>그렇다면 일한 회사의 수가 0인 사람들은 총 경력기간과 회사의 근속년수가 같아야 합니다.</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">data</span><span class="p">[(</span><span class="n">data</span><span class="p">.</span><span class="n">NumCompaniesWorked</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">TotalWorkingYears</span> <span class="o">==</span> <span class="n">data</span><span class="p">.</span><span class="n">YearsAtCompany</span><span class="p">)][[</span><span class="s">'NumCompaniesWorked'</span><span class="p">,</span><span class="s">'TotalWorkingYears'</span><span class="p">,</span><span class="s">'YearsAtCompany'</span><span class="p">]]</span>
</pre></table></code></div></div><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>NumCompaniesWorked<th>TotalWorkingYears<th>YearsAtCompany<tbody></table></div><ul><li>일한 회사의 수가 0개인 사람들 중 전체 경력과 근속년수가 같은 인원은 한명도 없습니다.</li><li>데이터의 오류인지 더 확인해봐야겠습니다.</li><li>이번엔 일한 회사가 0개인 사람들 중에 경력과 근속년수가 다른 사람들을 확인하겠습니다.</li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="k">print</span><span class="p">(</span><span class="n">data</span><span class="p">[(</span><span class="n">data</span><span class="p">.</span><span class="n">NumCompaniesWorked</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">TotalWorkingYears</span> <span class="o">!=</span> <span class="n">data</span><span class="p">.</span><span class="n">YearsAtCompany</span><span class="p">)][[</span><span class="s">'NumCompaniesWorked'</span><span class="p">,</span><span class="s">'TotalWorkingYears'</span><span class="p">,</span><span class="s">'YearsAtCompany'</span><span class="p">]].</span><span class="n">shape</span><span class="p">)</span>
<span class="n">data</span><span class="p">[(</span><span class="n">data</span><span class="p">.</span><span class="n">NumCompaniesWorked</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">TotalWorkingYears</span> <span class="o">!=</span> <span class="n">data</span><span class="p">.</span><span class="n">YearsAtCompany</span><span class="p">)][[</span><span class="s">'NumCompaniesWorked'</span><span class="p">,</span><span class="s">'TotalWorkingYears'</span><span class="p">,</span><span class="s">'YearsAtCompany'</span><span class="p">]].</span><span class="n">head</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>(197, 3)
</pre></table></code></div></div><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>NumCompaniesWorked<th>TotalWorkingYears<th>YearsAtCompany<tbody><tr><th>5<td>0<td>8<td>7<tr><th>8<td>0<td>10<td>9<tr><th>10<td>0<td>6<td>5<tr><th>11<td>0<td>10<td>9<tr><th>13<td>0<td>3<td>2</table></div><ul><li>총 197개의 데이터가 있고, 경력과 근속년수가 1년씩 차이납니다.</li><li>그렇다면 경력과 근속년수가 같은 사람들은 일한 회사의 수가 몇개로 나오는지 확인하겠습니다.</li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">data</span><span class="p">[(</span><span class="n">data</span><span class="p">.</span><span class="n">TotalWorkingYears</span> <span class="o">==</span> <span class="n">data</span><span class="p">.</span><span class="n">YearsAtCompany</span><span class="p">)][[</span><span class="s">'NumCompaniesWorked'</span><span class="p">,</span><span class="s">'TotalWorkingYears'</span><span class="p">,</span><span class="s">'YearsAtCompany'</span><span class="p">]].</span><span class="n">head</span><span class="p">()</span>
</pre></table></code></div></div><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>NumCompaniesWorked<th>TotalWorkingYears<th>YearsAtCompany<tbody><tr><th>1<td>1<td>10<td>10<tr><th>3<td>1<td>8<td>8<tr><th>7<td>1<td>1<td>1<tr><th>12<td>1<td>5<td>5<tr><th>15<td>1<td>10<td>10</table></div><ul><li>경력과 근속년수가 같은 사람들은 모두 일한회사의 수가 1개로 나옵니다.</li><li>그렇다면 일한회사의 수가 2개 이상인데 경력과 근속년수가 같은 사람도 있는지 확인해봐야겠습니다</li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">data</span><span class="p">[(</span><span class="n">data</span><span class="p">.</span><span class="n">NumCompaniesWorked</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">TotalWorkingYears</span> <span class="o">==</span> <span class="n">data</span><span class="p">.</span><span class="n">YearsAtCompany</span><span class="p">)][[</span><span class="s">'NumCompaniesWorked'</span><span class="p">,</span><span class="s">'TotalWorkingYears'</span><span class="p">,</span><span class="s">'YearsAtCompany'</span><span class="p">]].</span><span class="n">head</span><span class="p">()</span>
</pre></table></code></div></div><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>NumCompaniesWorked<th>TotalWorkingYears<th>YearsAtCompany<tbody></table></div><ul><li>일한회사의 수개 2개 이상 인데, 근속년수가 같은 사람은 없습니다.</li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">data</span><span class="p">[(</span><span class="n">data</span><span class="p">.</span><span class="n">NumCompaniesWorked</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">((</span><span class="n">data</span><span class="p">.</span><span class="n">TotalWorkingYears</span> <span class="o">-</span> <span class="n">data</span><span class="p">.</span><span class="n">YearsAtCompany</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)][[</span><span class="s">'NumCompaniesWorked'</span><span class="p">,</span><span class="s">'TotalWorkingYears'</span><span class="p">,</span><span class="s">'YearsAtCompany'</span><span class="p">]].</span><span class="n">head</span><span class="p">()</span>
</pre></table></code></div></div><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>NumCompaniesWorked<th>TotalWorkingYears<th>YearsAtCompany<tbody><tr><th>35<td>1<td>6<td>5<tr><th>45<td>1<td>23<td>22<tr><th>94<td>1<td>12<td>11<tr><th>109<td>1<td>1<td>0<tr><th>129<td>1<td>16<td>15</table></div><ul><li>일한 회사가 1개고, 총 경력과 근속년수가 1년 차이나는 사람은 있습니다.</li><li>하지만 일한 회사가 2개 이상이며, 총 경력과 근속년수가 1년 차이나는 사람은 없습니다.</li><li>정리하자면 일한회사가 0개의 의미는<ul><li>1) 현재 근속하는 회사를 제외시킨 수치여서 그렇다. (일한회사가 0 = IBM이 첫회사이다)<ul><li>그렇다면 일한회사가 1개인 사람들은 총 경력과 현재 근속년수가 같으면 안된다. (IBM에 들어오기전 직장이 있기 때문에)</li><li>하지만 일한회사가 1개인 사람들 중 총 경력과 현재 근속년수가 같은 사람이 있다. -&gt; 오류</li></ul></li><li>2) 일한회사가 0개는 오류이다.<ul><li>일한 회사가 없을수는 없으니 무조건 1개부터 시작한다,</li><li>0으로 넣은 사람들은 오류이고, 1개를 더해주면 된다.(IBM 회사)</li></ul></li></ul></li><li>결론을 이야기하자면, 데이터 상으로 일한회사가 0개가 나올수는 없으니, 0인 사람들은 모두 +1을 해주면 된다.</li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">data</span><span class="p">.</span><span class="n">NumCompaniesWorked</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">NumCompaniesWorked</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120489392-8ec96f80-c3f2-11eb-93f9-f3f654359203.png" /></p><ul><li>다시 일한회사의 수가 0인 사람들을 1로 바꾸고 보니, 압도적으로 IBM에서만 일한 사람이 많다.</li></ul><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">data</span><span class="p">.</span><span class="n">NumCompaniesWorked</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">NumCompaniesWorked</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">object</span><span class="p">)</span>
</pre></table></code></div></div><ul><li>int형으로 변경되었기에 다시 object로 변경</li></ul><h3 id="43-total-satisfaction">4.3 Total Satisfaction</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="n">point</span> <span class="o">=</span> <span class="p">{</span><span class="s">'Low'</span> <span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s">'Medium'</span> <span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s">'High'</span> <span class="p">:</span> <span class="mi">2</span> <span class="p">,</span> <span class="s">'Very High'</span> <span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
<span class="n">EnvironmentSatisfaction</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'EnvironmentSatisfaction'</span><span class="p">].</span><span class="nb">map</span><span class="p">(</span><span class="n">point</span><span class="p">)</span>
<span class="n">RelationshipSatisfaction</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'RelationshipSatisfaction'</span><span class="p">].</span><span class="nb">map</span><span class="p">(</span><span class="n">point</span><span class="p">)</span>
<span class="n">JobSatisfaction</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'JobSatisfaction'</span><span class="p">].</span><span class="nb">map</span><span class="p">(</span><span class="n">point</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s">'TotalSatisfaction'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">EnvironmentSatisfaction</span> <span class="o">+</span> <span class="n">RelationshipSatisfaction</span> <span class="o">+</span> <span class="n">JobSatisfaction</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">object</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Total Satisfaction'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">'TotalSatisfaction'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120489395-8f620600-c3f2-11eb-824b-70d5ab27f897.png" /></p><ul><li>EnvironmentSatisfaction, RelationshipSatisfaction, JobSatisfaction는 만족이라는 키워드를 가지는 컬럼입니다.</li><li>위 컬럼의 만족도에 대한 점수들을 합산하여 포탈만족도라는 컬럼을 생성하였습니다.</li><li>따라서, 개별 만족도 컬럼은 삭제 합니다.</li></ul><h3 id="44-outlier-확인">4.4 Outlier 확인</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">cont_cols</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">data</span><span class="p">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">dtype</span> <span class="o">!=</span> <span class="nb">object</span><span class="p">]</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cont_cols</span><span class="p">):</span>
    <span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">index</span><span class="p">])</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120489397-8ffa9c80-c3f2-11eb-8d8d-3f4e5d80d949.png" /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="c1"># 아웃라이어 확인 함수 생성
</span><span class="k">def</span> <span class="nf">outlier</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">col</span><span class="p">):</span>
    <span class="n">q1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">],</span> <span class="mi">25</span><span class="p">)</span> 
    <span class="n">q3</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">],</span> <span class="mi">75</span><span class="p">)</span>
    <span class="n">IQR</span> <span class="o">=</span> <span class="n">q3</span> <span class="o">-</span> <span class="n">q1</span>
    <span class="n">outlier_step</span> <span class="o">=</span> <span class="mf">1.5</span> <span class="o">*</span> <span class="n">IQR</span>
    <span class="k">return</span> <span class="n">data</span><span class="p">[(</span><span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">q1</span> <span class="o">-</span> <span class="n">outlier_step</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">q3</span> <span class="o">+</span> <span class="n">outlier_step</span><span class="p">)]</span>
</pre></table></code></div></div><h4 id="441-monthlyincom">4.4.1 MonthlyIncom</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">monthlyincom_outlier</span> <span class="o">=</span> <span class="n">outlier</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s">'MonthlyIncome'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'MonthlyIncome의 아웃라이어 갯수 </span><span class="si">{</span><span class="n">monthlyincom_outlier</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">개'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'전체 데이터의 </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">monthlyincom_outlier</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s">% 차지'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">monthlyincom_outlier</span><span class="p">.</span><span class="n">Attrition</span><span class="p">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">monthlyincom_outlier</span><span class="p">.</span><span class="n">Attrition</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>MonthlyIncome의 아웃라이어 갯수 114개
전체 데이터의 0.08% 차지
No     109
Yes      5
Name: Attrition, dtype: int64
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120489403-90933300-c3f2-11eb-8b27-df26eed28e3d.png" /></p><ul><li>컬럼 삭제 합니다. 아웃라이어가 너무 크고 많으며 VIF 계수도 굉장히 높았습니다.</li></ul><h4 id="442-totalworkingyears">4.4.2 TotalWorkingYears</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">workingyear_outlier</span> <span class="o">=</span> <span class="n">outlier</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s">'TotalWorkingYears'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'TotalWorkingYears의 아웃라이어 갯수 </span><span class="si">{</span><span class="n">workingyear_outlier</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">개'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'전체 데이터의 </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">workingyear_outlier</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s">% 차지'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">workingyear_outlier</span><span class="p">.</span><span class="n">Attrition</span><span class="p">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">workingyear_outlier</span><span class="p">.</span><span class="n">Attrition</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>TotalWorkingYears의 아웃라이어 갯수 63개
전체 데이터의 0.04% 차지
No     58
Yes     5
Name: Attrition, dtype: int64
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120489407-91c46000-c3f2-11eb-9ecc-1192fe4220a7.png" /></p><ul><li>아웃라이어의 갯수가 많지는 않으나, VIF가 높았었기에 컬럼을 삭제 합니다.</li></ul><h4 id="443-trainingtimeslastyear">4.4.3 TrainingTimesLastYear</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">traininigtimes_outlier</span> <span class="o">=</span> <span class="n">outlier</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s">'TrainingTimesLastYear'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'TrainingTimesLastYear의 아웃라이어 갯수 </span><span class="si">{</span><span class="n">traininigtimes_outlier</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">개'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'전체 데이터의 </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">traininigtimes_outlier</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s">% 차지'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">traininigtimes_outlier</span><span class="p">.</span><span class="n">Attrition</span><span class="p">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">traininigtimes_outlier</span><span class="p">.</span><span class="n">Attrition</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>TrainingTimesLastYear의 아웃라이어 갯수 238개
전체 데이터의 0.16% 차지
No     203
Yes     35
Name: Attrition, dtype: int64
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120489411-925cf680-c3f2-11eb-965a-14d54570366d.png" /></p><ul><li>VIF 계수도 낮으며, 아웃라이어가 전체 데이터에 많은 양을 자지해서 컬럼 및 아웃라이어도 그대로 유지합니다.</li></ul><h4 id="444-yearsatcompany">4.4.4 YearsAtCompany</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">yearsatcompany_outlier</span> <span class="o">=</span> <span class="n">outlier</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s">'YearsAtCompany'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'YearsAtCompany의 아웃라이어 갯수 </span><span class="si">{</span><span class="n">yearsatcompany_outlier</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">개'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'전체 데이터의 </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">yearsatcompany_outlier</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s">% 차지'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">yearsatcompany_outlier</span><span class="p">.</span><span class="n">Attrition</span><span class="p">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">yearsatcompany_outlier</span><span class="p">.</span><span class="n">Attrition</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>YearsAtCompany의 아웃라이어 갯수 104개
전체 데이터의 0.07% 차지
No     94
Yes    10
Name: Attrition, dtype: int64
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120489414-92f58d00-c3f2-11eb-9c33-26dbf061c1ec.png" /></p><ul><li>아웃라이어가 전체 데이터에 0.07% 차지합니다. 근속년수가 퇴사 여부에 영향을 미칠듯 싶어서 아웃라이어만 삭제 합니다.</li></ul><h4 id="445-yearsincurrentrole">4.4.5 YearsInCurrentRole</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">yearsincurrentrole_outlier</span> <span class="o">=</span> <span class="n">outlier</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s">'YearsInCurrentRole'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'YearsInCurrentRole의 아웃라이어 갯수 </span><span class="si">{</span><span class="n">yearsincurrentrole_outlier</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">개'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'전체 데이터의 </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">yearsincurrentrole_outlier</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s">% 차지'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">yearsincurrentrole_outlier</span><span class="p">.</span><span class="n">Attrition</span><span class="p">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">yearsincurrentrole_outlier</span><span class="p">.</span><span class="n">Attrition</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>YearsInCurrentRole의 아웃라이어 갯수 21개
전체 데이터의 0.01% 차지
No     19
Yes     2
Name: Attrition, dtype: int64
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120489416-92f58d00-c3f2-11eb-8aa8-38bae907fbe7.png" /></p><ul><li>아웃라이어가 전체 데이터에 0.01%밖에 차지를 안합니다. VIF 계수가 낮기에 아웃라이어만 삭제 결정</li></ul><h4 id="446-yearssincelastpromotion">4.4.6 YearsSinceLastPromotion</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">yearssincelastpromotion_outlier</span> <span class="o">=</span> <span class="n">outlier</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s">'YearsSinceLastPromotion'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'YearsSinceLastPromotion의 아웃라이어 갯수 </span><span class="si">{</span><span class="n">yearssincelastpromotion_outlier</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">개'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'전체 데이터의 </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">yearssincelastpromotion_outlier</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s">% 차지'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">yearssincelastpromotion_outlier</span><span class="p">.</span><span class="n">Attrition</span><span class="p">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">yearssincelastpromotion_outlier</span><span class="p">.</span><span class="n">Attrition</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre>YearsSinceLastPromotion의 아웃라이어 갯수 107개
전체 데이터의 0.07% 차지
No     94
Yes    13
Name: Attrition, dtype: int64
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120489417-938e2380-c3f2-11eb-9a06-8c427c68de98.png" /></p><ul><li>아웃라이어가 전체 데이터에 0.07% 차지하여 삭제하긴 어렵고, 컬럼은 VIF가 낮으니 삭제하기 어려워 유지</li></ul><h4 id="447-yearswithcurrmanager">4.4.7 YearsWithCurrManager</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">yearswithcurrmanager_outlier</span> <span class="o">=</span> <span class="n">outlier</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s">'YearsWithCurrManager'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'YearsWithCurrManager의 아웃라이어 갯수 </span><span class="si">{</span><span class="n">yearswithcurrmanager_outlier</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s">개'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'전체 데이터의 </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">yearswithcurrmanager_outlier</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">data</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s">% 차지'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">yearswithcurrmanager_outlier</span><span class="p">.</span><span class="n">Attrition</span><span class="p">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">yearswithcurrmanager_outlier</span><span class="p">.</span><span class="n">Attrition</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>YearsWithCurrManager의 아웃라이어 갯수 14개
전체 데이터의 0.01% 차지
No    14
Name: Attrition, dtype: int64
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120489418-938e2380-c3f2-11eb-9c16-07823a87a391.png" /></p><ul><li>VIF 도 상대적으로 낮고, 아웃라이어가 몇개 없긴 하지만, 모두 No라는 특성을 가지고 있기에 아웃라이어가 실제 특성을 가지고 있을수 있어서 유지 결정</li></ul><h4 id="448-outlier-및-컬럼-삭제">4.4.8 Outlier 및 컬럼 삭제</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">data_copy</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">outlier_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span><span class="n">yearsatcompany_outlier</span><span class="p">,</span> <span class="n">yearsincurrentrole_outlier</span><span class="p">]).</span><span class="n">drop_duplicates</span><span class="p">()</span>
<span class="n">data_copy</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">outlier_df</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">data_copy</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s">'MonthlyIncome'</span><span class="p">,</span> <span class="s">'Age'</span><span class="p">,</span> <span class="s">'TotalWorkingYears'</span><span class="p">,</span> <span class="s">'YearsAtCompany'</span><span class="p">,</span> <span class="s">'Department'</span><span class="p">,</span>
                       <span class="s">'EnvironmentSatisfaction'</span><span class="p">,</span> <span class="s">'RelationshipSatisfaction'</span><span class="p">,</span> <span class="s">'JobSatisfaction'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">data_copy</span><span class="p">.</span><span class="n">shape</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>(1361, 28)
</pre></table></code></div></div><ul><li>Outlier 및 Column을 삭제할때는 하나의 지표를 절대적으로 참고하는것이 아닌 여러가지의 지표를 사용해야 합니다.</li><li>일단, 해당 데이터에 도메인 지식이 있어서 도메인 지식을 활용하여 컬럼 및 데이터 삭제를 할수 있으면 좋습니다.</li><li>그 외에는 VIF, 아웃라이어를 가진 컬럼의 시각화, 아웃라이어 데이터만 보기 등이 있습니다.</li><li>만일 아웃라이어데이터가 이진분류에서 하나의 클래스(All 0 or all 1)만 가지고 있다면 해당 아웃라이어는 클래스를 설명하는 지표가 될수 있기에 삭제를 하지 않는쪽으로 생각 해야합니다.</li><li>반대로 두개의 클래스에 50:50으로 분포가 되어있다면, 삭제를 고려하여도 됩니다.</li></ul><p><br /></p><h2 id="5-예측을-위한-데이터-처리">5. 예측을 위한 데이터 처리</h2><hr /><h3 id="51-label-encoder-및-scaler-적용">5.1 Label Encoder 및 Scaler 적용</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="n">numeric_features</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">data_copy</span><span class="p">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">data_copy</span><span class="p">[</span><span class="n">column</span><span class="p">].</span><span class="n">dtype</span> <span class="o">!=</span> <span class="nb">object</span><span class="p">]</span>
<span class="n">categorical_features</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">data_copy</span><span class="p">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">data_copy</span><span class="p">[</span><span class="n">column</span><span class="p">].</span><span class="n">dtype</span> <span class="o">==</span> <span class="nb">object</span><span class="p">]</span>

<span class="n">data_copy</span><span class="p">[</span><span class="n">categorical_features</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_copy</span><span class="p">[</span><span class="n">categorical_features</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="n">LabelEncoder</span><span class="p">().</span><span class="n">fit_transform</span><span class="p">)</span>
<span class="n">data_copy</span><span class="p">[</span><span class="n">numeric_features</span><span class="p">]</span> <span class="o">=</span> <span class="n">RobustScaler</span><span class="p">().</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data_copy</span><span class="p">[</span><span class="n">numeric_features</span><span class="p">])</span>
</pre></table></code></div></div><ul><li>컴퓨터는 Male, HR 이런 단어들을 인식하지 못합니다. 해당 단어들을 숫자로 바꿔주는것이 Label Encoder 입니다.</li><li>예를들어 Department의 ‘Sales’, ‘Human Resources’, ‘Research &amp; Development’ 를 컴퓨터가 알아볼수 있게 0, 1, 2로 바꿔주는 것입니다.</li></ul><h3 id="52-xy-분리">5.2 X,y 분리</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">X</span> <span class="o">=</span> <span class="n">data_copy</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span> <span class="p">[</span><span class="s">'Attrition'</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data_copy</span><span class="p">.</span><span class="n">Attrition</span>
</pre></table></code></div></div><ul><li>데이터를 종속변수와 독립변수로 나눠줍니다.</li></ul><h3 id="53-train-test-분리">5.3 train, test 분리</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">87</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">train_rate</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">y_train</span><span class="p">.</span><span class="nb">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
<span class="n">test_rate</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">y_test</span><span class="p">.</span><span class="nb">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'학습 데이터에서의 Target 비율 : </span><span class="si">{</span><span class="n">train_rate</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'테스트 데이터에서의 Target 비율 : </span><span class="si">{</span><span class="n">test_rate</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>학습 데이터에서의 Target 비율 : 0.17
테스트 데이터에서의 Target 비율 : 0.17
</pre></table></code></div></div><h3 id="54-함수-생성">5.4 함수 생성</h3><h4 id="541--learning-curve-함수-준비">5.4.1 Learning Curve 함수 준비</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
</pre><td class="rouge-code"><pre><span class="c1"># Plot learning curve
</span><span class="k">def</span> <span class="nf">plot_learning_curve</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
                        <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_sizes</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(.</span><span class="mi">1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s">'accuracy'</span><span class="p">):</span>
    <span class="s">"""
    Generate a simple plot of the test and traning learning curve.

    Parameters
    ----------
    estimator : object type that implements the "fit" and "predict" methods
        An object of that type which is cloned for each validation.

    title : string
        Title for the chart.

    X : array-like, shape (n_samples, n_features)
        Training vector, where n_samples is the number of samples and
        n_features is the number of features.

    y : array-like, shape (n_samples) or (n_samples, n_features), optional
        Target relative to X for classification or regression;
        None for unsupervised learning.

    ylim : tuple, shape (ymin, ymax), optional
        Defines minimum and maximum yvalues plotted.

    cv : integer, cross-validation generator, optional
        If an integer is passed, it is the number of folds (defaults to 3).
        Specific cross-validation objects can be passed, see
        sklearn.cross_validation module for the list of possible objects

    n_jobs : integer, optional
        Number of jobs to run in parallel (default 1).

    x1 = np.linspace(0, 10, 8, endpoint=True) produces
        8 evenly spaced points in the range 0 to 10
    """</span>

    <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ylim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">*</span><span class="n">ylim</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Training examples"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Score"</span><span class="p">)</span>
    <span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores</span><span class="p">,</span> <span class="n">test_scores</span> <span class="o">=</span> <span class="n">learning_curve</span><span class="p">(</span>
        <span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> <span class="n">train_sizes</span><span class="o">=</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">)</span>
    <span class="n">train_scores_mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">train_scores_std</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_scores_mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_scores_std</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">grid</span><span class="p">()</span>

    <span class="n">plt</span><span class="p">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores_mean</span> <span class="o">-</span> <span class="n">train_scores_std</span><span class="p">,</span>
                     <span class="n">train_scores_mean</span> <span class="o">+</span> <span class="n">train_scores_std</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                     <span class="n">color</span><span class="o">=</span><span class="s">"r"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">test_scores_mean</span> <span class="o">-</span> <span class="n">test_scores_std</span><span class="p">,</span>
                     <span class="n">test_scores_mean</span> <span class="o">+</span> <span class="n">test_scores_std</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"g"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores_mean</span><span class="p">,</span> <span class="s">'o-'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"r"</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s">"Training score"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">test_scores_mean</span><span class="p">,</span> <span class="s">'o-'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"g"</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s">"Cross-validation score"</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">"best"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><ul><li>학습이 과적합인지 과소적합인지 확인하는 Learning Curve function 생성</li><li>Gridsearch와 title, x, y값을 넣으면 Learning Curve를 볼수 있는 함수</li><li>Learning Curve로 과적합을 판단함</li></ul><h4 id="542-model-성능-함수-생성">5.4.2 Model 성능 함수 생성</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">model_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predict</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Accuracy : '</span><span class="p">,</span><span class="nb">round</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predict</span><span class="p">),</span> <span class="mi">3</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Recall : '</span><span class="p">,</span><span class="nb">round</span><span class="p">(</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predict</span><span class="p">),</span> <span class="mi">3</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Precision : '</span><span class="p">,</span><span class="nb">round</span><span class="p">(</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predict</span><span class="p">),</span> <span class="mi">3</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'F1_Score : '</span><span class="p">,</span><span class="nb">round</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predict</span><span class="p">),</span> <span class="mi">3</span><span class="p">))</span>
    <span class="k">print</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Confusion_matrix :'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predict</span><span class="p">))</span>
</pre></table></code></div></div><h2 id="6-머신러닝-알고리즘을-이용한-퇴사자-예측">6. 머신러닝 알고리즘을 이용한 퇴사자 예측</h2><hr /><h3 id="61-의사결정나무">6.1 의사결정나무</h3><ul><li>데이터를 분석하여 이들 사이에 존재하는 패턴을 예측 가능한 규칙들의 조합으로 나타내며, 그 모양이 ‘나무’와 같다고 해서 의사결정나무라 불립니다.</li><li>분류(classification)와 회귀(regression) 모두 가능합니다.</li><li>종속변수를 잘 나타내주는 독립변수를 지니불순도나 엔트로피를 이용하여 분류합니다.</li><li>장점<ul><li>모델을 쉽게 시각화하여 비전문가도 이해하기 쉽습니다.</li><li>데이터의 스케일에 구애받지 않음, 전처리(정규화,표준화)가 필요 없습니다.</li><li>각 특성의 스케일이 다르거나 이진특성, 연속특성이 혼합되어 있을 때도 잘 작동 합니다.</li></ul></li><li>단점<ul><li>사전 가지치기를 사용해도 과대적합되는 경향이 있어 일반화 성능이 좋지 않습니다.</li><li>외삽(extrapolation) = 훈련 데이터의 범위 밖의 포인트는 예측할 수 없습니다.</li></ul></li></ul><h4 id="611-기본-모델-생성-및-학습">6.1.1 기본 모델 생성 및 학습</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="n">clf_model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">87</span><span class="p">)</span>

<span class="n">params_grid</span> <span class="o">=</span> <span class="p">[{}]</span>

<span class="n">gridsearch</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">clf_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">params_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">gridsearch</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=87), n_jobs=-1,
             param_grid=[{}], return_train_score=True)
</pre></table></code></div></div><ul><li>의사결정나무에 하이퍼파라미터 튜닝을 하지 않고 기본 설정으로 모델을 생성하였습니다.</li><li>Cross Validation(CV)를 5회 진행하였습니다.</li></ul><p><br /></p><h4 id="612-학습-결과-저장">6.1.2 학습 결과 저장</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">result</span><span class="p">.</span><span class="n">append</span><span class="p">({</span><span class="s">'Estimator'</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">best_estimator_</span><span class="p">).</span><span class="n">split</span><span class="p">(</span><span class="s">'('</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
           <span class="s">'mean_train_score'</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s">'mean_train_score'</span><span class="p">]),</span>
           <span class="s">'mean_test_score'</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s">'mean_test_score'</span><span class="p">])})</span>
</pre></table></code></div></div><ul><li>학습한 결과를 추후에 모델별로 시각화 할수 있게 저장을 해둡니다.</li></ul><p><br /></p><h4 id="613-예측-및-검증">6.1.3 예측 및 검증</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">clf_best_model</span> <span class="o">=</span> <span class="n">gridsearch</span><span class="p">.</span><span class="n">best_estimator_</span>
<span class="n">clf_best_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">clf_predict</span> <span class="o">=</span> <span class="n">clf_best_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">model_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">clf_predict</span><span class="p">)</span>
<span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">clf_best_model</span><span class="p">,</span> <span class="s">'DecisionTree Learning Curve'</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>Accuracy :  0.799
Recall :  0.37
Precision :  0.395
F1_Score :  0.382

Confusion_matrix :
[[201  26]
 [ 29  17]]
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120489421-9426ba00-c3f2-11eb-9f95-73de04de52a3.png" /></p><ul><li>학습이 잘 되고 있는지, Learning Curve를 그려보았습니다.</li><li>학습은 Accuracy가 1로 잘 맞추지만, 실제 검증을 하면 0.8을 넘지못합니다.</li><li>과대적합이 있습니다.</li></ul><p><br /></p><h4 id="614-중요변수-확인">6.1.4 중요변수 확인</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">important</span> <span class="o">=</span> <span class="n">clf_best_model</span><span class="p">.</span><span class="n">feature_importances_</span>

<span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">important</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'important'</span><span class="p">]).</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s">'important'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">rot</span> <span class="o">=</span> <span class="mi">45</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span><span class="s">'Important Feature'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120489425-9426ba00-c3f2-11eb-914d-1bd042222c20.png" /></p><ul><li>의사결정나무모델이 사용한 변수들중 중요하다고 판단한 Feature들을 확인해보았습니다.</li><li>가장 마지막에 있는 점수가 없는 Feature들은 중요하지 않다고해서 삭제를 할순 없습니다.</li></ul><p><br /></p><h4 id="615-결정나무-시각화">6.1.5 결정나무 시각화</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="n">dot_data</span> <span class="o">=</span> <span class="n">export_graphviz</span><span class="p">(</span><span class="n">clf_best_model</span><span class="p">,</span> <span class="n">out_file</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                <span class="n">feature_names</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span>
                <span class="n">class_names</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">Attrition</span><span class="p">.</span><span class="n">unique</span><span class="p">(),</span>
                <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="c1"># 표현하고 싶은 최대 depth
</span>                <span class="n">precision</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="c1"># 소수점 표기 자릿수
</span>                <span class="n">filled</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="c1"># class별 color 채우기
</span>                <span class="n">rounded</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="c1"># 박스의 모양을 둥글게
</span>               <span class="p">)</span>
<span class="n">pydot_graph</span> <span class="o">=</span> <span class="n">pydotplus</span><span class="p">.</span><span class="n">graph_from_dot_data</span><span class="p">(</span><span class="n">dot_data</span><span class="p">)</span>
<span class="n">pydot_graph</span><span class="p">.</span><span class="n">set_size</span><span class="p">(</span><span class="s">"</span><span class="se">\"</span><span class="s">24</span><span class="se">\"</span><span class="s">"</span><span class="p">)</span>
<span class="n">gvz_graph</span> <span class="o">=</span> <span class="n">graphviz</span><span class="p">.</span><span class="n">Source</span><span class="p">(</span><span class="n">pydot_graph</span><span class="p">.</span><span class="n">to_string</span><span class="p">())</span>
<span class="n">gvz_graph</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491363-23809d00-c3f4-11eb-842c-8157c0035d8c.png" /></p><ul><li>의사결정나무의 장점은 알고리즘을 시각화 할수 있다는 뜻입니다.</li><li>맨위의 Feature인 Overtiem이 0.5 이상이면 True, 아니면 False이며, 지니불순도를 이용하여 클래스들의 섞임 정도를 확인합니다.(하나의 클래스에 몰려있다면 지니계수가 0과 가깝게 나옴)</li><li>그러다 마지막에 지니계수가 0이 되거나, 미리 설정한 파라미터에 의해 마지막 Depth가 되면 멈추게 되고, 마지막 클래스를 결정합니다.</li><li>Class : 0혹은 1로 이루어진 종속변수값</li></ul><p><br /></p><h3 id="62-랜덤포레스트">6.2 랜덤포레스트</h3><ul><li>분류, 회귀 분석 등에 사용되는 앙상블 학습 방법의 일종으로 훈련 과정에서 구성한 다수의 결정트리로부터 분류 또는 평균 회귀 분석을 실행합니다.</li><li>여러개의 의사 결정 나무를 생성한 후에 다수결 또는 평균에 따라 출력 변수를 예측하는 알고리즘입니다. 즉 의사 결정 나무와 bagging을 혼합한 형태라고 볼 수 있습니다.</li><li>Bagging은 샘플을 여러 번 뽑아 각 모델을 학습시켜 결과를 집계(Aggregating) 하는 방법입니다.</li><li>장점<ul><li>여러개의 의사결정트리의 결과를 가지고 최종결과를 결정하기에 과적합을 방지합니다.</li><li>따라서, 결측치의 비율이 높아져도 높은 정확도를 나타냅니다.</li><li>변수의 중요성을 파악할 수 있습니다.</li></ul></li><li>단점<ul><li>데이터의 수가 많아지면 의사 결정나무에 비해 속도가 크게 떨어집니다.</li><li>여러개의 의사결정나무에서 나온 결과에 대해 최종 결과를 도출하므로, 최종 결과에 대한 해석이 어려운 단점이 있습니다.</li></ul></li></ul><h4 id="621-기본-모델-생성-및-학습">6.2.1 기본 모델 생성 및 학습</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">rf_model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">87</span><span class="p">)</span>
<span class="n">params_grid</span> <span class="o">=</span> <span class="p">[{}]</span>

<span class="n">gridsearch</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">rf_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">params_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">gridsearch</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=87), n_jobs=-1,
             param_grid=[{}], return_train_score=True)
</pre></table></code></div></div><ul><li>랜덤포레스트의 모델을 기본 설정을 사용하여 생성하고 학습하였습니다.</li><li>의사결정나무와 마찬가지로 CV는 5회 하였습니다.</li></ul><p><br /></p><h4 id="622-학습-결과-저장">6.2.2 학습 결과 저장</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">result</span><span class="p">.</span><span class="n">append</span><span class="p">({</span><span class="s">'Estimator'</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">best_estimator_</span><span class="p">).</span><span class="n">split</span><span class="p">(</span><span class="s">'('</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
           <span class="s">'mean_train_score'</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s">'mean_train_score'</span><span class="p">]),</span>
           <span class="s">'mean_test_score'</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s">'mean_test_score'</span><span class="p">])})</span>
</pre></table></code></div></div><ul><li>추후 전체 결과에 대한 시각화를 위해 학습 결과를 저장합니다.</li></ul><p><br /></p><h4 id="623-예측-및-검증">6.2.3 예측 및 검증</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">rf_best_model</span> <span class="o">=</span> <span class="n">gridsearch</span><span class="p">.</span><span class="n">best_estimator_</span>
<span class="n">rf_best_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">rf_predict</span> <span class="o">=</span> <span class="n">rf_best_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">model_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf_predict</span><span class="p">)</span>
<span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">rf_best_model</span><span class="p">,</span> <span class="s">'RandomForest Learning Curve'</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>Accuracy :  0.861
Recall :  0.196
Precision :  0.9
F1_Score :  0.321

Confusion_matrix :
[[226   1]
 [ 37   9]]
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120489429-9557e700-c3f2-11eb-8a41-8e091da26143.png" /></p><ul><li>의사결정나무와 마찬가지로 Learning Curve를 그려보았을때, 과대적합이 나타납니다.</li><li>하지만 검증 Accuracy는 의사결정나무보다 높습니다.</li><li>보통 랜덤포레스트가 의사결정나무보다는 더 나은 성능을 보입니다. 하지만 결과에 대한 해석이 어렵다는 단점이 있습니다.</li></ul><p><br /></p><h4 id="62-4-중요-변수-확인">6.2. 4 중요 변수 확인</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">important</span> <span class="o">=</span> <span class="n">rf_best_model</span><span class="p">.</span><span class="n">feature_importances_</span>

<span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">important</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'important'</span><span class="p">]).</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s">'important'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">rot</span> <span class="o">=</span> <span class="mi">45</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span><span class="s">'Important Feature'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120489433-9557e700-c3f2-11eb-89fc-4906860a2977.png" /></p><ul><li>랜덤포레스트에서 중요하다고 나온 Feature들을 확인해보았습니다.</li><li>다행히 의사결정나무와는 다르게 중요하지 않다는 변수는 없습니다.</li><li>위와 같은 사유로 하나의 모델을 보고 변수를 삭제하는것은 바람직 하지 않을수 있습니다.</li></ul><p><br /></p><h4 id="625-랜덤포레스트-시각화">6.2.5 랜덤포레스트 시각화</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="n">dot_data</span> <span class="o">=</span> <span class="n">export_graphviz</span><span class="p">(</span><span class="n">rf_best_model</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">out_file</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                <span class="n">feature_names</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span>
                <span class="n">class_names</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">Attrition</span><span class="p">.</span><span class="n">unique</span><span class="p">(),</span>
                <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="c1"># 표현하고 싶은 최대 depth
</span>                <span class="n">precision</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="c1"># 소수점 표기 자릿수
</span>                <span class="n">filled</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="c1"># class별 color 채우기
</span>                <span class="n">rounded</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="c1"># 박스의 모양을 둥글게
</span>               <span class="p">)</span>
<span class="n">pydot_graph</span> <span class="o">=</span> <span class="n">pydotplus</span><span class="p">.</span><span class="n">graph_from_dot_data</span><span class="p">(</span><span class="n">dot_data</span><span class="p">)</span>
<span class="n">pydot_graph</span><span class="p">.</span><span class="n">set_size</span><span class="p">(</span><span class="s">"</span><span class="se">\"</span><span class="s">24</span><span class="se">\"</span><span class="s">"</span><span class="p">)</span>
<span class="n">gvz_graph</span> <span class="o">=</span> <span class="n">graphviz</span><span class="p">.</span><span class="n">Source</span><span class="p">(</span><span class="n">pydot_graph</span><span class="p">.</span><span class="n">to_string</span><span class="p">())</span>
<span class="n">gvz_graph</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491497-3eeba800-c3f4-11eb-8f46-1bf7be1da31d.png" /></p><ul><li>랜덤포레스트도 트리기반이기 때문에 결정나무를 시각화하여 볼수 있습니다.</li><li>다만 Estimator의 갯수가 1개가 아닌, 많은 의사결정나무의 모임이기 때문에 대표되는 하나의 의사결정나무만 확인합니다.</li></ul><p><br /></p><h3 id="63-로지스틱-회귀">6.3 로지스틱 회귀</h3><ul><li>독립 변수의 선형 결합을 이용하여 사건의 발생 가능성을 예측하는데 사용되는 통계 기법입니다.</li><li>일반적인 회귀 분석의 목표와 동일하게 종속 변수와 독립 변수간의 관계를 구체적인 함수로 나타내어 향후 예측 모델에 사용합니다.</li><li>장점<ul><li>결과가 ‘0 또는 1’과 같이 이산 분포일 때 선형 회귀 모형의 문제점을 보완합니다.</li><li>선형회귀와 다르게 바로 ‘값’이 아닌 ‘확률’로서 분류합니다. 시그모이드 함수를 사용하여 설정하는 확률값(0.5)에따라서 0과 1으로 분류 할수 있습니다.</li></ul></li><li>단점<ul><li>선형회귀와 마찬가지로 독립변수와 종속변수가 선형 상관관계를 가지고 있다는 가정이 있어야 합니다.</li><li>언더피팅되는 경향이 있습니다.</li></ul></li></ul><p><br /></p><h4 id="631-기본-모델-생성-및-학습">6.3.1 기본 모델 생성 및 학습</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">lr_model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">87</span><span class="p">)</span>
<span class="n">params_grid</span> <span class="o">=</span> <span class="p">[{}]</span>

<span class="n">gridsearch</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">lr_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">params_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">gridsearch</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(random_state=87), n_jobs=-1,
             param_grid=[{}], return_train_score=True)
</pre></table></code></div></div><ul><li>로지스틱회귀 모델을 생성하고 학습하였습니다.</li><li>모델의 파라미터는 기본으로 설정하고, CV는 5회 진행합니다.</li></ul><p><br /></p><h4 id="632-학습-결과-저장">6.3.2 학습 결과 저장</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">result</span><span class="p">.</span><span class="n">append</span><span class="p">({</span><span class="s">'Estimator'</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">best_estimator_</span><span class="p">).</span><span class="n">split</span><span class="p">(</span><span class="s">'('</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
           <span class="s">'mean_train_score'</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s">'mean_train_score'</span><span class="p">]),</span>
           <span class="s">'mean_test_score'</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s">'mean_test_score'</span><span class="p">])})</span>
</pre></table></code></div></div><ul><li>추후 전체 결과를 시각화하여 표현하기 위해 결과를 저장합니다.</li></ul><p><br /></p><h4 id="633-예측-및-검증">6.3.3 예측 및 검증</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="n">lr_best_model</span> <span class="o">=</span> <span class="n">gridsearch</span><span class="p">.</span><span class="n">best_estimator_</span>
<span class="n">lr_best_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">lr_predict</span> <span class="o">=</span> <span class="n">lr_best_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">model_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">lr_predict</span><span class="p">)</span>
<span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">lr_best_model</span><span class="p">,</span>
                    <span class="s">'Logistic Regression Learning Curve'</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>Accuracy :  0.89
Recall :  0.457
Precision :  0.808
F1_Score :  0.583

Confusion_matrix :
[[222   5]
 [ 25  21]]
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491679-66db0b80-c3f4-11eb-8f1d-124245a9be83.png" /></p><ul><li>생성된 최적의 모델로 검증을 진행합니다.</li><li>Accuracy도 높게 나오고, 과적합이 일어나지 않습니다. 생각보다 괜찮은것 같습니다</li></ul><p><br /></p><h4 id="634-중요-변수-확인">6.3.4 중요 변수 확인</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">coefs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">lr_best_model</span><span class="p">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">coefs</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'important'</span><span class="p">]).</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s">'important'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">rot</span> <span class="o">=</span> <span class="mi">45</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span> <span class="s">'Important Feature'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491689-693d6580-c3f4-11eb-8fdd-b85846312f44.png" /></p><ul><li>로지스틱 회귀에서 중요한 변수들을 확인합니다.</li><li>로지스틱 회귀의 중요도 점수는 음수를 가질수 있기에, np.abs를 사용하여 절대값으로 비교하였습니다.</li><li>현재의 그래프에서는 중요한 순서와 점수만 알수 있을뿐, 절대값을 주었기에 음수인지 양수인지는 확인 불가합니다.</li><li>음수와 양수를 나누려면 절대값코드를 제거하면 됩니다.</li></ul><p><br /></p><h3 id="64-xgboost">6.4 XGBoost</h3><ul><li>Decision tree를 기반으로 한 Ensemble 방법으로 Boosting을 기반으로 하는 머신러닝 방법입니다.</li><li>Boosting은 여러개의 알고리즘이 순차적으로 학습을 하되 앞에 학습한 알고리즘 예측이 틀린 데이터에 대해 올바르게 예측할수 있도록 그 다음번 알고리즘에 가중치를 부여하여 학습과 예측을 진행하는 방식입니다.</li><li>장점<ul><li>GBM 기반의 알고리즘의 느린속도를 다양한 규제를 통해 해결하여 속도가 빠릅니다.</li><li>병렬 학습이 가능하도록 설계됨</li><li>XGBoost는 반복 수행시 마다 내부적으로 학습데이터와 검증데이터를 교차검증으로 수행합니다.</li><li>교차검증을 통해 최적화되면 반복을 중단하는 조기 중단 기능이 있습니다.</li></ul></li><li>단점<ul><li>GBM보다는 빠르지만, 여전히 느립니다.</li></ul></li></ul><h4 id="641-기본-모델-생성-및-학습">6.4.1 기본 모델 생성 및 학습</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="n">xgb_model</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">XGBClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">87</span><span class="p">)</span>

<span class="n">params_grid</span> <span class="o">=</span> <span class="p">[{}]</span>

<span class="n">gridsearch</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">xgb_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">params_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">gridsearch</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre>GridSearchCV(cv=5,
             estimator=XGBClassifier(base_score=None, booster=None,
                                     colsample_bylevel=None,
                                     colsample_bynode=None,
                                     colsample_bytree=None, gamma=None,
                                     gpu_id=None, importance_type='gain',
                                     interaction_constraints=None,
                                     learning_rate=None, max_delta_step=None,
                                     max_depth=None, min_child_weight=None,
                                     missing=nan, monotone_constraints=None,
                                     n_estimators=100, n_jobs=None,
                                     num_parallel_tree=None, random_state=87,
                                     reg_alpha=None, reg_lambda=None,
                                     scale_pos_weight=None, subsample=None,
                                     tree_method=None, validate_parameters=None,
                                     verbosity=None),
             n_jobs=-1, param_grid=[{}], return_train_score=True)
</pre></table></code></div></div><ul><li>XGBoost를 기본 파라미터를 사용하여 생성합니다.</li><li>마찬가지로 CV는 5회 합니다.</li></ul><p><br /></p><h4 id="642-학습-결과-및-저장">6.4.2 학습 결과 및 저장</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">result</span><span class="p">.</span><span class="n">append</span><span class="p">({</span><span class="s">'Estimator'</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">best_estimator_</span><span class="p">).</span><span class="n">split</span><span class="p">(</span><span class="s">'('</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
           <span class="s">'mean_train_score'</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s">'mean_train_score'</span><span class="p">]),</span>
           <span class="s">'mean_test_score'</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s">'mean_test_score'</span><span class="p">])})</span>
</pre></table></code></div></div><ul><li>추후 전체 결과를 시각화하기 위해 학습 결과를 저장합니다.</li></ul><p><br /></p><h4 id="643-예측-및-검증">6.4.3 예측 및 검증</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="n">xgb_best_model</span> <span class="o">=</span> <span class="n">gridsearch</span><span class="p">.</span><span class="n">best_estimator_</span>
<span class="n">xgb_best_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">xgb_predict</span> <span class="o">=</span> <span class="n">xgb_best_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">model_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">xgb_predict</span><span class="p">)</span>
<span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">xgb_best_model</span><span class="p">,</span>
                    <span class="s">'XGBoosting Learning Curve'</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>Accuracy :  0.883
Recall :  0.435
Precision :  0.769
F1_Score :  0.556

Confusion_matrix :
[[221   6]
 [ 26  20]]
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491699-6b072900-c3f4-11eb-93f4-c0a4af0b6c63.png" /></p><ul><li>Learning Curve를 확인한 결과 학습은 잘되었지만, 검증과는 차이가 많이 납니다.</li><li>역시나 과대 적합 같습니다.</li></ul><p><br /></p><h4 id="644-중요-변수-확인">6.4.4 중요 변수 확인</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">important</span> <span class="o">=</span> <span class="n">xgb_best_model</span><span class="p">.</span><span class="n">feature_importances_</span>

<span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">important</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'important'</span><span class="p">]).</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s">'important'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">rot</span> <span class="o">=</span> <span class="mi">45</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span> <span class="s">'Important Feature'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491703-6b9fbf80-c3f4-11eb-9b4f-1073c9a9afbf.png" /></p><ul><li>XGBoost에서의 중요 Feature들을 확인해 보았습니다.</li><li>Overtime이 모든 모델에 있어 중요한 변수로 확인됩니다.</li></ul><h3 id="65-lightgbm">6.5 LightGBM</h3><ul><li>LightGBM은 XGBoost와 함께 부스팅 계열에서 가장 각광받는 알고리즘으로, XGBoost에서 속도 및 편의 등을 개선하여 나온 알고리즘입니다.</li><li>장점<ul><li>LGBM의 큰 장점은 속도입니다. GBM 계열중에 제일 빠릅니다.</li><li>XGBoost보다 학습에 걸리는 시간이 훨씬 적으며, 메모리 사용량도 상대적으로 적다.</li><li>XGBoost와 마찬가지로 대용량 데이터에 대한 뛰어난 성능 및 병렬컴퓨팅 기능을 제공하고 최근에는 추가로GPU까지 지원한다.</li></ul></li><li>단점<ul><li>적은 수의 데이터에는 어울리지 않으며, 데이터가 적으면 과적합에 쉽게 걸린다. (일반적으로 10000건 이상의 데이터가 필요하다고 함)</li></ul></li></ul><h4 id="651-기본-모델-생성-및-학습">6.5.1 기본 모델 생성 및 학습</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">lgbm_model</span> <span class="o">=</span> <span class="n">LGBMClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">87</span><span class="p">)</span>
<span class="n">params_grid</span> <span class="o">=</span> <span class="p">[{}]</span>

<span class="n">gridsearch</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">lgbm_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">params_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">gridsearch</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(random_state=87), n_jobs=-1,
             param_grid=[{}], return_train_score=True)
</pre></table></code></div></div><ul><li>LightGBM 모델을 기본 파라미터로 생성 합니다.</li><li>마찬가지로 CV는 5회 합니다.</li></ul><p><br /></p><h4 id="652-학습-결과-저장">6.5.2 학습 결과 저장</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">result</span><span class="p">.</span><span class="n">append</span><span class="p">({</span><span class="s">'Estimator'</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">best_estimator_</span><span class="p">).</span><span class="n">split</span><span class="p">(</span><span class="s">'('</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
           <span class="s">'mean_train_score'</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s">'mean_train_score'</span><span class="p">]),</span>
           <span class="s">'mean_test_score'</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s">'mean_test_score'</span><span class="p">])})</span>
</pre></table></code></div></div><ul><li>전체 모델에 대한 시각화를 위해 학습 결과를 저장합니다.</li></ul><p><br /></p><h4 id="653-예측-및-검증">6.5.3 예측 및 검증</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">lgbm_best_model</span> <span class="o">=</span> <span class="n">gridsearch</span><span class="p">.</span><span class="n">best_estimator_</span>
<span class="n">lgbm_best_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">lgbm_predict</span> <span class="o">=</span> <span class="n">lgbm_best_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">model_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">lgbm_predict</span><span class="p">)</span>
<span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">lgbm_best_model</span><span class="p">,</span> <span class="s">'Light LGBM Learning Curve'</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>Accuracy :  0.864
Recall :  0.348
Precision :  0.696
F1_Score :  0.464

Confusion_matrix :
[[220   7]
 [ 30  16]]
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491706-6d698300-c3f4-11eb-930d-ac5876e8b70f.png" /></p><ul><li>Learning Curve를 확인한 결과 역시나 과대적합입니다.</li><li>트리기반의 모델은 대부분 과대적합을 가지는 단점을 가지고 있습니다.</li></ul><p><br /></p><h4 id="654-중요-변수-확인">6.5.4 중요 변수 확인</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">important</span> <span class="o">=</span> <span class="n">lgbm_best_model</span><span class="p">.</span><span class="n">feature_importances_</span>

<span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">important</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'important'</span><span class="p">]).</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s">'important'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">rot</span> <span class="o">=</span> <span class="mi">45</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span> <span class="s">'Important Feature'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491710-6e021980-c3f4-11eb-8c87-b641214206e6.png" /></p><ul><li>LightGBM의 중요변수를 확인하였습니다.</li><li>Rate의 변수들이 모두 중요하다고 한것이 특이한 점입니다.</li></ul><p><br /></p><h3 id="66-roc-curve">6.6 ROC Curve</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
</pre><td class="rouge-code"><pre><span class="n">clf_pred_proba</span> <span class="o">=</span> <span class="n">clf_best_model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">clf_fpr</span><span class="p">,</span> <span class="n">clf_tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">clf_pred_proba</span><span class="p">)</span>
<span class="n">clf_roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">clf_pred_proba</span><span class="p">)</span>

<span class="n">rf_pred_proba</span> <span class="o">=</span> <span class="n">rf_best_model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">rf_fpr</span><span class="p">,</span> <span class="n">rf_tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf_pred_proba</span><span class="p">)</span>
<span class="n">rf_roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf_pred_proba</span><span class="p">)</span>

<span class="n">lr_pred_proba</span> <span class="o">=</span> <span class="n">lr_best_model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">lr_fpr</span><span class="p">,</span> <span class="n">lr_tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">lr_pred_proba</span><span class="p">)</span>
<span class="n">lr_roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">lr_pred_proba</span><span class="p">)</span>

<span class="n">xgb_pred_proba</span> <span class="o">=</span> <span class="n">xgb_best_model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">xgb_fpr</span><span class="p">,</span> <span class="n">xgb_tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">xgb_pred_proba</span><span class="p">)</span>
<span class="n">xgb_roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">xgb_pred_proba</span><span class="p">)</span>

<span class="n">lgbm_pred_proba</span> <span class="o">=</span> <span class="n">gridsearch</span><span class="p">.</span><span class="n">best_estimator_</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">lgbm_fpr</span><span class="p">,</span> <span class="n">lgbm_tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">lgbm_pred_proba</span><span class="p">)</span>
<span class="n">lgbm_roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">lgbm_pred_proba</span><span class="p">)</span>



<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'ROC Curve'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">clf_fpr</span><span class="p">,</span> <span class="n">clf_tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'DecisionTree Roc Auc Score (area = %0.2f)'</span> <span class="o">%</span> <span class="n">clf_roc_auc</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">rf_fpr</span><span class="p">,</span> <span class="n">rf_tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'RandomForest Roc Auc Score (area = %0.2f)'</span> <span class="o">%</span> <span class="n">rf_roc_auc</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_fpr</span><span class="p">,</span> <span class="n">lr_tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'LogisticRegression Roc Auc Score (area = %0.2f)'</span> <span class="o">%</span> <span class="n">lr_roc_auc</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xgb_fpr</span><span class="p">,</span> <span class="n">xgb_tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'XGBoosting Roc Auc Score (area = %0.2f)'</span> <span class="o">%</span> <span class="n">xgb_roc_auc</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lgbm_fpr</span><span class="p">,</span> <span class="n">lgbm_tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Light LGBM Roc Auc Score (area = %0.2f)'</span> <span class="o">%</span> <span class="n">lgbm_roc_auc</span><span class="p">)</span>


<span class="n">plt</span><span class="p">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">"lower right"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491717-6e9ab000-c3f4-11eb-9669-e040c13181ae.png" /></p><ul><li>전체 모델의 ROC Curve와 AUC점수를 확인해 보았습니다.</li><li>ROC Curve는 그래프가 반대 ㄱ모양으로 생기는게 가장 이상적인 모양입니다.</li><li>AUC 점수는 ROC Curve의 아래 면적입니다. 1에 가까울수록 높은 수치 입니다.</li><li>역시나 의사결정나무가 가장 낮고, 로지스틱회귀가 가장 높으며 나머지는 비슷합니다.</li></ul><p><br /></p><h3 id="67-accuracy-비교">6.7 Accuracy 비교</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">(</span><span class="s">'mean_test_score'</span><span class="p">,</span><span class="s">'Estimator'</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">)</span>
<span class="n">g</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"Mean Accuracy"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491720-6f334680-c3f4-11eb-9790-4bd8764233c6.png" /></p><ul><li>전체 모델의 Validation Accuracy를 시각화 하였습니다.</li><li>의사결정나무를 제외하고는 다들 비슷한 성능을 보입니다.</li></ul><p><br /></p><h2 id="7-hyperparameter-tuning">7. Hyperparameter Tuning</h2><hr /><h3 id="71-decision-tree-hyperparameter-tuning">7.1 Decision Tree Hyperparameter Tuning</h3><h4 id="711-튜닝-모델-생성-및-학습">7.1.1 튜닝 모델 생성 및 학습</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="n">clf_model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">87</span><span class="p">)</span>

<span class="n">params_grid</span> <span class="o">=</span> <span class="p">[{</span>
    <span class="s">'max_depth'</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span> <span class="c1"># 얼마나 깊게 들어가는지.
</span>    <span class="s">'min_samples_split'</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="c1"># 노드를 분할하기 위한 최소한의 샘플 데이터수 → 과적합을 제어하는데 사용
</span><span class="p">}]</span>


<span class="n">gridsearch</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">clf_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">params_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">gridsearch</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=87), n_jobs=-1,
             param_grid=[{'max_depth': [5, 7, 9, 11],
                          'min_samples_split': [1, 2, 3, 4, 5]}],
             return_train_score=True)
</pre></table></code></div></div><ul><li>의사결정나무의 파라미터를 튜닝하여 생성합니다.</li><li>파라미터는 그리드서치를 사용하여 최적의 파라미터를 찾게 하였습니다.</li><li>사용한 파라미터는 max_depth와 min_samples_split 입니다.</li></ul><p><br /></p><h4 id="712-학습-결과-저장">7.1.2 학습 결과 저장</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">result_hyper</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">result_hyper</span><span class="p">.</span><span class="n">append</span><span class="p">({</span><span class="s">'Estimator'</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">best_estimator_</span><span class="p">).</span><span class="n">split</span><span class="p">(</span><span class="s">'('</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
           <span class="s">'hyper_mean_train_score'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s">'mean_train_score'</span><span class="p">]).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span>
           <span class="s">'hyper_mean_test_score'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s">'mean_test_score'</span><span class="p">]).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)})</span>
</pre></table></code></div></div><ul><li>추후에 전체 모델에 대한 학습한 결과를 시각화하기 위해 저장합니다.</li></ul><p><br /></p><h4 id="713-예측-및-검증">7.1.3 예측 및 검증</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="n">clf_hyper_model</span> <span class="o">=</span> <span class="n">gridsearch</span><span class="p">.</span><span class="n">best_estimator_</span>
<span class="n">clf_hyper_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">clf_hyper_predict</span> <span class="o">=</span> <span class="n">clf_hyper_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">model_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">clf_predict</span><span class="p">)</span>
<span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">clf_best_model</span><span class="p">,</span> <span class="s">'DecisionTree Learning Curve'</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">model_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">clf_hyper_predict</span><span class="p">)</span>
<span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">clf_hyper_model</span><span class="p">,</span> <span class="s">'DecisionTree Hyperparameter Learning Curve'</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>Accuracy :  0.799
Recall :  0.37
Precision :  0.395
F1_Score :  0.382

Confusion_matrix :
[[201  26]
 [ 29  17]]
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491722-6fcbdd00-c3f4-11eb-86e6-cd7b4a13a9b7.png" /></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>Accuracy :  0.832
Recall :  0.37
Precision :  0.5
F1_Score :  0.425

Confusion_matrix :
[[210  17]
 [ 29  17]]
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491724-6fcbdd00-c3f4-11eb-8f3a-7e8319408182.png" /></p><ul><li>파라미터를 튜닝한뒤 결과를 확인합니다.</li><li>확실히 학습에 규제를 주었기 때문에 Learning Curve가 서로 만나려고 합니다.</li><li>튜닝전과 후의 결과도 전체적으로 나은 모습을 보입니다.</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">clf_hyper_model</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>DecisionTreeClassifier(max_depth=5, random_state=87)
</pre></table></code></div></div><h4 id="714-중요-변수-확인">7.1.4 중요 변수 확인</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">important</span> <span class="o">=</span> <span class="n">clf_best_model</span><span class="p">.</span><span class="n">feature_importances_</span>
<span class="n">important_hyper</span> <span class="o">=</span> <span class="n">clf_hyper_model</span><span class="p">.</span><span class="n">feature_importances_</span>

<span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">important</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'important'</span><span class="p">]).</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s">'important'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">rot</span> <span class="o">=</span> <span class="mi">45</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span> <span class="s">'Before Important Feature'</span><span class="p">)</span>
<span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">important_hyper</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'important_hyper'</span><span class="p">]).</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s">'important_hyper'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">rot</span> <span class="o">=</span> <span class="mi">45</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span> <span class="s">'After Important Feature'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491726-70647380-c3f4-11eb-94fa-ba2dfaf725b7.png" /></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491729-70647380-c3f4-11eb-9f9c-1d60becc7c5e.png" /></p><ul><li>파라미터를 튜닝하기 전과 튜닝 후의 중요변수를 확인해보았습니다.</li><li>튜닝전에는 Rate 계열의 변수가 중요했다면, 지금은 Overtime과 같은 변수가 중요해지는 등의 변화가 보입니다.</li></ul><p><br /></p><h4 id="715-결정나무-시각화">7.1.5 결정나무 시각화</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="n">dot_data</span> <span class="o">=</span> <span class="n">export_graphviz</span><span class="p">(</span><span class="n">clf_hyper_model</span><span class="p">,</span> <span class="n">out_file</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                <span class="n">feature_names</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span>
                <span class="n">class_names</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">Attrition</span><span class="p">.</span><span class="n">unique</span><span class="p">(),</span>
                <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="c1"># 표현하고 싶은 최대 depth
</span>                <span class="n">precision</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="c1"># 소수점 표기 자릿수
</span>                <span class="n">filled</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="c1"># class별 color 채우기
</span>                <span class="n">rounded</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="c1"># 박스의 모양을 둥글게
</span>               <span class="p">)</span>
<span class="n">pydot_graph</span> <span class="o">=</span> <span class="n">pydotplus</span><span class="p">.</span><span class="n">graph_from_dot_data</span><span class="p">(</span><span class="n">dot_data</span><span class="p">)</span>
<span class="n">pydot_graph</span><span class="p">.</span><span class="n">set_size</span><span class="p">(</span><span class="s">"</span><span class="se">\"</span><span class="s">24</span><span class="se">\"</span><span class="s">"</span><span class="p">)</span>
<span class="n">gvz_graph</span> <span class="o">=</span> <span class="n">graphviz</span><span class="p">.</span><span class="n">Source</span><span class="p">(</span><span class="n">pydot_graph</span><span class="p">.</span><span class="n">to_string</span><span class="p">())</span>
<span class="n">gvz_graph</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491732-70fd0a00-c3f4-11eb-8c85-9e27e9c5a7ff.png" /></p><ul><li>이번에도 결정나무를 시각화 하였습니다.</li><li>Max depth에 대해 규제를 주었기에 모든 결과를 볼수 있었습니다.</li></ul><p><br /></p><h3 id="72-randomforest-hyperparameter-tuning">7.2 RandomForest Hyperparameter Tuning</h3><h4 id="721-튜닝-모델-생성-및-학습">7.2.1 튜닝 모델 생성 및 학습</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="n">rf_model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">87</span><span class="p">)</span>

<span class="n">params_grid</span> <span class="o">=</span> <span class="p">[{</span><span class="s">'n_estimators'</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">150</span><span class="p">],</span> <span class="c1"># 의사결정나무의 갯수
</span>                <span class="s">'max_features'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span> <span class="c1"># 선택할 특성의 수
</span>                <span class="s">'max_depth'</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="c1"># 얼마나 깊게 들어가는지
</span>                <span class="s">'min_samples_split'</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="c1"># 노드를 분할하기 위한 최소 샘플 수
</span>                <span class="s">'min_samples_leaf'</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="c1"># 한 노드에서 가지고 있어야 하는 최소 샘플 수
</span>                <span class="p">}]</span>

<span class="n">gridsearch</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">rf_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">params_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">gridsearch</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=87), n_jobs=-1,
             param_grid=[{'max_depth': [2, 4, 6, 8], 'max_features': [0.3, 0.7],
                          'min_samples_leaf': [2, 4, 6, 8],
                          'min_samples_split': [2, 4, 6, 8],
                          'n_estimators': [10, 50, 150]}],
             return_train_score=True)
</pre></table></code></div></div><ul><li>그리드 서치를 이용하여 최적의 파라미터를 가진 모델을 찾습니다.</li><li>파라미터는 n_estimators, max_features, max_depth, min_samples_split, min_samples_leaf를 사용하였습니다.</li></ul><p><br /></p><h4 id="722-학습-결과-저장">7.2.2 학습 결과 저장</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">result_hyper</span><span class="p">.</span><span class="n">append</span><span class="p">({</span><span class="s">'Estimator'</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">best_estimator_</span><span class="p">).</span><span class="n">split</span><span class="p">(</span><span class="s">'('</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
           <span class="s">'hyper_mean_train_score'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s">'mean_train_score'</span><span class="p">]).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span>
           <span class="s">'hyper_mean_test_score'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s">'mean_test_score'</span><span class="p">]).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)})</span>
</pre></table></code></div></div><ul><li>전체 모델의 결과를 시각화하기 위해 학습 결과를 저장합니다.</li></ul><p><br /></p><h4 id="723-예측-및-검증">7.2.3 예측 및 검증</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">rf_hyper_model</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>RandomForestClassifier(max_depth=8, max_features=0.3, min_samples_leaf=2,
                       n_estimators=50, random_state=87)
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="n">rf_hyper_model</span> <span class="o">=</span> <span class="n">gridsearch</span><span class="p">.</span><span class="n">best_estimator_</span>
<span class="n">rf_hyper_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">rf_hyper_predict</span> <span class="o">=</span> <span class="n">rf_hyper_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">model_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf_predict</span><span class="p">)</span>
<span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">rf_best_model</span><span class="p">,</span>
                    <span class="s">'RandomForest Learning Curve'</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">model_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf_hyper_predict</span><span class="p">)</span>
<span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">rf_hyper_model</span><span class="p">,</span>
                    <span class="s">'RandomForest Hyperparameter Learning Curve'</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>Accuracy :  0.861
Recall :  0.196
Precision :  0.9
F1_Score :  0.321

Confusion_matrix :
[[226   1]
 [ 37   9]]
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491735-7195a080-c3f4-11eb-9994-8ba723295795.png" /></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>Accuracy :  0.864
Recall :  0.196
Precision :  1.0
F1_Score :  0.327

Confusion_matrix :
[[227   0]
 [ 37   9]]
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491739-722e3700-c3f4-11eb-9aa6-c31c4db869a3.png" /></p><ul><li>파라미터 튜닝을 하여 찾은 최적의 모델을 사용하여 Learning Curve를 확인하였습니다.</li><li>확실히, 이전보다 성능도 좋아지고, 학습곡선도 잘 나옵니다.</li></ul><p><br /></p><h4 id="724-중요-변수-확인">7.2.4 중요 변수 확인</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">important</span> <span class="o">=</span> <span class="n">rf_best_model</span><span class="p">.</span><span class="n">feature_importances_</span>
<span class="n">important_hyper</span> <span class="o">=</span> <span class="n">rf_hyper_model</span><span class="p">.</span><span class="n">feature_importances_</span>

<span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">important</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'important'</span><span class="p">]).</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s">'important'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">rot</span> <span class="o">=</span> <span class="mi">45</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span> <span class="s">'Before Important Feature'</span><span class="p">)</span>
<span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">important_hyper</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'important_hyper'</span><span class="p">]).</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s">'important_hyper'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">rot</span> <span class="o">=</span> <span class="mi">45</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span> <span class="s">'After Important Feature'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491740-72c6cd80-c3f4-11eb-9b4d-7347053601ff.png" /></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491742-735f6400-c3f4-11eb-9982-c40cb7df40dc.png" /></p><ul><li>파라미터를 튜닝하기전과 하고난 뒤의 중요 Feature들을 비교합니다.</li><li>마찬가지로 Overtime이 상위로 올라왔습니다.</li></ul><p><br /></p><h4 id="725-결정나무-시각화">7.2.5 결정나무 시각화</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="n">dot_data</span> <span class="o">=</span> <span class="n">export_graphviz</span><span class="p">(</span><span class="n">rf_hyper_model</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">out_file</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> 
                <span class="n">feature_names</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span>
                <span class="n">class_names</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">Attrition</span><span class="p">.</span><span class="n">unique</span><span class="p">(),</span>
                <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="c1"># 표현하고 싶은 최대 depth
</span>                <span class="n">precision</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="c1"># 소수점 표기 자릿수
</span>                <span class="n">filled</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="c1"># class별 color 채우기
</span>                <span class="n">rounded</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="c1"># 박스의 모양을 둥글게
</span>               <span class="p">)</span>
<span class="n">pydot_graph</span> <span class="o">=</span> <span class="n">pydotplus</span><span class="p">.</span><span class="n">graph_from_dot_data</span><span class="p">(</span><span class="n">dot_data</span><span class="p">)</span>
<span class="n">pydot_graph</span><span class="p">.</span><span class="n">set_size</span><span class="p">(</span><span class="s">"</span><span class="se">\"</span><span class="s">24</span><span class="se">\"</span><span class="s">"</span><span class="p">)</span>
<span class="n">gvz_graph</span> <span class="o">=</span> <span class="n">graphviz</span><span class="p">.</span><span class="n">Source</span><span class="p">(</span><span class="n">pydot_graph</span><span class="p">.</span><span class="n">to_string</span><span class="p">())</span>
<span class="n">gvz_graph</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491749-73f7fa80-c3f4-11eb-8a3f-e16090bf3087.png" /></p><ul><li>랜덤포레스트의 결정나무중 하나를 가져와서 확인해봅니다.</li><li>이번에는 LowWorkingYears 변수를 시작하여 노드들이 나갑니다.</li></ul><p><br /></p><h3 id="73-logistic-regression-hyperparameter-tuning">7.3 Logistic Regression Hyperparameter Tuning</h3><h4 id="731-튜닝-모델-생성-및-학습">7.3.1 튜닝 모델 생성 및 학습</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="n">lr_model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">87</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="s">'balance'</span><span class="p">)</span>

<span class="n">params_grid</span> <span class="o">=</span> <span class="p">[{</span>
    <span class="s">'solver'</span><span class="p">:</span> <span class="p">[</span><span class="s">'newton-cg'</span><span class="p">,</span> <span class="s">'lbfgs'</span><span class="p">,</span> <span class="s">'liblinear'</span><span class="p">,</span> <span class="s">'library'</span><span class="p">,</span>  <span class="s">'sag'</span><span class="p">,</span> <span class="s">'saga'</span><span class="p">],</span> <span class="c1"># 최적화에 사용할 알고리즘
</span>    <span class="s">'C'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="c1"># 규칙강도의 역수 값
</span>    <span class="s">'max_iter'</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">50</span><span class="p">))</span> <span class="c1"># solver가 수렴하게 만드는 최대 반복값
</span><span class="p">}]</span>

<span class="n">gridsearch</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">lr_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">params_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">gridsearch</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre>GridSearchCV(cv=5,
             estimator=LogisticRegression(class_weight='balance',
                                          random_state=87),
             n_jobs=-1,
             param_grid=[{'C': [0.01, 0.1, 1, 5, 10],
                          'max_iter': [1, 51, 101, 151, 201, 251, 301, 351, 401,
                                       451, 501, 551, 601, 651, 701, 751, 801,
                                       851, 901, 951],
                          'solver': ['newton-cg', 'lbfgs', 'liblinear',
                                     'library', 'sag', 'saga']}],
             return_train_score=True)
</pre></table></code></div></div><ul><li>로지스틱 회귀를 마찬가지로 그리드 서치를 사용하여 생성합니다.</li><li>solver, C, max_iter의 파라미터를 사용하였습니다.</li></ul><p><br /></p><h4 id="732-학습-결과-저장">7.3.2 학습 결과 저장</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">result_hyper</span><span class="p">.</span><span class="n">append</span><span class="p">({</span><span class="s">'Estimator'</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">best_estimator_</span><span class="p">).</span><span class="n">split</span><span class="p">(</span><span class="s">'('</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
           <span class="s">'hyper_mean_train_score'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s">'mean_train_score'</span><span class="p">]).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span>
           <span class="s">'hyper_mean_test_score'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s">'mean_test_score'</span><span class="p">]).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)})</span>
</pre></table></code></div></div><ul><li>추후 전체 데이터 시각화를 위해 학습결과를 저장합니다.</li></ul><p><br /></p><h4 id="733-예측-및-검증">7.3.3 예측 및 검증</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="n">lr_hyper_model</span> <span class="o">=</span> <span class="n">gridsearch</span><span class="p">.</span><span class="n">best_estimator_</span>
<span class="n">lr_hyper_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">lr_hyper_predict</span> <span class="o">=</span> <span class="n">lr_hyper_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">model_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">lr_predict</span><span class="p">)</span>
<span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">lr_best_model</span><span class="p">,</span>
                    <span class="s">'Logistic Regression Learning Curve'</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>


<span class="n">model_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">lr_hyper_predict</span><span class="p">)</span>
<span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">lr_hyper_model</span><span class="p">,</span>
                    <span class="s">'Logistic Regression Hyperparameter Learning Curve'</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>Accuracy :  0.89
Recall :  0.457
Precision :  0.808
F1_Score :  0.583

Confusion_matrix :
[[222   5]
 [ 25  21]]
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491758-75c1be00-c3f4-11eb-8c75-2e17ae098358.png" /></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>Accuracy :  0.894
Recall :  0.478
Precision :  0.815
F1_Score :  0.603

Confusion_matrix :
[[222   5]
 [ 24  22]]
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491760-75c1be00-c3f4-11eb-8d2b-44c7649525c6.png" /></p><ul><li>트리기반의 모델들 보다는 뚜렷하게 나아진점이 보이진 않지만, 약하게 나마 Learning Curve도 좋아지는 모습을 보입니다.</li><li>또한, 성능도 좋은 수준입니다.</li></ul><p><br /></p><h4 id="734-중요-변수-확인">7.3.4 중요 변수 확인</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="n">important</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">lr_best_model</span><span class="p">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">important_hyper</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">lr_hyper_model</span><span class="p">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">important</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'important'</span><span class="p">]).</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s">'important'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">rot</span> <span class="o">=</span> <span class="mi">45</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span> <span class="s">'Before Important Feature'</span><span class="p">)</span>
<span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">important_hyper</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'important_hyper'</span><span class="p">]).</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s">'important_hyper'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">rot</span> <span class="o">=</span> <span class="mi">45</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span> <span class="s">'After Important Feature'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491762-765a5480-c3f4-11eb-841a-59dfb944efed.png" /></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491766-76f2eb00-c3f4-11eb-937a-815beff86ca4.png" /></p><ul><li>중요한 변수를 확인해 보았습니다.</li><li>트리기반 모델들은 rate 계열의 컬럼을 중요하게 나왔는데, 회귀모델은 overtime이 중요하게 나옵니다.</li></ul><p><br /></p><h3 id="74-xgboost">7.4 XGBoost</h3><h4 id="741-튜닝-모델-생성-및-학습">7.4.1 튜닝 모델 생성 및 학습</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre><td class="rouge-code"><pre><span class="n">xgb_model</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">XGBClassifier</span><span class="p">(</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">87</span><span class="p">,</span> <span class="n">objective</span><span class="o">=</span><span class="s">'binary:logistic'</span><span class="p">,</span> <span class="n">booster</span><span class="o">=</span><span class="s">'gbtree'</span><span class="p">)</span>

<span class="n">params_grid</span> <span class="o">=</span> <span class="p">[{</span>
    <span class="s">'n_estimators'</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">110</span><span class="p">,</span> <span class="mi">10</span><span class="p">)),</span> <span class="c1"># 의사결정나무의 수
</span>    <span class="s">'min_child_weight'</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="c1"># 자식노드에서 관측되는 최소 가중치의 합
</span>    <span class="s">'gamma'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">],</span> <span class="c1"># 트리의 노드에서 추가 파티션을 만들기 위해 필요한 최소 손실 감소. 크면 클수록 더 보수적인 알고리즘이 생성됨
</span>    <span class="s">'max_depth'</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="c1"># 얼마나 깊게 들어가는지
</span>
<span class="p">}]</span>

<span class="n">gridsearch</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">xgb_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">params_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">gridsearch</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
</pre><td class="rouge-code"><pre>GridSearchCV(cv=5,
             estimator=XGBClassifier(base_score=None, booster='gbtree',
                                     colsample_bylevel=None,
                                     colsample_bynode=None,
                                     colsample_bytree=None, gamma=None,
                                     gpu_id=None, importance_type='gain',
                                     interaction_constraints=None,
                                     learning_rate=None, max_delta_step=None,
                                     max_depth=None, min_child_weight=None,
                                     missing=nan, monotone_constraints=None,
                                     n_estimators=100, n_jobs=None,
                                     num_parallel_tree=None, random_state=87,
                                     reg_alpha=None, reg_lambda=None,
                                     scale_pos_weight=None, subsample=None,
                                     tree_method=None, validate_parameters=None,
                                     verbosity=None),
             n_jobs=-1,
             param_grid=[{'gamma': [0.1, 0.5, 0.7, 1, 1.3],
                          'max_depth': [1, 3, 5, 7, 9],
                          'min_child_weight': [5, 7, 9],
                          'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90,
                                           100]}],
             return_train_score=True)
</pre></table></code></div></div><ul><li>파라미터 튜닝을 하여 XGBoost를 생성합니다.</li><li>사용한 파라미터는 n_estimators, min_child_weight, gamma, max_depth 입니다.</li></ul><p><br /></p><h4 id="742-학습-결과-저장">7.4.2 학습 결과 저장</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">result_hyper</span><span class="p">.</span><span class="n">append</span><span class="p">({</span><span class="s">'Estimator'</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">best_estimator_</span><span class="p">).</span><span class="n">split</span><span class="p">(</span><span class="s">'('</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
           <span class="s">'hyper_mean_train_score'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s">'mean_train_score'</span><span class="p">]).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span>
           <span class="s">'hyper_mean_test_score'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s">'mean_test_score'</span><span class="p">]).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)})</span>
</pre></table></code></div></div><ul><li>전체 모델에 대해 결과를 시각화하기 위해 결과 저장</li></ul><p><br /></p><h4 id="743-예측-및-검증">7.4.3 예측 및 검증</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="n">xgb_hyper_model</span> <span class="o">=</span> <span class="n">gridsearch</span><span class="p">.</span><span class="n">best_estimator_</span>
<span class="n">xgb_hyper_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">xgb_hyper_predict</span> <span class="o">=</span> <span class="n">xgb_hyper_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">model_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">xgb_predict</span><span class="p">)</span>
<span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">xgb_best_model</span><span class="p">,</span>
                    <span class="s">'XGBoosting Learning Curve'</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>


<span class="n">model_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">xgb_hyper_predict</span><span class="p">)</span>
<span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">xgb_hyper_model</span><span class="p">,</span>
                    <span class="s">'XGBoosting Hyperparameter Learning Curve'</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>Accuracy :  0.883
Recall :  0.435
Precision :  0.769
F1_Score :  0.556

Confusion_matrix :
[[221   6]
 [ 26  20]]
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491770-78241800-c3f4-11eb-99ac-fb39855fd601.png" /></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>Accuracy :  0.886
Recall :  0.348
Precision :  0.941
F1_Score :  0.508

Confusion_matrix :
[[226   1]
 [ 30  16]]
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120491775-78bcae80-c3f4-11eb-85bf-618b113688e5.png" /></p><ul><li>파라미터를 사용하여 모델을 생성한 결과 많은 수치는 아니지만 꽤 좋은 성능을 내는 모델이 생성되었습니다.</li><li>Recall의 점수는 떨어졌지만, Precision의 점수는 더욱 올라 F1-score가 좋아졌습니다.</li></ul><p><br /></p><h4 id="744-중요-변수-확인">7.4.4 중요 변수 확인</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">important</span> <span class="o">=</span> <span class="n">xgb_best_model</span><span class="p">.</span><span class="n">feature_importances_</span>
<span class="n">important_hyper</span> <span class="o">=</span> <span class="n">xgb_hyper_model</span><span class="p">.</span><span class="n">feature_importances_</span>

<span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">important</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'important'</span><span class="p">]).</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s">'important'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">rot</span> <span class="o">=</span> <span class="mi">45</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span> <span class="s">'Before Important Feature'</span><span class="p">)</span>
<span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">important_hyper</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'important_hyper'</span><span class="p">]).</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s">'important_hyper'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">rot</span> <span class="o">=</span> <span class="mi">45</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span> <span class="s">'After Important Feature'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120492605-2fb92a00-c3f5-11eb-9e3b-d037c3e80177.png" /></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120492623-321b8400-c3f5-11eb-99cc-d5706f56360c.png" /></p><ul><li>파라미터를 튜닝하기 전과 후의 중요변수를 보면 YearWithCurrManager가 갑자기 상승하였습니다.</li></ul><p><br /></p><h3 id="75-lightgbm">7.5 LightGBM</h3><h4 id="751-튜닝-모델-생성-및-학습">7.5.1 튜닝 모델 생성 및 학습</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre><td class="rouge-code"><pre><span class="n">lgbm_model</span> <span class="o">=</span> <span class="n">LGBMClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">87</span><span class="p">)</span>

<span class="n">params_grid</span> <span class="o">=</span> <span class="p">[{</span>
    <span class="s">'boosting_type'</span><span class="p">:</span> <span class="p">[</span><span class="s">'gbdt'</span><span class="p">,</span> <span class="s">'dart'</span><span class="p">,</span> <span class="s">'rf'</span><span class="p">,</span> <span class="s">'goss'</span><span class="p">],</span> <span class="c1"># 알고리즘 타입
</span>    <span class="s">'num_leaves'</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span> <span class="c1"># 잎사귀의 수
</span>    <span class="s">'max_depth'</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span> <span class="c1"># 깊이의 수
</span>    <span class="s">'reg_alpha'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="c1"># L1 정규화
</span>    <span class="s">'lambda_l1'</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span> <span class="c1"># L1 정규화
</span>    <span class="s">'lambda_l2'</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span> <span class="c1"># L2 정규화
</span><span class="p">}]</span>

<span class="n">gridsearch</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">lgbm_model</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">params_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">gridsearch</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre>[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.1 will be ignored. Current value: lambda_l1=1
[LightGBM] [Warning] lambda_l2 is set=1.5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.5





GridSearchCV(cv=5, estimator=LGBMClassifier(random_state=87), n_jobs=-1,
             param_grid=[{'boosting_type': ['gbdt', 'dart', 'rf', 'goss'],
                          'lambda_l1': [0, 1, 1.5], 'lambda_l2': [0, 1, 1.5],
                          'max_depth': [1, 2, 3, 4, 5, 7, 9, 11],
                          'num_leaves': [5, 10, 20], 'reg_alpha': [0.1, 0.5]}],
             return_train_score=True)
</pre></table></code></div></div><ul><li>그리드 서치를 이용하여 LightGBM의 파라미터를 튜닝 및 최적의 모델을 생성하였습니다.</li><li>파라미터는 boosting_type, num_leaves, max_depth, reg_alpha, lambda_l1, lambda_l2 를 사용했습니다.</li><li>아무래도 트리기반의 모델들은 depth가 중요한 파라미터인듯 합니다.</li></ul><p><br /></p><h4 id="752-학습-결과-저장">7.5.2 학습 결과 저장</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">result_hyper</span><span class="p">.</span><span class="n">append</span><span class="p">({</span><span class="s">'Estimator'</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">best_estimator_</span><span class="p">).</span><span class="n">split</span><span class="p">(</span><span class="s">'('</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
           <span class="s">'hyper_mean_train_score'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s">'mean_train_score'</span><span class="p">]).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span>
           <span class="s">'hyper_mean_test_score'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">gridsearch</span><span class="p">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s">'mean_test_score'</span><span class="p">]).</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)})</span>
</pre></table></code></div></div><ul><li>전체 모델에 대한 결과를 시각화 하기 위해 결과를 저장합니다.</li></ul><p><br /></p><h4 id="753-예측-및-검증">7.5.3 예측 및 검증</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="n">lgbm_hyper_model</span> <span class="o">=</span> <span class="n">gridsearch</span><span class="p">.</span><span class="n">best_estimator_</span>
<span class="n">lgbm_hyper_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">lgbm_hyper_predict</span> <span class="o">=</span> <span class="n">lgbm_hyper_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">model_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">lgbm_predict</span><span class="p">)</span>
<span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">lgbm_best_model</span><span class="p">,</span>
                    <span class="s">'LightGBM Learning Curve'</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">model_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">lgbm_hyper_predict</span><span class="p">)</span>
<span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">lgbm_hyper_model</span><span class="p">,</span>
                    <span class="s">'LightGBM Hyperparmeter Learning Curve'</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>Accuracy :  0.864
Recall :  0.348
Precision :  0.696
F1_Score :  0.464

Confusion_matrix :
[[220   7]
 [ 30  16]]
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120492628-334cb100-c3f5-11eb-8aa6-fd22175831ce.png" /></p><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>Accuracy :  0.861
Recall :  0.304
Precision :  0.7
F1_Score :  0.424

Confusion_matrix :
[[221   6]
 [ 32  14]]
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120492631-334cb100-c3f5-11eb-925f-3251a99a3385.png" /></p><ul><li>이번엔 튜닝을 하여도 성능이 좋아진것 같지 않습니다.</li><li>Learning Curve만 보면 좋아진것 같지만, 그외의 다른것들의 점수가 다 낮아졌습니다.</li><li>사실 LGBM은 데이터가 적으면 큰 성능을 보이지 못합니다. 최소 데이터가 10000개는 있어야 한다고 합니다.</li></ul><p><br /></p><h4 id="754-중요-변수-확인">7.5.4 중요 변수 확인</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">important</span> <span class="o">=</span> <span class="n">lgbm_best_model</span><span class="p">.</span><span class="n">feature_importances_</span>
<span class="n">important_hyper</span> <span class="o">=</span> <span class="n">lgbm_hyper_model</span><span class="p">.</span><span class="n">feature_importances_</span>

<span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">important</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'important'</span><span class="p">]).</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s">'important'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">rot</span> <span class="o">=</span> <span class="mi">45</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span> <span class="s">'Before Important Feature'</span><span class="p">)</span>
<span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">important_hyper</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'important_hyper'</span><span class="p">]).</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s">'important_hyper'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'bar'</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">36</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">rot</span> <span class="o">=</span> <span class="mi">45</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span> <span class="s">'After Important Feature'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120492633-33e54780-c3f5-11eb-81f4-b3b6db30b92e.png" /></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120492637-35167480-c3f5-11eb-8ae0-26dd17102227.png" /></p><ul><li>튜닝을 하여도 큰 변화가 없어서 그런지 중요변수도 크게 변화한것 같지 않습니다.</li><li>그대로 Rate 계열의 변수가 상위권에 있습니다.</li></ul><p><br /></p><h3 id="76-roc-curve-auc">7.6 ROC Curve, AUC</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
</pre><td class="rouge-code"><pre><span class="n">clf_pred_proba</span> <span class="o">=</span> <span class="n">clf_best_model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">clf_fpr</span><span class="p">,</span> <span class="n">clf_tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">clf_pred_proba</span><span class="p">)</span>
<span class="n">clf_roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">clf_pred_proba</span><span class="p">)</span>

<span class="n">clf_hyper_pred_proba</span> <span class="o">=</span> <span class="n">clf_hyper_model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">clf_hyper_fpr</span><span class="p">,</span> <span class="n">clf_hyper_tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">clf_hyper_pred_proba</span><span class="p">)</span>
<span class="n">clf_hyper_roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">clf_hyper_pred_proba</span><span class="p">)</span>

<span class="c1">####
</span>
<span class="n">rf_pred_proba</span> <span class="o">=</span> <span class="n">rf_best_model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">rf_fpr</span><span class="p">,</span> <span class="n">rf_tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf_pred_proba</span><span class="p">)</span>
<span class="n">rf_roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf_pred_proba</span><span class="p">)</span>

<span class="n">rf_hyper_pred_proba</span> <span class="o">=</span> <span class="n">rf_hyper_model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">rf_hyper_fpr</span><span class="p">,</span> <span class="n">rf_hyper_tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf_hyper_pred_proba</span><span class="p">)</span>
<span class="n">rf_hyper_roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rf_hyper_pred_proba</span><span class="p">)</span>

<span class="c1">###
</span>
<span class="n">lr_pred_proba</span> <span class="o">=</span> <span class="n">lr_best_model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">lr_fpr</span><span class="p">,</span> <span class="n">lr_tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">lr_pred_proba</span><span class="p">)</span>
<span class="n">lr_roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">lr_pred_proba</span><span class="p">)</span>

<span class="n">lr_hyper_pred_proba</span> <span class="o">=</span> <span class="n">lr_hyper_model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">lr_hyper_fpr</span><span class="p">,</span> <span class="n">lr_hyper_tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">lr_hyper_pred_proba</span><span class="p">)</span>
<span class="n">lr_hyper_roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">lr_hyper_pred_proba</span><span class="p">)</span>

<span class="c1">###
</span>
<span class="n">xgb_pred_proba</span> <span class="o">=</span> <span class="n">xgb_best_model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">xgb_fpr</span><span class="p">,</span> <span class="n">xgb_tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">xgb_pred_proba</span><span class="p">)</span>
<span class="n">xgb_roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">xgb_pred_proba</span><span class="p">)</span>

<span class="n">xgb_hyper_pred_proba</span> <span class="o">=</span> <span class="n">xgb_hyper_model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">xgb_hyper_fpr</span><span class="p">,</span> <span class="n">xgb_hyper_tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">xgb_hyper_pred_proba</span><span class="p">)</span>
<span class="n">xgb_hyper_roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">xgb_hyper_pred_proba</span><span class="p">)</span>

<span class="c1">###
</span>
<span class="n">lgbm_pred_proba</span> <span class="o">=</span> <span class="n">gridsearch</span><span class="p">.</span><span class="n">best_estimator_</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">lgbm_fpr</span><span class="p">,</span> <span class="n">lgbm_tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">lgbm_pred_proba</span><span class="p">)</span>
<span class="n">lgbm_roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">lgbm_pred_proba</span><span class="p">)</span>

<span class="n">lgbm_hyper_pred_proba</span> <span class="o">=</span> <span class="n">lgbm_hyper_model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">lgbm_hyper_fpr</span><span class="p">,</span> <span class="n">lgbm_hyper_tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">lgbm_hyper_pred_proba</span><span class="p">)</span>
<span class="n">lgbm_hyper_roc_auc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">lgbm_hyper_pred_proba</span><span class="p">)</span>



<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span><span class="mi">12</span><span class="p">))</span>

<span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ax2</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>

<span class="n">ax1</span><span class="p">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">clf_fpr</span><span class="p">,</span> <span class="n">clf_tpr</span><span class="p">,</span>
         <span class="n">label</span><span class="o">=</span><span class="s">'DecisionTree Roc Auc Score (area = %0.2f)'</span> <span class="o">%</span> <span class="n">clf_roc_auc</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">rf_fpr</span><span class="p">,</span> <span class="n">rf_tpr</span><span class="p">,</span>
         <span class="n">label</span><span class="o">=</span><span class="s">'RandomForest Roc Auc Score (area = %0.2f)'</span> <span class="o">%</span> <span class="n">rf_roc_auc</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_fpr</span><span class="p">,</span> <span class="n">lr_tpr</span><span class="p">,</span>
         <span class="n">label</span><span class="o">=</span><span class="s">'LogisticRegression Roc Auc Score (area = %0.2f)'</span> <span class="o">%</span> <span class="n">lr_roc_auc</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xgb_fpr</span><span class="p">,</span> <span class="n">xgb_tpr</span><span class="p">,</span>
         <span class="n">label</span><span class="o">=</span><span class="s">'XGBoosting Roc Auc Score (area = %0.2f)'</span> <span class="o">%</span> <span class="n">xgb_roc_auc</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lgbm_fpr</span><span class="p">,</span> <span class="n">lgbm_tpr</span><span class="p">,</span>
         <span class="n">label</span><span class="o">=</span><span class="s">'LightLGBM Roc Auc Score (area = %0.2f)'</span> <span class="o">%</span> <span class="n">lgbm_roc_auc</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'Before Hyperparameter Tuning'</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">ax1</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">"lower right"</span><span class="p">)</span>

<span class="n">ax2</span><span class="p">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">clf_hyper_fpr</span><span class="p">,</span> <span class="n">clf_hyper_tpr</span><span class="p">,</span>
         <span class="n">label</span><span class="o">=</span><span class="s">'DecisionTree Roc Auc Score (area = %0.2f)'</span> <span class="o">%</span> <span class="n">clf_hyper_roc_auc</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">rf_hyper_fpr</span><span class="p">,</span> <span class="n">rf_hyper_tpr</span><span class="p">,</span>
         <span class="n">label</span><span class="o">=</span><span class="s">'RandomForest Roc Auc Score (area = %0.2f)'</span> <span class="o">%</span> <span class="n">rf_hyper_roc_auc</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_hyper_fpr</span><span class="p">,</span> <span class="n">lr_hyper_tpr</span><span class="p">,</span>
         <span class="n">label</span><span class="o">=</span><span class="s">'LogisticRegression Roc Auc Score (area = %0.2f)'</span> <span class="o">%</span> <span class="n">lr_hyper_roc_auc</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xgb_hyper_fpr</span><span class="p">,</span> <span class="n">xgb_hyper_tpr</span><span class="p">,</span>
         <span class="n">label</span><span class="o">=</span><span class="s">'XGBoosting Roc Auc Score (area = %0.2f)'</span> <span class="o">%</span> <span class="n">xgb_hyper_roc_auc</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lgbm_hyper_fpr</span><span class="p">,</span> <span class="n">lgbm_hyper_tpr</span><span class="p">,</span>
         <span class="n">label</span><span class="o">=</span><span class="s">'LightLGBM Roc Auc Score (area = %0.2f)'</span> <span class="o">%</span> <span class="n">lgbm_hyper_roc_auc</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'After Hyperparameter Tuning'</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">ax2</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">"lower right"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120492642-35af0b00-c3f5-11eb-8768-abdd919e0fbf.png" /></p><ul><li>파라미터 튜닝 후 전체적으로 성능이 좋아진것을 알수 있습니다.</li></ul><p><br /></p><h4 id="77-validation-score-확인">7.7 Validation Score 확인</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">result_hyper</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">df2</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">'Estimator'</span><span class="p">)</span>

<span class="n">df</span><span class="p">.</span><span class="n">plot</span><span class="p">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'Estimator'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="p">[</span>
                   <span class="s">'mean_test_score'</span><span class="p">,</span> <span class="s">'hyper_mean_test_score'</span><span class="p">],</span> <span class="n">rot</span><span class="o">=</span><span class="mi">360</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">title</span> <span class="o">=</span> <span class="s">'Test Score Compare'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'lower left'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/120492648-3647a180-c3f5-11eb-94a6-e5269a9fc821.png" /></p><ul><li>의사결정나무를 제외하고는 파라미터를 수정하여 Accuracy가 눈에띄게 좋아진것은 없습니다.</li><li>하지만 Accuracy만이 모델의 성능을 측정하는 지표는 아니며, Accuracy가 비슷하거나 조금 떨어졌지만, 그외의 지표들이 높아졌으니, 성능에 개선에 있었다고 이야기할수 있습니다.</li></ul><p><br /></p><h2 id="8-회고">8. 회고</h2><hr /><h3 id="81-회고">8.1 회고</h3><ul><li>만일 데이터가 더 많았다면, 성능을 더 많이 올릴수 있을것 같았는데 아쉽습니다.</li><li>해당 내용에는 없지만 SMOTE를 사용하여 오버샘플링을 해보았지만, 오버샘플링의 단점인 과적합에 빠져, 오히려 검증시에는 성능이 안좋게 나왔습니다.</li><li>그래도 각 알고리즘별로 파라미터 튜닝을 실습해보고 했던것에 만족합니다.</li><li>많은 시간을 할애하여 진행했던 프로젝트지만 목표 Accuray는 0.9에 근접하게 나오긴 했지만 넘지는 못하여 아쉽습니다.</li><li>추후에 같은 데이터를 딥러닝에 적용하여 해봐야 겠습니다.</li></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/data-science/'>Data Science</a>, <a href='/categories/machine-learning/'>Machine Learning</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/xgboost/" class="post-tag no-text-decoration" >XGBoost</a> <a href="/tags/random-forest/" class="post-tag no-text-decoration" >Random Forest</a> <a href="/tags/logistic-regression/" class="post-tag no-text-decoration" >Logistic Regression</a> <a href="/tags/lightgbm/" class="post-tag no-text-decoration" >LightGBM</a> <a href="/tags/decision-tree/" class="post-tag no-text-decoration" >Decision Tree</a> <a href="/tags/gridsearch/" class="post-tag no-text-decoration" >GridSearch</a> <a href="/tags/hyperparameter-tuning/" class="post-tag no-text-decoration" >HyperParameter Tuning</a> <a href="/tags/eda/" class="post-tag no-text-decoration" >EDA</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><!-- Post sharing snippet v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=IBM HR Data로 해보는 퇴사자 예측 - Data Include Me&url=https://datainclude.me/posts/IBM_HR_Data%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_%ED%87%B4%EC%82%AC%EC%9E%90_%EC%98%88%EC%B8%A1/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=IBM HR Data로 해보는 퇴사자 예측 - Data Include Me&u=https://datainclude.me/posts/IBM_HR_Data%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_%ED%87%B4%EC%82%AC%EC%9E%90_%EC%98%88%EC%B8%A1/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=IBM HR Data로 해보는 퇴사자 예측 - Data Include Me&url=https://datainclude.me/posts/IBM_HR_Data%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_%ED%87%B4%EC%82%AC%EC%9E%90_%EC%98%88%EC%B8%A1/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><!-- The Panel on right side (Desktop views) v2.3 © 2024 Your Name MIT License --><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><h3 data-toc-skip>Recent Update</h3><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li class="recent-item"> <a href="/posts/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C_%EC%BB%B4%ED%93%A8%ED%8C%85_%EA%B0%80%EC%83%81%ED%99%94/">클라우드 컴퓨팅 - 가상화</a> <span class="text-muted small">2024-10-28</span></li><li class="recent-item"> <a href="/posts/gemini_api_%EC%82%AC%EC%9A%A9%ED%95%B4%EB%B3%B4%EA%B8%B0/">Gemini API 사용해보기</a> <span class="text-muted small">2024-03-12</span></li><li class="recent-item"> <a href="/posts/Ollama%EC%99%80_Python_%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC_LLaMa2%EB%A5%BC_%EB%A1%9C%EC%BB%AC%EC%97%90%EC%84%9C_%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/">Ollama와 Python 라이브러리를 이용하여 LLaMa2를 로컬에서 사용하기</a> <span class="text-muted small">2024-02-13</span></li><li class="recent-item"> <a href="/posts/Mistral_7B_Fine_Tuning/">Mistral 7B 파인튜닝(Fine Tuning)하기</a> <span class="text-muted small">2023-10-25</span></li><li class="recent-item"> <a href="/posts/Penn_Fudan%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EA%B0%9D%EC%B2%B4_%ED%83%90%EC%A7%80_%EB%B6%84%ED%95%A0/">Penn-Fudan으로 알아보는 객체 탐지(Object Detection), 분할(Segmentation) with FasterRCNN</a> <span class="text-muted small">2023-10-23</span></li></ul></div><div id="access-tags"><h3 data-toc-skip>Trending Tags</h3><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/tensorflow/">Tensorflow</a> <a class="post-tag" href="/tags/sklearn/">Sklearn</a> <a class="post-tag" href="/tags/round/">Round</a> <a class="post-tag" href="/tags/python-lv0/">Python Lv0</a> <a class="post-tag" href="/tags/pca/">PCA</a> <a class="post-tag" href="/tags/eda/">EDA</a> <a class="post-tag" href="/tags/distinct/">Distinct</a> <a class="post-tag" href="/tags/random-forest/">Random Forest</a> <a class="post-tag" href="/tags/beautifulsoup/">Beautifulsoup</a> <a class="post-tag" href="/tags/baekjoon/">Baekjoon</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><h3 data-toc-skip class="pl-3 pt-2 mb-2">Contents</h3><nav id="toc" data-toggle="toc"></nav></div></div><style> .recent-item { margin-bottom: 0.5rem; } .recent-item a { color: var(--link-color); } .recent-item .small { font-size: 0.75rem; margin-left: 0.5rem; }</style></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"> <!-- Recommend the other 3 posts according to the tags and categories of the current post, if the number is not enough, use the other latest posts to supplement. v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%EC%9D%84_%EC%9D%B4%EC%9A%A9%ED%95%9C_%ED%83%80%EC%9D%B4%ED%83%80%EB%8B%89_%EC%83%9D%EC%A1%B4%EC%9E%90_%EC%98%88%EC%B8%A1/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Oct 17, 2020 <i class="unloaded">2020-10-17T09:10:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>머신러닝을 이용한 타이타닉 생존자 예측</h3><div class="text-muted small"><p> 1. 타이타닉 EDA 1.1 데이터 로드 import pandas as pd titanic = pd.read_excel('https://github.com/hmkim312/datas/blob/main/titanic/titanic.xls?raw=true') titanic.head() pclass ...</p></div></div></a></div><div class="card"> <a href="/posts/%EC%95%99%EC%83%81%EB%B8%94(ensemble)/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Oct 13, 2020 <i class="unloaded">2020-10-13T09:10:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>앙상블(Ensemble)</h3><div class="text-muted small"><p> 1. 앙상블 기법 1.1 앙상블 기법 앙상블 학습을 통한 분류 : 여러 개의 분류기를 생성하고 그 예측을 결합하여 정확한 최종 예측을 기대하는 기법 앙상블 학습의 목표 : 다양한 분류기의 예측 결과를 결합함으로써 단일 분류기보다 신뢰성이 높은 예측 값을 얻는 것 정형 데이터를 대상으로 하는 분류기에서는 앙상블 기법이 뛰어난 성과를 보여...</p></div></div></a></div><div class="card"> <a href="/posts/HAR_%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_GBM,_XGBoost,_LightGBM/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Oct 23, 2020 <i class="unloaded">2020-10-23T10:10:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>HAR 데이터로 해보는 GBM, XGBoost, LightGBM</h3><div class="text-muted small"><p> 1. GBM - Gradient Boosting Machine 1.1 GBM 부스팅 알고리즘은 여러 개의 약한 학습기를 순차적으로 학습 예측하면서 잘못 예측한 데이터에 가중치를 부여해서 오류를 개선해 나가는 방식 GBM은 가중치를 업데이트할때 경사 하강법을 사용하는것이 큰 차이 1.2 HAR 데이터로 실습 import pandas...</p></div></div></a></div></div></div><!-- Navigation buttons at the bottom of the post. v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --><div class="post-navigation d-flex justify-content-between"> <a href="/posts/%ED%94%84%EB%A6%B0%ED%84%B0/" class="btn btn-outline-primary"><p>프린터 [Python]</p></a> <a href="/posts/Clustering_on_numerical_and_categorical_features/" class="btn btn-outline-primary"><p>Numerical and Categorical Features의 Clustering 방법</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('#post-wrapper img'); const observer = lozad(imgs); observer.observe(); </script></div><!-- The Search results v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/tensorflow/">Tensorflow</a> <a class="post-tag" href="/tags/sklearn/">Sklearn</a> <a class="post-tag" href="/tags/round/">Round</a> <a class="post-tag" href="/tags/python-lv0/">Python Lv0</a> <a class="post-tag" href="/tags/pca/">PCA</a> <a class="post-tag" href="/tags/eda/">EDA</a> <a class="post-tag" href="/tags/distinct/">Distinct</a> <a class="post-tag" href="/tags/random-forest/">Random Forest</a> <a class="post-tag" href="/tags/beautifulsoup/">Beautifulsoup</a> <a class="post-tag" href="/tags/baekjoon/">Baekjoon</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <!-- The GA snippet v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <!-- Jekyll Simple Search loader v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://datainclude.me{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script>
