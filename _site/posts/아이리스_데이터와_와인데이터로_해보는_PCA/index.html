<!DOCTYPE html><html lang="ko" mode="light" > <!-- The Head v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>아이리스 데이터와 와인데이터로 해보는 PCA | Data Include Me</title><meta name="generator" content="Jekyll v3.9.3" /><meta property="og:title" content="아이리스 데이터와 와인데이터로 해보는 PCA" /><meta name="author" content="HyunMin Kim" /><meta property="og:locale" content="ko" /><meta name="description" content="1. PCA 1.1 PCA란?" /><meta property="og:description" content="1. PCA 1.1 PCA란?" /><link rel="canonical" href="https://datainclude.me/posts/%EC%95%84%EC%9D%B4%EB%A6%AC%EC%8A%A4_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%99%80_%EC%99%80%EC%9D%B8%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_PCA/" /><meta property="og:url" content="https://datainclude.me/posts/%EC%95%84%EC%9D%B4%EB%A6%AC%EC%8A%A4_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%99%80_%EC%99%80%EC%9D%B8%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_PCA/" /><meta property="og:site_name" content="Data Include Me" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-10-23T12:10:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="아이리스 데이터와 와인데이터로 해보는 PCA" /><meta name="twitter:site" content="@" /><meta name="twitter:creator" content="@HyunMin Kim" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"HyunMin Kim"},"dateModified":"2020-10-23T12:10:00+09:00","datePublished":"2020-10-23T12:10:00+09:00","description":"1. PCA 1.1 PCA란?","headline":"아이리스 데이터와 와인데이터로 해보는 PCA","mainEntityOfPage":{"@type":"WebPage","@id":"https://datainclude.me/posts/%EC%95%84%EC%9D%B4%EB%A6%AC%EC%8A%A4_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%99%80_%EC%99%80%EC%9D%B8%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_PCA/"},"url":"https://datainclude.me/posts/%EC%95%84%EC%9D%B4%EB%A6%AC%EC%8A%A4_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%99%80_%EC%99%80%EC%9D%B8%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_PCA/"}</script><meta property="og:image" content="https://datainclude.me/assets/img/sample/avatar.jpg" /> <!-- The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps Generated by: https://www.favicon-generator.org/ v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT license --><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="36x36" href="/assets/img/favicons/android-icon-36x36.png"><link rel="icon" type="image/png" sizes="48x48" href="/assets/img/favicons/android-icon-48x48.png"><link rel="icon" type="image/png" sizes="72x72" href="/assets/img/favicons/android-icon-72x72.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/android-icon-96x96.png"><link rel="icon" type="image/png" sizes="144x144" href="/assets/img/favicons/android-icon-144x144.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="70x70" href="/assets/img/favicons/ms-icon-70x70.png"><link rel="icon" type="image/png" sizes="144x144" href="/assets/img/favicons/ms-icon-144x144.png"><link rel="icon" type="image/png" sizes="150x150" href="/assets/img/favicons/ms-icon-150x150.png"><link rel="icon" type="image/png" sizes="310x310" href="/assets/img/favicons/ms-icon-310x310.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preload" href="https://www.googletagmanager.com/gtm.js?id=GTM-MW9VRMW9" as="script"> <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src= 'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f); })(window,document,'script','dataLayer','GTM-MW9VRMW9');</script><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="preload" as="style" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous" media="print" onload="this.media='all'"> <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"> </noscript> <!-- CSS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --><link rel="preload" as="style" href="/assets/css/post.css"><link rel="stylesheet" href="/assets/css/post.css"><link rel="preload" as="style" href="/assets/css/lib/bootstrap-toc.min.css"><link rel="stylesheet" href="/assets/css/lib/bootstrap-toc.min.css" /><link rel="preload" as="script" href="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" async></script> <!-- JS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --> <script src="/assets/js/post.min.js" async></script> <script src="/app.js" defer></script><body data-spy="scroll" data-target="#toc"> <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MW9VRMW9" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div id="sidebar" class="d-flex flex-column"> <!-- The Side Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="nav-wrapper"><div id="profile-wrapper" class="d-flex flex-column"><div id="avatar" class="d-flex justify-content-center"> <a href="/" alt="avatar"> <img src="/assets/img/sample/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="profile-text mt-3"><div class="site-title"> <a href="/">Data Include Me</a></div><div class="site-subtitle font-italic">Data Science Blog</div></div></div><ul class="nav flex-column"><li class="nav-item d-flex justify-content-center "> <a href="/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/categories/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/tags/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/archives/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/about/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></li></ul></div><div class="sidebar-bottom d-flex flex-wrap justify-content-around mt-4"> <a href="https://github.com/hmkim312" target="_blank"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/" target="_blank"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:window.open('mailto:' + ['sanarial312','gmail.com'].join('@'))" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" > <i class="fas fa-rss"></i> </a></div></div><!-- The Top Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>아이리스 데이터와 와인데이터로 해보는 PCA</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"> <!-- Refactor the HTML structure. --> <!-- Suroundding the markdown table with '<div class="table-wrapper">. and '</div>' --> <!-- Fixed kramdown code highlight rendering: https://github.com/penibelst/jekyll-compress-html/issues/101 https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901 --><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"> <script type="text/javascript"> var lazyloadads = false; function loadAds() { if (!lazyloadads) { var script = document.createElement("script"); script.type = "text/javascript"; script.async = true; script.src = "https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7594406644928408"; document.body.appendChild(script); lazyloadads = true; } } window.addEventListener("mousemove", loadAds, { once: true }); window.addEventListener('touchstart', loadAds, { once: true }); </script><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>아이리스 데이터와 와인데이터로 해보는 PCA</h1><div class="post-meta text-muted d-flex flex-column"><div> Posted <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Fri, Oct 23, 2020, 12:10 PM +0900" > Oct 23, 2020 <i class="unloaded">2020-10-23T12:10:00+09:00</i> </span> by <span class="author"> HyunMin Kim </span></div><a href="https://hits.seeyoufarm.com"> <img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https://datainclude.me/posts/%EC%95%84%EC%9D%B4%EB%A6%AC%EC%8A%A4_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%99%80_%EC%99%80%EC%9D%B8%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_PCA/%2F&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=views&edge_flat=false" alt="페이지 조회수 뱃지", width: 100%;, height: 100%;/> </a></div><div class="post-content"><h2 id="1-pca">1. PCA</h2><hr /><h3 id="11-pca란">1.1 PCA란?</h3><ul><li>데이터 집합 내에 존재하는 각 데이터의 차이를 가장 잘 나타내주는 요소를 찾아 내는 방법</li><li>통계 데이터 분석(주성분 분석), 데이터 압축(차원 감소), 노이즈 제거 등 다양한 분야에서 사용</li></ul><p><br /></p><h3 id="12-간단한-pca의-개념">1.2 간단한 PCA의 개념</h3><ul><li>주성분 분석 : 차원축소와 변수추출 기법으로 널리 쓰이고 있음</li><li>데이터의 분산을 최대한 보존하면서 서로 직교하는 새 기저(축)를 찾가, 고차원 공간의 표본들을 선형 연관성이 없는 저차원 공간으로 변환하는 기법</li><li>변수추출 : 기존 변수를 조합해 새로운 변수를 만드는 기법(변수 선택)과 구분해야 함</li></ul><p><br /></p><h3 id="13-고유값과-고유벡터">1.3 고유값과 고유벡터</h3><ul><li>임의의 n × n 행렬 A 에 대하여, 0이 아닌 솔루션 벡터 x가 존재한다면 숫자 λ는 행렬 A의 고유값라고 할 수 있다.</li><li>Ax = λx</li><li>이 때, 솔루션 벡터 x는 고유값 λ에 대응하는 고유벡터이다.</li></ul><p><br /></p><h3 id="14-코드로-실습">1.4 코드로 실습</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">array</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">mean</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">cov</span>
<span class="kn">from</span> <span class="nn">numpy.linalg</span> <span class="kn">import</span> <span class="n">eig</span>

<span class="c1"># 매트릭스 정의
</span><span class="n">A</span> <span class="o">=</span> <span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="k">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>[[1 2]
 [3 4]
 [5 6]]
</pre></table></code></div></div><p><br /></p><h4 id="141-평균-계산">1.4.1 평균 계산</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">M</span> <span class="o">=</span> <span class="n">mean</span><span class="p">(</span><span class="n">A</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">M</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>[3. 4.]
</pre></table></code></div></div><p><br /></p><h4 id="142-원-행렬에서-평균을-뺌">1.4.2 원 행렬에서 평균을 뺌</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">C</span> <span class="o">=</span> <span class="n">A</span> <span class="o">-</span> <span class="n">M</span>
<span class="k">print</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>[[-2. -2.]
 [ 0.  0.]
 [ 2.  2.]]
</pre></table></code></div></div><p><br /></p><h4 id="143-공분산-행렬을-찾음">1.4.3 공분산 행렬을 찾음</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">V</span> <span class="o">=</span> <span class="n">cov</span><span class="p">(</span><span class="n">C</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">V</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>[[4. 4.]
 [4. 4.]]
</pre></table></code></div></div><p><br /></p><h4 id="144-고유값과-고유벡터를-계산">1.4.4 고유값과 고유벡터를 계산</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">values</span><span class="p">,</span> <span class="n">vectors</span> <span class="o">=</span> <span class="n">eig</span><span class="p">(</span><span class="n">V</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>[[ 0.70710678 -0.70710678]
 [ 0.70710678  0.70710678]]
[8. 0.]
</pre></table></code></div></div><p><br /></p><h4 id="145-고유벡터에-다시-원데이터를-투영">1.4.5 고유벡터에 다시 원데이터를 투영</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">P</span> <span class="o">=</span> <span class="n">vectors</span><span class="p">.</span><span class="n">T</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">C</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">P</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>[[-2.82842712  0.        ]
 [ 0.          0.        ]
 [ 2.82842712  0.        ]]
</pre></table></code></div></div><p><br /></p><h4 id="146-pca를-사용하여-한번에-하기">1.4.6 PCA를 사용하여 한번에 하기</h4><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">array</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="c1"># PCA 객체 생성
</span><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># data 적용
</span><span class="n">pca</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="c1"># 고유값과 고유벡터
</span><span class="k">print</span><span class="p">(</span><span class="n">pca</span><span class="p">.</span><span class="n">components_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">pca</span><span class="p">.</span><span class="n">explained_variance_</span><span class="p">)</span>
<span class="k">print</span><span class="p">()</span>

<span class="c1"># 고유벡터에 다시 원데이터 투영
</span><span class="n">B</span> <span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre>[[ 0.70710678  0.70710678]
 [ 0.70710678 -0.70710678]]
[8.00000000e+00 2.25080839e-33]

[[-2.82842712e+00  2.22044605e-16]
 [ 0.00000000e+00  0.00000000e+00]
 [ 2.82842712e+00 -2.22044605e-16]]
</pre></table></code></div></div><p><br /></p><h2 id="2-sklearn을-이용하여-연습">2. sklearn을 이용하여 연습</h2><hr /><h3 id="21-데이터-만들기">2.1 데이터 만들기</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="n">sns</span><span class="p">.</span><span class="n">set_style</span><span class="p">(</span><span class="s">'whitegrid'</span><span class="p">)</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">13</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">rng</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">rng</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">200</span><span class="p">)).</span><span class="n">T</span>
<span class="n">X</span><span class="p">.</span><span class="n">shape</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>(200, 2)
</pre></table></code></div></div><p><br /></p><h3 id="22-데이터의-생김새">2.2 데이터의 생김새</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'equal'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/97006872-73080c00-157b-11eb-9563-959ff6ac19a3.png" /></p><p><br /></p><h3 id="23-pca-fit">2.3 PCA fit</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">pca</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>PCA(n_components=2, random_state=13)
</pre></table></code></div></div><p><br /></p><h3 id="24-벡터와-분산값">2.4 벡터와 분산값</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">pca</span><span class="p">.</span><span class="n">components_</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>array([[ 0.47802511,  0.87834617],
       [-0.87834617,  0.47802511]])
</pre></table></code></div></div><ul><li>벡터는 components_ 로 확인</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">pca</span><span class="p">.</span><span class="n">explained_variance_</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>array([1.82531406, 0.13209947])
</pre></table></code></div></div><ul><li>분산값은 explained_variance_로 확인</li></ul><p><br /></p><h3 id="25-주성분-벡터를-그릴-함수-작성">2.5 주성분 벡터를 그릴 함수 작성</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">draw_vector</span><span class="p">(</span><span class="n">v0</span><span class="p">,</span> <span class="n">v1</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span> <span class="ow">or</span> <span class="n">plt</span><span class="p">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">arrowprops</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">arrowstyle</span><span class="o">=</span><span class="s">'-&gt;'</span><span class="p">,</span>
                      <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'black'</span><span class="p">,</span>
                      <span class="n">shrinkA</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shrinkB</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">annotate</span><span class="p">(</span><span class="s">''</span><span class="p">,</span> <span class="n">v1</span><span class="p">,</span> <span class="n">v0</span><span class="p">,</span> <span class="n">arrowprops</span><span class="o">=</span><span class="n">arrowprops</span><span class="p">)</span>
</pre></table></code></div></div><p><br /></p><h3 id="26-그리기">2.6 그리기</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="k">for</span> <span class="n">length</span><span class="p">,</span> <span class="n">vector</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">pca</span><span class="p">.</span><span class="n">explained_variance_</span><span class="p">,</span> <span class="n">pca</span><span class="p">.</span><span class="n">components_</span><span class="p">):</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">vector</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">length</span><span class="p">)</span>
    <span class="n">draw_vector</span><span class="p">(</span><span class="n">pca</span><span class="p">.</span><span class="n">mean_</span><span class="p">,</span> <span class="n">pca</span><span class="p">.</span><span class="n">mean_</span> <span class="o">+</span> <span class="n">v</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'equal'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/97006875-74393900-157b-11eb-8410-f2cfdba047a6.png" /></p><p><br /></p><h3 id="27-n_components를-1로-두고-해보기">2.7 n_components를 1로 두고 해보기</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">pca</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">pca</span><span class="p">.</span><span class="n">components_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">pca</span><span class="p">.</span><span class="n">explained_variance_</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>[[0.47802511 0.87834617]]
[1.82531406]
</pre></table></code></div></div><p><br /></p><h3 id="28-linear-regression과-비슷해-보임">2.8 Linear regression과 비슷해 보임</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="n">X_new</span> <span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">X_pca</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_new</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_new</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">'equal'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/97006878-74d1cf80-157b-11eb-94ab-c0aeef00364f.png" /></p><p><br /></p><h2 id="3-iris-data-로-실습">3. Iris data 로 실습</h2><hr /><h3 id="31-data-load">3.1 Data load</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>

<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>

<span class="n">iris_pd</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">iris</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">iris</span><span class="p">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">iris_pd</span><span class="p">[</span><span class="s">'species'</span><span class="p">]</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">target</span>
<span class="n">iris_pd</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></table></code></div></div><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>sepal length (cm)<th>sepal width (cm)<th>petal length (cm)<th>petal width (cm)<th>species<tbody><tr><th>0<td>5.1<td>3.5<td>1.4<td>0.2<td>0<tr><th>1<td>4.9<td>3.0<td>1.4<td>0.2<td>0<tr><th>2<td>4.7<td>3.2<td>1.3<td>0.2<td>0</table></div><p><br /></p><h3 id="32-특성-4개를-pairplot으로-확인해보기">3.2 특성 4개를 pairplot으로 확인해보기</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="n">sns</span><span class="p">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">iris_pd</span><span class="p">,</span> <span class="n">hue</span> <span class="o">=</span> <span class="s">'species'</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
            <span class="n">x_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s">'sepal length (cm)'</span><span class="p">,</span> <span class="s">'petal width (cm)'</span><span class="p">],</span>
            <span class="n">y_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s">'petal length (cm)'</span><span class="p">,</span> <span class="s">'sepal width (cm)'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/97006879-756a6600-157b-11eb-887b-7eb2cf5441b0.png" /></p><ul><li>이렇게 보면 어떤 특성을 가지고 있는지 알아보기 좀 힘든듯 싶다.</li></ul><p><br /></p><h3 id="33-scaler-적용">3.3 Scaler 적용</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="n">iris_ss</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">().</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">iris</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>
<span class="n">iris_ss</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>array([[-0.90068117,  1.01900435, -1.34022653, -1.3154443 ],
       [-1.14301691, -0.13197948, -1.34022653, -1.3154443 ],
       [-1.38535265,  0.32841405, -1.39706395, -1.3154443 ]])
</pre></table></code></div></div><p><br /></p><h3 id="34-pca결과를-return하는-함수-작성">3.4 Pca결과를 return하는 함수 작성</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="k">def</span> <span class="nf">get_pca_data</span><span class="p">(</span><span class="n">ss_data</span><span class="p">,</span> <span class="n">n_components</span> <span class="o">=</span> <span class="mi">2</span><span class="p">):</span>
    <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">n_components</span><span class="p">)</span>
    <span class="n">pca</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">ss_data</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">pca</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">ss_data</span><span class="p">),</span> <span class="n">pca</span>
</pre></table></code></div></div><p><br /></p><h3 id="35-pca-함수-적용">3.5 pca 함수 적용</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">iris_pca</span><span class="p">,</span> <span class="n">pca</span> <span class="o">=</span> <span class="n">get_pca_data</span><span class="p">(</span><span class="n">iris_ss</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">iris_pca</span><span class="p">.</span><span class="n">shape</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>(150, 2)
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">pca</span><span class="p">.</span><span class="n">mean_</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>array([-1.69031455e-15, -1.84297022e-15, -1.69864123e-15, -1.40924309e-15])
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">pca</span><span class="p">.</span><span class="n">components_</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>array([[ 0.52106591, -0.26934744,  0.5804131 ,  0.56485654],
       [ 0.37741762,  0.92329566,  0.02449161,  0.06694199]])
</pre></table></code></div></div><p><br /></p><h3 id="36-pca-결과를-dataframe으로-변환하는-함수-생성">3.6 Pca 결과를 dataframe으로 변환하는 함수 생성</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">get_pd_from_pca</span><span class="p">(</span><span class="n">pca_data</span><span class="p">,</span> <span class="n">cols</span><span class="o">=</span><span class="p">[</span><span class="s">'pca_component_1'</span><span class="p">,</span> <span class="s">'pca_component_2'</span><span class="p">]):</span>
    <span class="k">return</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">pca_data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">cols</span><span class="p">)</span>
</pre></table></code></div></div><p><br /></p><h3 id="37-2개의-특성으로-pca한것의-dataframe">3.7 2개의 특성으로 pca한것의 DataFrame</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">iris_pd_pca</span> <span class="o">=</span>  <span class="n">get_pd_from_pca</span><span class="p">(</span><span class="n">iris_pca</span><span class="p">)</span>
<span class="n">iris_pd_pca</span><span class="p">[</span><span class="s">'species'</span><span class="p">]</span> <span class="o">=</span> <span class="n">iris</span><span class="p">.</span><span class="n">target</span>
<span class="n">iris_pd_pca</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></table></code></div></div><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>pca_component_1<th>pca_component_2<th>species<tbody><tr><th>0<td>-2.264703<td>0.480027<td>0<tr><th>1<td>-2.080961<td>-0.674134<td>0<tr><th>2<td>-2.364229<td>-0.341908<td>0</table></div><ul><li>원래 4개의 특성을 가지고 있던 데이터를 pca하여 2개의 특성으로 압축시킨것</li></ul><p><br /></p><h3 id="38-pca한-특성-그려보기">3.8 Pca한 특성 그려보기</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">sns</span><span class="p">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">iris_pd_pca</span><span class="p">,</span> <span class="n">hue</span> <span class="o">=</span> <span class="s">'species'</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
            <span class="n">x_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s">'pca_component_1'</span><span class="p">],</span> <span class="n">y_vars</span> <span class="o">=</span> <span class="s">'pca_component_2'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/97006883-7602fc80-157b-11eb-8bbf-5732a25cd6b1.png" /></p><p><br /></p><h3 id="39-pca한-데이터의-설명력">3.9 PCA한 데이터의 설명력</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">print_variance_ratio</span><span class="p">(</span><span class="n">pca</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'variance_ratio: '</span><span class="p">,</span> <span class="n">pca</span><span class="p">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'sum of variance_ratio: '</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">pca</span><span class="p">.</span><span class="n">explained_variance_ratio_</span><span class="p">))</span>
<span class="n">print_variance_ratio</span><span class="p">(</span><span class="n">pca</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>variance_ratio:  [0.72962445 0.22850762]
sum of variance_ratio:  0.9581320720000164
</pre></table></code></div></div><ul><li>2개의 주성분으로 압축한 데이터는 기존 데이터의 95.8%의 설명력을 가진다.</li></ul><p><br /></p><h3 id="310-4개의-특성을-모두-사용한-randomforest">3.10 4개의 특성을 모두 사용한 Randomforest</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="k">def</span> <span class="nf">rf_scores</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">5</span><span class="p">):</span>
    <span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">scores_rf</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">rf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'accuracy'</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span><span class="p">)</span>
    
    <span class="k">print</span><span class="p">(</span><span class="s">'Score : '</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores_rf</span><span class="p">))</span>
    
<span class="n">rf_scores</span><span class="p">(</span><span class="n">iris_ss</span><span class="p">,</span> <span class="n">iris</span><span class="p">.</span><span class="n">target</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>Score :  0.96
</pre></table></code></div></div><ul><li>iris데이터의 4개의 모든 특성을 적용하여 RandomForest를 적용하면 accuracy는 0.96 나온다.</li></ul><p><br /></p><h3 id="311-pca를-한-데이터를-사용한-randomforest">3.11 PCA를 한 데이터를 사용한 Randomforest</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">pca_X</span> <span class="o">=</span> <span class="n">iris_pd_pca</span><span class="p">[[</span><span class="s">'pca_component_1'</span><span class="p">,</span> <span class="s">'pca_component_2'</span><span class="p">]]</span>

<span class="n">rf_scores</span><span class="p">(</span><span class="n">pca_X</span><span class="p">,</span> <span class="n">iris</span><span class="p">.</span><span class="n">target</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>Score :  0.9066666666666666
</pre></table></code></div></div><ul><li>2개의 데이터로 PCA한 iris 데이터의 accuracy는 0.9정도 나온다</li><li>아무래도 PCA를 하여서 조금이라도 데이터의 손실이 있었기에, 기존의 4개의 특성을 사용했을떄보단 accuracy는 작게 나온다</li><li>그래도 4개의 특성을 절반을 줄여 0.96의 accuracy에서 0.9의 accuracy가 나온것은 괜찮은 성과라고 생각해도 될듯 하다.(개인차 있음)</li></ul><p><br /></p><h2 id="4-wine-data로-실습">4. Wine data로 실습</h2><hr /><h3 id="41-data-load">4.1 Data load</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="n">wine_url</span> <span class="o">=</span> <span class="s">'https://raw.githubusercontent.com/PinkWink/ML_tutorial/master/dataset/wine.csv'</span>

<span class="n">wine</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">wine_url</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">wine</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</pre></table></code></div></div><div style="width:100%; height:200px; overflow:auto"><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>fixed acidity<th>volatile acidity<th>citric acid<th>residual sugar<th>chlorides<th>free sulfur dioxide<th>total sulfur dioxide<th>density<th>pH<th>sulphates<th>alcohol<th>quality<th>color<tbody><tr><th>0<td>7.4<td>0.70<td>0.00<td>1.9<td>0.076<td>11.0<td>34.0<td>0.9978<td>3.51<td>0.56<td>9.4<td>5<td>1<tr><th>1<td>7.8<td>0.88<td>0.00<td>2.6<td>0.098<td>25.0<td>67.0<td>0.9968<td>3.20<td>0.68<td>9.8<td>5<td>1<tr><th>2<td>7.8<td>0.76<td>0.04<td>2.3<td>0.092<td>15.0<td>54.0<td>0.9970<td>3.26<td>0.65<td>9.8<td>5<td>1<tr><th>3<td>11.2<td>0.28<td>0.56<td>1.9<td>0.075<td>17.0<td>60.0<td>0.9980<td>3.16<td>0.58<td>9.8<td>6<td>1<tr><th>4<td>7.4<td>0.70<td>0.00<td>1.9<td>0.076<td>11.0<td>34.0<td>0.9978<td>3.51<td>0.56<td>9.4<td>5<td>1</table></div><p><br /></p><h3 id="42-와인-색상분류redwhite를-위한-x-y-분리">4.2 와인 색상분류(red/white)를 위한 X, y 분리</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">wine_y</span> <span class="o">=</span> <span class="n">wine</span><span class="p">[</span><span class="s">'color'</span><span class="p">]</span>
<span class="n">wine_X</span> <span class="o">=</span> <span class="n">wine</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'color'</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">wine_X</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</pre></table></code></div></div><div style="width:100%; height:200px; overflow:auto"><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>fixed acidity<th>volatile acidity<th>citric acid<th>residual sugar<th>chlorides<th>free sulfur dioxide<th>total sulfur dioxide<th>density<th>pH<th>sulphates<th>alcohol<th>quality<tbody><tr><th>0<td>7.4<td>0.70<td>0.00<td>1.9<td>0.076<td>11.0<td>34.0<td>0.9978<td>3.51<td>0.56<td>9.4<td>5<tr><th>1<td>7.8<td>0.88<td>0.00<td>2.6<td>0.098<td>25.0<td>67.0<td>0.9968<td>3.20<td>0.68<td>9.8<td>5<tr><th>2<td>7.8<td>0.76<td>0.04<td>2.3<td>0.092<td>15.0<td>54.0<td>0.9970<td>3.26<td>0.65<td>9.8<td>5<tr><th>3<td>11.2<td>0.28<td>0.56<td>1.9<td>0.075<td>17.0<td>60.0<td>0.9980<td>3.16<td>0.58<td>9.8<td>6<tr><th>4<td>7.4<td>0.70<td>0.00<td>1.9<td>0.076<td>11.0<td>34.0<td>0.9978<td>3.51<td>0.56<td>9.4<td>5</table></div><p><br /></p><h3 id="43-standardscaler-적용">4.3 StandardScaler 적용</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">wine_ss</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">().</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">wine_X</span><span class="p">)</span>
<span class="n">wine_ss</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre>array([[ 0.14247327,  2.18883292, -2.19283252, -0.7447781 ,  0.56995782,
        -1.10013986, -1.44635852,  1.03499282,  1.81308951,  0.19309677,
        -0.91546416, -0.93722961],
       [ 0.45103572,  3.28223494, -2.19283252, -0.59764007,  1.1979747 ,
        -0.31132009, -0.86246863,  0.70148631, -0.11507303,  0.99957862,
        -0.58006813, -0.93722961],
       [ 0.45103572,  2.55330026, -1.91755268, -0.66069923,  1.02669737,
        -0.87476278, -1.09248586,  0.76818761,  0.25811972,  0.79795816,
        -0.58006813, -0.93722961]])
</pre></table></code></div></div><p><br /></p><h3 id="44-2개로-pca">4.4 2개로 PCA</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">pca_wine</span><span class="p">,</span> <span class="n">pca</span> <span class="o">=</span> <span class="n">get_pca_data</span><span class="p">(</span><span class="n">wine_ss</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">pca_wine</span><span class="p">.</span><span class="n">shape</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>(6497, 2)
</pre></table></code></div></div><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">print_variance_ratio</span><span class="p">(</span><span class="n">pca</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>variance_ratio:  [0.25346226 0.22082117]
sum of variance_ratio:  0.47428342743236185
</pre></table></code></div></div><ul><li>총 12개의 특성을 가지고 있는 와인 데이터를 2개의 성분으로 주성분 분석하면, 전체 데이터의 0.47정도의 설명력을 가진다.</li><li>설명력이 부족하긴 하지만 1/6로 데이터를 줄인것 가지고 진행을 해보자</li></ul><p><br /></p><h3 id="45-데이터-프레임-만들고-pairplot-그려보기">4.5 데이터 프레임 만들고 pairplot 그려보기</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="n">pca_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'pca_component_1'</span><span class="p">,</span> <span class="s">'pca_component_2'</span><span class="p">]</span>
<span class="n">pca_wine_pd</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">pca_wine</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span> <span class="n">pca_columns</span><span class="p">)</span>
<span class="n">pca_wine_pd</span><span class="p">[</span><span class="s">'color'</span><span class="p">]</span> <span class="o">=</span> <span class="n">wine_y</span><span class="p">.</span><span class="n">values</span>

<span class="n">sns</span><span class="p">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">pca_wine_pd</span><span class="p">,</span> <span class="n">hue</span> <span class="o">=</span> <span class="s">'color'</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span> <span class="mi">5</span><span class="p">,</span> 
            <span class="n">x_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s">'pca_component_1'</span><span class="p">],</span> <span class="n">y_vars</span> <span class="o">=</span> <span class="p">[</span><span class="s">'pca_component_2'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/97006884-769b9300-157b-11eb-8bd4-d9aeab80da57.png" /></p><ul><li>그냥 눈으로 보기에는 y값(color)이 주황색점으로 파란색점이 잘 나뉘어져 있는것으로 보인다</li></ul><p><br /></p><h3 id="46-randomforest-적용">4.6 RandomForest 적용</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="n">rf_scores</span><span class="p">(</span><span class="n">wine_ss</span><span class="p">,</span> <span class="n">wine_y</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>Score :  0.9935352638124
</pre></table></code></div></div><ul><li>iris 데이터에서 생성한 RandomForest 함수를 사용</li><li>원래의 12개 특성을 가지고 있는 데이터를 가지고 RandomForest를 적용하면 0.99가 나온다</li></ul><p><br /></p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">pca_X</span> <span class="o">=</span> <span class="n">pca_wine_pd</span><span class="p">[[</span><span class="s">'pca_component_1'</span><span class="p">,</span> <span class="s">'pca_component_2'</span><span class="p">]]</span>
<span class="n">rf_scores</span><span class="p">(</span><span class="n">pca_X</span><span class="p">,</span> <span class="n">wine_y</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>Score :  0.981067803635933
</pre></table></code></div></div><ul><li>2개의 주성분분석을 한 데이터를 가지고 RandomForest를 적용하면 0.98이 나온다</li><li>생각보다 설명력이 47% 밖에 안되는 PCA 데이터를 가지고 적용하였는데도, 의외로 원래의 데이터와 큰 차이가 안난다</li></ul><p><br /></p><h3 id="47-주성분-3개로-해보기">4.7 주성분 3개로 해보기</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="n">pca_wine</span><span class="p">,</span> <span class="n">pca</span> <span class="o">=</span> <span class="n">get_pca_data</span><span class="p">(</span><span class="n">wine_ss</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">print_variance_ratio</span><span class="p">(</span><span class="n">pca</span><span class="p">)</span>

<span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="s">'pca_1'</span><span class="p">,</span> <span class="s">'pca_2'</span><span class="p">,</span> <span class="s">'pca_3'</span><span class="p">]</span>
<span class="n">pca_wine_pd</span> <span class="o">=</span> <span class="n">get_pd_from_pca</span><span class="p">(</span><span class="n">pca_wine</span><span class="p">,</span> <span class="n">cols</span><span class="o">=</span><span class="n">cols</span><span class="p">)</span>

<span class="n">pca_X</span> <span class="o">=</span> <span class="n">pca_wine_pd</span><span class="p">[</span><span class="n">cols</span><span class="p">]</span>
<span class="n">rf_scores</span><span class="p">(</span><span class="n">pca_X</span><span class="p">,</span> <span class="n">wine_y</span><span class="p">)</span>
</pre></table></code></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre>variance_ratio:  [0.25346226 0.22082117 0.13679223]
sum of variance_ratio:  0.6110756621838703
Score :  0.9832236631728548
</pre></table></code></div></div><ul><li>3개의 주성분으로 생성 후 RandomForest를 하였을때 accuracy는 0.98이 나옴</li><li>2개의 주성분으로 하였을땐 원래 데이터의 0.47의 설명력을 가졌고, 3개의 주성분으로 하였을땐 0.61의 설명력을 가짐</li><li>의외로 주성분을 2개에서 3개로 올렸을떄 설명력은 0.14정도가 차이가 났는데, accuracy는 크게 상승하지 않았음</li></ul><p><br /></p><p><br /></p><h3 id="48-주성분-3개로-표현한-데이터를-프레임으로-생성">4.8 주성분 3개로 표현한 데이터를 프레임으로 생성</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">pca_wine_plot</span> <span class="o">=</span> <span class="n">pca_X</span>
<span class="n">pca_wine_plot</span><span class="p">[</span><span class="s">'color'</span><span class="p">]</span> <span class="o">=</span> <span class="n">wine_y</span><span class="p">.</span><span class="n">values</span>
<span class="n">pca_wine_plot</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</pre></table></code></div></div><div><style scoped=""> .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }</style><table border="1" class="dataframe"><thead><tr style="text-align: right;"><th><th>pca_1<th>pca_2<th>pca_3<th>color<tbody><tr><th>0<td>-3.348438<td>0.568926<td>-2.727386<td>1<tr><th>1<td>-3.228595<td>1.197335<td>-1.998904<td>1<tr><th>2<td>-3.237468<td>0.952580<td>-1.746578<td>1<tr><th>3<td>-1.672561<td>1.600583<td>2.856552<td>1<tr><th>4<td>-3.348438<td>0.568926<td>-2.727386<td>1</table></div><p><br /></p><h3 id="49-3d로-그려보기">4.9 3D로 그려보기</h3><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>

<span class="n">markers</span> <span class="o">=</span> <span class="p">[</span><span class="s">'^'</span><span class="p">,</span> <span class="s">'o'</span><span class="p">]</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s">'3d'</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">marker</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">markers</span><span class="p">):</span>
    <span class="n">x_axis_data</span> <span class="o">=</span> <span class="n">pca_wine_plot</span><span class="p">[</span><span class="n">pca_wine_plot</span><span class="p">[</span><span class="s">'color'</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">][</span><span class="s">'pca_1'</span><span class="p">]</span>
    <span class="n">y_axis_data</span> <span class="o">=</span> <span class="n">pca_wine_plot</span><span class="p">[</span><span class="n">pca_wine_plot</span><span class="p">[</span><span class="s">'color'</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">][</span><span class="s">'pca_2'</span><span class="p">]</span>
    <span class="n">z_axis_data</span> <span class="o">=</span> <span class="n">pca_wine_plot</span><span class="p">[</span><span class="n">pca_wine_plot</span><span class="p">[</span><span class="s">'color'</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">][</span><span class="s">'pca_3'</span><span class="p">]</span>

    <span class="n">ax</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_axis_data</span><span class="p">,</span> <span class="n">y_axis_data</span><span class="p">,</span> <span class="n">z_axis_data</span><span class="p">,</span>
               <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="n">marker</span><span class="p">)</span>
    
<span class="n">ax</span><span class="p">.</span><span class="n">view_init</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></table></code></div></div><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://user-images.githubusercontent.com/60168331/97006885-77342980-157b-11eb-969f-f1cd22e8245f.png" /></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/data-science/'>Data Science</a>, <a href='/categories/machine-learning/'>Machine Learning</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/pca/" class="post-tag no-text-decoration" >PCA</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><!-- Post sharing snippet v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=아이리스 데이터와 와인데이터로 해보는 PCA - Data Include Me&url=https://datainclude.me/posts/%EC%95%84%EC%9D%B4%EB%A6%AC%EC%8A%A4_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%99%80_%EC%99%80%EC%9D%B8%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_PCA/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=아이리스 데이터와 와인데이터로 해보는 PCA - Data Include Me&u=https://datainclude.me/posts/%EC%95%84%EC%9D%B4%EB%A6%AC%EC%8A%A4_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%99%80_%EC%99%80%EC%9D%B8%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_PCA/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=아이리스 데이터와 와인데이터로 해보는 PCA - Data Include Me&url=https://datainclude.me/posts/%EC%95%84%EC%9D%B4%EB%A6%AC%EC%8A%A4_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%99%80_%EC%99%80%EC%9D%B8%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_PCA/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><!-- The Panel on right side (Desktop views) v2.3 © 2024 Your Name MIT License --><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><h3 data-toc-skip>Recent Update</h3><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li class="recent-item"> <a href="/posts/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C_%EC%BB%B4%ED%93%A8%ED%8C%85_%EA%B0%80%EC%83%81%ED%99%94/">클라우드 컴퓨팅 - 가상화</a> <span class="text-muted small">2024-10-28</span></li><li class="recent-item"> <a href="/posts/gemini_api_%EC%82%AC%EC%9A%A9%ED%95%B4%EB%B3%B4%EA%B8%B0/">Gemini API 사용해보기</a> <span class="text-muted small">2024-03-12</span></li><li class="recent-item"> <a href="/posts/Ollama%EC%99%80_Python_%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC_LLaMa2%EB%A5%BC_%EB%A1%9C%EC%BB%AC%EC%97%90%EC%84%9C_%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/">Ollama와 Python 라이브러리를 이용하여 LLaMa2를 로컬에서 사용하기</a> <span class="text-muted small">2024-02-13</span></li><li class="recent-item"> <a href="/posts/Mistral_7B_Fine_Tuning/">Mistral 7B 파인튜닝(Fine Tuning)하기</a> <span class="text-muted small">2023-10-25</span></li><li class="recent-item"> <a href="/posts/Penn_Fudan%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EA%B0%9D%EC%B2%B4_%ED%83%90%EC%A7%80_%EB%B6%84%ED%95%A0/">Penn-Fudan으로 알아보는 객체 탐지(Object Detection), 분할(Segmentation) with FasterRCNN</a> <span class="text-muted small">2023-10-23</span></li></ul></div><div id="access-tags"><h3 data-toc-skip>Trending Tags</h3><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/tensorflow/">Tensorflow</a> <a class="post-tag" href="/tags/sklearn/">Sklearn</a> <a class="post-tag" href="/tags/round/">Round</a> <a class="post-tag" href="/tags/python-lv0/">Python Lv0</a> <a class="post-tag" href="/tags/pca/">PCA</a> <a class="post-tag" href="/tags/eda/">EDA</a> <a class="post-tag" href="/tags/distinct/">Distinct</a> <a class="post-tag" href="/tags/random-forest/">Random Forest</a> <a class="post-tag" href="/tags/beautifulsoup/">Beautifulsoup</a> <a class="post-tag" href="/tags/baekjoon/">Baekjoon</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><h3 data-toc-skip class="pl-3 pt-2 mb-2">Contents</h3><nav id="toc" data-toggle="toc"></nav></div></div><style> .recent-item { margin-bottom: 0.5rem; } .recent-item a { color: var(--link-color); } .recent-item .small { font-size: 0.75rem; margin-left: 0.5rem; }</style></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"> <!-- Recommend the other 3 posts according to the tags and categories of the current post, if the number is not enough, use the other latest posts to supplement. v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/PCA_tSNE_LDA%EC%9C%BC%EB%A1%9C_%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94_%EC%B0%A8%EC%9B%90_%EC%B6%95%EC%86%8C/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Sep 8, 2023 <i class="unloaded">2023-09-08T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>PCA, t-SNE, LDA으로 알아보는 차원 축소</h3><div class="text-muted small"><p> 차원 축소는 데이터의 차원을 줄여서 데이터를 간결하게 만드는 기술이다. 시각화, 데이터 축소, 노이즈 제거, 성능 향상 및 계산 시간 감소를 위해 사용한다. 대표적인 차원 축소 알고리즘으로는 PCA, t-SNE, LDA가 있으며, 각 알고리즘은 장점과 단점이 있다. 차원 축소는 머신 러닝 모델의 성능에 긍부적 적인 영향을 미치며, 특성 선택과 차원 축...</p></div></div></a></div><div class="card"> <a href="/posts/Eigenface%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_PCA/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Oct 23, 2020 <i class="unloaded">2020-10-23T13:10:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Eigenface로 해보는 PCA</h3><div class="text-muted small"><p> 1. Olivetti 데이터 1.1 데이터 소개 미국의 AT&amp;T와 캠프리지 대학 전산 연구실에서 공동으로 제작한 얼굴 사진 데이터 얼굴 인식 등 다양한 분야에서 활용되고 있음 일부 데이터가 sklearn에 dataset으로 내장되어 있음 2. 실습 2.1 Data load 1 2 3 4 from sklearn.datas...</p></div></div></a></div><div class="card"> <a href="/posts/HAR%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_PCA/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Oct 23, 2020 <i class="unloaded">2020-10-23T15:10:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>HAR로 해보는 PCA</h3><div class="text-muted small"><p> 1. HAR data 1.1 HAR data load 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import pandas as pd import matplotlib.pyplot as plt url = 'https://raw.githubusercontent.com/hmkim312/datas/main/HAR/features.txt' ...</p></div></div></a></div></div></div><!-- Navigation buttons at the bottom of the post. v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --><div class="post-navigation d-flex justify-content-between"> <a href="/posts/%EC%8B%A0%EC%9A%A9%EC%B9%B4%EB%93%9C_%EB%B6%80%EC%A0%95_%EC%82%AC%EC%9A%A9%EC%9E%90_%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_%EB%B6%80%EC%8A%A4%ED%8C%85/" class="btn btn-outline-primary"><p>신용카드 부정 사용자 데이터로 해보는 부스팅</p></a> <a href="/posts/Eigenface%EB%A1%9C_%ED%95%B4%EB%B3%B4%EB%8A%94_PCA/" class="btn btn-outline-primary"><p>Eigenface로 해보는 PCA</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('#post-wrapper img'); const observer = lozad(imgs); observer.observe(); </script></div><!-- The Search results v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/tensorflow/">Tensorflow</a> <a class="post-tag" href="/tags/sklearn/">Sklearn</a> <a class="post-tag" href="/tags/round/">Round</a> <a class="post-tag" href="/tags/python-lv0/">Python Lv0</a> <a class="post-tag" href="/tags/pca/">PCA</a> <a class="post-tag" href="/tags/eda/">EDA</a> <a class="post-tag" href="/tags/distinct/">Distinct</a> <a class="post-tag" href="/tags/random-forest/">Random Forest</a> <a class="post-tag" href="/tags/beautifulsoup/">Beautifulsoup</a> <a class="post-tag" href="/tags/baekjoon/">Baekjoon</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <!-- The GA snippet v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <!-- Jekyll Simple Search loader v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://datainclude.me{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script>
