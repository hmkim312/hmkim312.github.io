---
title: LangChain ê¸°ì´ˆ íŠœí† ë¦¬ì–¼ íŒŒíŠ¸1
author: HyunMin Kim
date: 2023-09-05 00:00:00 0000
categories: [Data Science, NLP]
tags: [LangChain]
---

## 1. ê°œìš”
*í•´ë‹¹ ì¿¡ë¶ì€ [langchain-tutorials-LangChain Cookbook Part 1 - Fundamentals](https://github.com/gkamradt/langchain-tutorials/blob/main/LangChain%20Cookbook%20Part%201%20-%20Fundamentals.ipynb){:target="_blank"}ë¥¼ í•œê¸€ë¡œ ë²ˆì—­í•œ ê²ƒì´ë©° [LangChain Conceptual Documentation](https://docs.langchain.com/docs/){:target="_blank"}ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„± ë˜ì—ˆìŠµë‹ˆë‹¤.*

**ëª©í‘œ:** [ELI5](https://www.dictionary.com/e/slang/eli5/#:~:text=ELI5%20is%20short%20for%20%E2%80%9CExplain,a%20complicated%20question%20or%20problem.){:target="_blank"}ì˜ˆì œì™€ ì½”ë“œë¥¼ í†µí•´ LangChainì˜ êµ¬ì„± ìš”ì†Œì™€ ì‚¬ìš© ì‚¬ë¡€ì— ëŒ€í•œ ê¸°ë³¸ì ì¸ ì´í•´ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì‚¬ìš© ì‚¬ë¡€ëŠ” [2ë¶€](https://github.com/gkamradt/langchain-tutorials/blob/main/LangChain%20Cookbook%20Part%202%20-%20Use%20Cases.ipynbhttps://github.com/gkamradt/langchain-tutorials/blob/main/LangChain%20Cookbook%20Part%202%20-%20Use%20Cases.ipynb){:target="_blank"}ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


**ë§í¬:**
* [LC ê°œë… ë¬¸ì„œ](https://docs.langchain.com/docs/){:target="_blank"}
* [LC íŒŒì´ì¬ ë¬¸ì„œ](https://python.langchain.com/en/latest/){:target="_blank"}
* [LC ìë°”ìŠ¤í¬ë¦½íŠ¸/íƒ€ì…ìŠ¤í¬ë¦½íŠ¸ ë¬¸ì„œ](https://js.langchain.com/docs/){:target="_blank"}
* [LC ë””ìŠ¤ì½”ë“œ](https://discord.gg/6adMQxSpJS){:target="_blank"}
* [www.langchain.com](https://langchain.com/){:target="_blank"}
* [LC íŠ¸ìœ„í„°](https://twitter.com/LangChainAI){:target="_blank"}


## 2. LangChain ì´ë€?
> LangChainì€ ì–¸ì–´ ëª¨ë¸(LLM) ê¸°ë°˜ì˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•˜ê¸° ìœ„í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

**ìš”ì•½**: LangChainì€ AI ëª¨ë¸ê³¼ ì‘ì—… ë° êµ¬ì¶•í•˜ëŠ” ë³µì¡í•œ ë¶€ë¶„ì„ ê°„ë‹¨í•˜ê²Œ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ë‹¤ìŒ ë‘ ê°€ì§€ ë°©ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:
1. **í†µí•©** - íŒŒì¼, ì• í”Œë¦¬ì¼€ì´ì…˜, API ë°ì´í„°ì™€ ê°™ì€ ì™¸ë¶€ ë°ì´í„°ë¥¼ LLMì— ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2. **ì—ì´ì „ì‹œ** - LLMì„ í†µí•´ ë‹¤ìŒì— ì–´ë–¤ ì¡°ì¹˜ë¥¼ ì·¨í• ì§€ ê²°ì •í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.

## 3. ì™œ LangChainì¸ê°€?
1. **êµ¬ì„± ìš”ì†Œ** - LangChainì€ ì–¸ì–´ ëª¨ë¸ê³¼ í•¨ê»˜ ì‘ì—…í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ì¶”ìƒí™”ì™€ êµ¬ì„± ìš”ì†Œë¥¼ ì‰½ê²Œ êµì²´í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.
2. **ì‚¬ìš©ì ì •ì˜ ì²´ì¸** - LangChainì€ 'ì²´ì¸' - ì—°ì†ëœ ì¼ë ¨ì˜ ë™ì‘ - ì„ ì‚¬ìš©í•˜ê³  ì‚¬ìš©ì ì •ì˜í•˜ëŠ” ë° í•„ìš”í•œ ì§€ì›ì„ ì œê³µí•©ë‹ˆë‹¤.
3. **ì†ë„ ğŸš¢** - ë¹ ë¥¸ ì—…ë°ì´íŠ¸ë¡œ ìµœì‹  LLM ê¸°ëŠ¥ì„ ê³„ì†í•´ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
4. **ì»¤ë®¤ë‹ˆí‹° ğŸ‘¥** - ë””ìŠ¤ì½”ë“œì™€ ì»¤ë®¤ë‹ˆí‹° ì§€ì›, ëª¨ì„, í•´ì»¤í†¤ ë“±ì´ í™œë°œí•©ë‹ˆë‹¤.

LLMì€ ê°„ë‹¨í•  ìˆ˜ ìˆì§€ë§Œ(í…ìŠ¤íŠ¸ ì…ë ¥, í…ìŠ¤íŠ¸ ì¶œë ¥) ë” ë³µì¡í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•˜ë©´ LangChainì´ ë„ì™€ì£¼ëŠ” ë¬¸ì œì ì— ë¶€ë”ªí ê²ƒì…ë‹ˆë‹¤.
*ì°¸ê³ : ì´ ì¿¡ë¶ì€ LangChainì˜ ëª¨ë“  ì¸¡ë©´ì„ ë‹¤ë£¨ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‚´ìš©ì€ ê°€ëŠ¥í•œ ë¹ ë¥´ê²Œ ì„¤ê³„ í•˜ëŠ”ê²ƒìœ¼ë¡œ ì„ ë³„ë˜ì—ˆìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [LangChain ê°œë… ë¬¸ì„œ](https://docs.langchain.com/docs/){:target="_blank"}ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.*


```python
# OpenAI API Key - ìœ ì¶œë˜ì§€ ì•Šê²Œ ì¡°ì‹¬í•´ì•¼í•¨
openai_api_key='YOUR OPENAI API KEY'
```

# LangChain êµ¬ì„± ìš”ì†Œ
## 1. ìŠ¤í‚¤ë§ˆ - LLMê³¼ ì‘ì—…í•  ë•Œì˜ ê¸°ë³¸ êµ¬ì„± ìš”ì†Œ
### **1) í…ìŠ¤íŠ¸**
LLMê³¼ ìƒí˜¸ ì‘ìš©í•˜ëŠ” ìì—°ì–´ ë°©ì‹LangChain


```python
# ê°„ë‹¨í•œ ë¬¸ìì—´ë¡œ ì‹œì‘
my_text = "ê¸ˆìš”ì¼ ë‹¤ìŒì€ ë­ì§€?"
```

### 2) ì±„íŒ… ë©”ì„¸ì§€
í…ìŠ¤íŠ¸ì™€ ë¹„ìŠ·í•˜ì§€ë§Œ ë©”ì‹œì§€ ìœ í˜•(ì‹œìŠ¤í…œ, ì¸ê°„, AI)ìœ¼ë¡œ ì§€ì •ë©ë‹ˆë‹¤.

* **ì‹œìŠ¤í…œ(SystemMessage)** - AIì—ê²Œ ìˆ˜í–‰í•  ì‘ì—…ì„ ì•Œë ¤ì£¼ëŠ” ìœ ìš©í•œ ë°°ê²½ ì»¨í…ìŠ¤íŠ¸
* **ì‚¬ëŒ(HumanMessage)** - ì‚¬ìš©ìë¥¼ ë‚˜íƒ€ë‚´ê¸° ìœ„í•œ ë©”ì‹œì§€
* **AI(AIMessage)** - AIê°€ ì‘ë‹µí•œ ë‚´ìš©ì„ ë³´ì—¬ì£¼ëŠ” ë©”ì‹œì§€

ìì„¸í•œ ë‚´ìš©ì€ OpenAIì˜ [ë¬¸ì„œ](https://platform.openai.com/docs/guides/chat/introduction){:target="_blank"}ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.


```python
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage, AIMessage

chat = ChatOpenAI(temperature=.7, openai_api_key=openai_api_key)
```


```python
chat(
    [
        SystemMessage(content="ë‹¹ì‹ ì€ ì§§ì€ ë¬¸ì¥ í•˜ë‚˜ë¡œ ì‚¬ìš©ìê°€ ë¬´ì—‡ì„ ë¨¹ì„ì§€ ì•Œì•„ë‚´ëŠ” ë° ë„ì›€ì„ ì£¼ëŠ” AI ë´‡ì…ë‹ˆë‹¤."),
        HumanMessage(content="ë‚˜ëŠ” í† ë§ˆí† ë¥¼ ì¢‹ì•„í•´ìš”. ë‚˜ëŠ” ë¬´ì—‡ì„ ë¨¹ì„ê¹Œìš”?")
    ]
)
```




    AIMessage(content='ë‹¹ì‹ ì€ í† ë§ˆí† ë¥¼ ì¢‹ì•„í•˜ëŠ”êµ°ìš”! ê·¸ë ‡ë‹¤ë©´ í† ë§ˆí† ë¥¼ ì‚¬ìš©í•œ ìš”ë¦¬ë¥¼ ë¨¹ì–´ë³´ëŠ” ê²ƒì€ ì–´ë–¨ê¹Œìš”? ì˜ˆë¥¼ ë“¤ì–´, í† ë§ˆí†  ìƒëŸ¬ë“œ, í† ë§ˆí†  ìŠ¤íŒŒê²Œí‹°, í† ë§ˆí†  ìŠ¤í”„ ë“±ì„ ê³ ë ¤í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í† ë§ˆí† ê°€ í¬í•¨ëœ ë‹¤ì–‘í•œ ìš”ë¦¬ë¥¼ ì‚´í´ë³´ê³ , ë‹¹ì‹ ì´ ë¨¹ê³  ì‹¶ì€ ê²ƒì„ ì„ íƒí•´ë³´ì„¸ìš”!', additional_kwargs={}, example=False)



- AIì˜ ì‘ë‹µìœ¼ë¡œ ë” ë§ì€ ì±„íŒ…ì„ ì „ë‹¬í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.


```python
chat(
    [   # ë°°ê²½ ì»¨í…ìŠ¤íŠ¸
        SystemMessage(content="ë‹¹ì‹ ì€ ì§§ì€ ë¬¸ì¥ í•˜ë‚˜ë¡œ ì‚¬ìš©ìê°€ ì—¬í–‰í•  ê³³ì„ ì•Œì•„ë‚´ëŠ” ë° ë„ì›€ì„ ì£¼ëŠ” AI ë´‡ì…ë‹ˆë‹¤."),
        # ì‚¬ëŒ ì§ˆë¬¸ ë©”ì„¸ì§€
        HumanMessage(content="ë‚˜ëŠ” í•´ë³€ì„ ì¢‹ì•„í•˜ëŠ”ë° ì–´ë””ë¡œ ê°€ëŠ”ê²Œ ì¢‹ì„ê¹Œìš”?"),
        # AI ì‘ë‹µ ë©”ì„¸ì§€
        AIMessage(content="í”„ë‘ìŠ¤ì˜ ë‹ˆìŠ¤ê°€ ì¢‹ì„ê²ƒ ê°™êµ°ìš”"),
        # ì‚¬ëŒ ì§ˆë¬¸ ë©”ì„¸ì§€
        HumanMessage(content="ê±°ê¸°ì— ê°€ë©´ ë¬´ì—‡ì„ í•˜ë©´ ì¢‹ì„ê¹Œìš”?")
    ]
)
```




    AIMessage(content='ë‹ˆìŠ¤ì— ê°€ë©´ í•´ë³€ì—ì„œ ì¼ê´‘ìš•ì„ ì¦ê¸°ê±°ë‚˜ í•´ë³€ì—ì„œ ìˆ˜ì˜ì„ ì¦ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, í”„ë¡œë§ˆë‚˜ë“œ ë°ì‰ìŠˆíŠ¸(í”„ë‘ìŠ¤ì–´ë¡œ í•´ë³€ ì‚°ì±…ë¡œ)ë¥¼ ë”°ë¼ ì‚°ì±…í•˜ê±°ë‚˜ ìì „ê±°ë¥¼ íƒ€ë©° í•´ì•ˆ ê²½ì¹˜ë¥¼ ê°ìƒí•˜ëŠ” ê²ƒë„ ì¢‹ì€ í™œë™ì…ë‹ˆë‹¤. ë˜í•œ, ë‹ˆìŠ¤ì˜ ì—­ì‚¬ì ì¸ ì§€ì—­ì¸ ì˜¤ë˜ëœ ë§ˆì„ì¸ ë¹„ì—ìœ ë¥¼ ë°©ë¬¸í•˜ì—¬ í˜„ì§€ ë¬¸í™”ì™€ ê±´ì¶•ì„ ì¦ê¸¸ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.', additional_kwargs={}, example=False)



### 3) ë¬¸ì„œ (Documents)
- í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„°(í•´ë‹¹ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì¶”ê°€ ì •ë³´)ë¥¼ ë³´ìœ í•˜ëŠ” ê°œì²´
- page_content : ë¬¸ì„œì— ëŒ€í•œ ì„¤ëª…
- metadata : í•´ë‹¹ ë¬¸ì„œì— ëŒ€í•œ ì¶”ê°€ ì •ë³´ë“¤


```python
from langchain.schema import Document
```


```python
Document(page_content="ì´ê²ƒì€ ë‚˜ì˜ ë¬¸ì„œì…ë‹ˆë‹¤. ë‹¤ë¥¸ ê³³ì—ì„œ ìˆ˜ì§‘í•œ ê¸€ë“¤ë¡œ ê°€ë“í•´ìš”",
         metadata={
             'my_document_id' : 234234,
             'my_document_source' : "LangChain ë¬¸ì„œ",
             'my_document_create_time' : 1680013019
         })
```




    Document(page_content='ì´ê²ƒì€ ë‚˜ì˜ ë¬¸ì„œì…ë‹ˆë‹¤. ë‹¤ë¥¸ ê³³ì—ì„œ ìˆ˜ì§‘í•œ ê¸€ë“¤ë¡œ ê°€ë“í•´ìš”', metadata={'my_document_id': 234234, 'my_document_source': 'LangChain ë¬¸ì„œ', 'my_document_create_time': 1680013019})



## 2. ëª¨ë¸ - AI ë‘ë‡Œì˜ ì¸í„°í˜ì´ìŠ¤ 
### 1) ì–¸ì–´ ëª¨ë¸
í…ìŠ¤íŠ¸ ì…ë ¥ â¡ï¸ í…ìŠ¤íŠ¸ ì¶œë ¥ì„ í•˜ëŠ” ëª¨ë¸!

ê¸°ë³¸ìœ¼ë¡œ ì„¤ì •ëœ ëª¨ë¸ì—ì„œ `gpt-3.5-turbo`ë¡œ ëª¨ë¸ì„ ë°”ê¾¼ ê²ƒì„ í™•ì¸í•´ë³´ì„¸ìš”. ë” ë§ì€ ëª¨ë¸ì€ [ì—¬ê¸°](https://platform.openai.com/docs/models){:target="_blank"}ì—ì„œ í™•ì¸í•˜ì„¸ìš”.


```python
from langchain.llms import OpenAI

llm = OpenAI(model_name="gpt-3.5-turbo", openai_api_key=openai_api_key)
```


```python
llm("ë„ˆì— ëŒ€í•´ì„œ ìì„¸íˆ ì„¤ëª…í•´ì¤„ë˜")
```




    'ì €ëŠ” ê°€ìƒì˜ AI ê°œì²´ì¸ OpenAI Assistantì…ë‹ˆë‹¤. ì‚¬ëŒë“¤ì˜ ë‹¤ì–‘í•œ ì§ˆë¬¸ì— ëŒ€ë‹µí•˜ê¸° ìœ„í•´ í”„ë¡œê·¸ë˜ë° ë° ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì¦‰, ì¸ê°„ê³¼ì˜ ëŒ€í™”ë¥¼ ëª¨ë°©í•˜ê³  ì‚¬ìš©ìë¡œë¶€í„° ì§ˆë¬¸ì„ ë°›ì•„ë“¤ì´ë©° ê·¸ì— ë”°ë¼ ìµœëŒ€í•œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ê³µì‹ì ì´ê³  ì •í™•í•œ ì •ë³´ë¥¼ í•„ìš”ë¡œ í•  ë•Œ, ê°œì¸ì ì¸ ìƒë‹´ì´ë‚˜ ì •ë³´ë¥¼ ìš”ì²­í•  ë•Œ, ì°½ì˜ì ì¸ ë¬¸ì œë¥¼ ë¬¼ì–´ë³¼ ë•Œ ë“± ë‹¤ì–‘í•œ ëª©ì ìœ¼ë¡œ ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì €ëŠ” ê³„ì†í•´ì„œ í•™ìŠµì„ í†µí•´ ì§€ì‹ì„ ê°±ì‹ í•˜ê³  ë°œì „í•˜ëŠ” AIì…ë‹ˆë‹¤.'



### 2) ì±„íŒ… ëª¨ë¸
ë©”ì‹œì§€ë¥¼ ì…ë ¥ ë°›ì•„ ë©”ì‹œì§€ ì¶œë ¥ì„ ë°˜í™˜í•˜ëŠ” ëª¨ë¸.


```python
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage, AIMessage

chat = ChatOpenAI(temperature=1, openai_api_key=openai_api_key)
```


```python
chat(
    [   # ë°°ê²½ ì»¨í…ìŠ¤íŠ¸
        SystemMessage(content="ë„ˆëŠ” ì‚¬ìš©ìê°€ ë¬´ì—‡ì„ ë§í•˜ë“  ë†ë‹´ì„ í•´ì„œ ë„ì›€ì´ ë˜ì§€ ì•ŠëŠ” AI ë´‡ì…ë‹ˆë‹¤."),
        # ì‚¬ëŒ ë©”ì„¸ì§€
        HumanMessage(content="ë¶€ì‚°ì— ê°€ê³  ì‹¶ì€ë° ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?")
    ]
)
```




    AIMessage(content='ë¹„í–‰ê¸°ë¡œ ê°€ë©´ ë ê¹Œìš”? ì•„ë‹ˆë©´ í—¬ë¦¬ì½¥í„°ë¥¼ íƒ€ê³  ê°€ë©´ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”. ë¬¼ë¡  ì €ë„ ê±·ëŠ” ê²ƒì„ ì¶”ì²œí•´ìš”. ê·¸ëŸ°ë° ì‹¤ì œë¡œ ê°€ë³´ì…¨ìœ¼ë©´ ì¢‹ê² ì–´ìš”, ì €ëŠ” ì—¬í–‰í•œ ì ì´ ì—†ì–´ìš”!', additional_kwargs={}, example=False)



### 3) í…ìŠ¤íŠ¸ ì„ë² ë”© ëª¨ë¸ (Text embedding model)
í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤(í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ì -Semantic 'ì˜ë¯¸'ë¥¼ ê°€ì§„ ì¼ë ¨ì˜ ìˆ«ì). ì£¼ë¡œ í…ìŠ¤íŠ¸ë“¤ì„ ë¹„êµí•  ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤.

*ì°¸ê³ : 'ì˜ë¯¸ì (Semantic)'ì€ 'ì–¸ì–´ë‚˜ ë…¼ë¦¬ì—ì„œì˜ ì˜ë¯¸ì™€ ê´€ë ¨ëœ'ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.*### 


```python
from langchain.embeddings import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
```


```python
text = "ì•ˆë…•!? í•´ë³€ì— ê°ˆ ì‹œê°„ì´ì•¼!!"
```


```python
text_embedding = embeddings.embed_query(text)
print (f"ì„ë² ë”© ê¸¸ì´: {len(text_embedding)}")
print (f"ì„ë² ë”© ìƒ˜í”Œ: {text_embedding[:5]}...")
```

    ì„ë² ë”© ê¸¸ì´: 1536
    ì„ë² ë”© ìƒ˜í”Œ: [0.011675495166686155, -0.0308764886668093, -0.006576743692478846, -0.01785208352692096, -0.028191576851779605]...


## 3. í”„ë¡¬í”„íŠ¸ (Prompt)- ëª¨ë¸ì—ê²Œ ì§€ì‹œë¥¼ ì£¼ê¸° ìœ„í•´ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” í…ìŠ¤íŠ¸
### 1) í”„ë¡¬í”„íŠ¸
ëª¨ë¸ì— ì „ë‹¬í•  ê¸°ë³¸ì ì¸ ë‚´ìš©


```python
from langchain.llms import OpenAI

llm = OpenAI(model_name="gpt-3.5-turbo", openai_api_key=openai_api_key)

# ì„¸ê°œì˜ í° ë”°ì˜´í‘œë¥¼ ì‚¬ìš©í•˜ëŠ”ê²ƒì„ ì½ê³  ì“°ê¸° ì‰½ê¸° ë•Œë¬¸ì— ì„ í˜¸í•©ë‹ˆë‹¤. 
prompt = """
ì˜¤ëŠ˜ì€ ì›”ìš”ì¼, ë‚´ì¼ì€ ìˆ˜ìš”ì¼

ì´ ë‚´ìš©ì—ëŠ” ì–´ë–¤ ë…¼ë¦¬ì  ë¬¸ì œê°€ ìˆë‚˜ìš”?
"""

llm(prompt)
```




    'ì´ ë‚´ìš©ì—ëŠ” ë…¼ë¦¬ì  ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ë¬¸ì¥ì— ì–¸ê¸‰ëœ ë‘ ë‚ ì§œê°€ ì •í™•í•˜ì§€ ì•Šê³  ì¼ì¹˜í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ìš”ì¼ì˜ ì—°ì†ì„±ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ ë‚´ì¼ì´ í™”ìš”ì¼ì´ì–´ì•¼ í•©ë‹ˆë‹¤.'



### 2) í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (Prompt Template)
ì‚¬ìš©ì ì…ë ¥ì²˜ëŸ¼ ì •ì ì¸ í…ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ì •ë³´ë‚˜ ê³ ì •ëœ í…œí”Œë¦¿ ë¬¸ìì—´ì˜ ì¡°í•©ì„ ê¸°ë°˜ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ê°ì²´ì…ë‹ˆë‹¤.

íŒŒì´ì¬ì˜ [f-string](https://realpython.com/python-f-strings/){:target="_blank"}ê³¼ ë¹„ìŠ·í•©ë‹ˆë‹¤.


```python
from langchain.llms import OpenAI
from langchain import PromptTemplate

llm = OpenAI(model_name="gpt-3.5-turbo", openai_api_key=openai_api_key)

# "{location}"ì— ì£¼ì˜í•˜ì„¸ìš”, ì´ê²ƒì€ ë‚˜ì¤‘ì— ë‹¤ë¥¸ ê°’ìœ¼ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤.
template = """
ë‚˜ëŠ” ì •ë§ {location}ì— ì—¬í–‰ ê°€ê³  ì‹¶ì–´. ì–´ë–»ê²Œ í•˜ë©´ ê°ˆ ìˆ˜ ìˆì„ê¹Œ??

ì§§ì€ í•œ ë¬¸ì¥ìœ¼ë¡œ ëŒ€ë‹µí•˜ì„¸ìš”.
"""

prompt = PromptTemplate(
    input_variables=["location"],
    template=template,
)

final_prompt = prompt.format(location="í”„ë‘ìŠ¤")

print (f"ìµœì¢… í”„ë¡¬í”„íŠ¸: {final_prompt}")
print ("-----------")
print (f"LLM ê²°ê³¼ë¬¼: {llm(final_prompt)}")
```

    ìµœì¢… í”„ë¡¬í”„íŠ¸: 
    ë‚˜ëŠ” ì •ë§ í”„ë‘ìŠ¤ì— ì—¬í–‰ ê°€ê³  ì‹¶ì–´. ì–´ë–»ê²Œ í•˜ë©´ ê°ˆ ìˆ˜ ìˆì„ê¹Œ??
    
    ì§§ì€ í•œ ë¬¸ì¥ìœ¼ë¡œ ëŒ€ë‹µí•˜ì„¸ìš”.
    
    -----------
    LLM ê²°ê³¼ë¬¼: ë¹„í–‰ê¸° í‹°ì¼“ì„ ì˜ˆì•½í•˜ì„¸ìš”.


### 3) ì˜ˆì œ ì„ íƒê¸° (example selector)
ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ë™ì ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ì— ë„£ì„ ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ì¼ë ¨ì˜ ì˜ˆì œ ì¤‘ì—ì„œ ì‰½ê²Œ ì„ íƒí•  ìˆ˜ ìˆëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ì‘ì—…ì´ ë¯¸ë¬˜í•˜ê±°ë‚˜ í° ì˜ˆì œ ëª©ë¡ì„ ê°€ì§€ê³  ìˆì„ ë•Œ ìì£¼ ì‚¬ìš©ë©ë‹ˆë‹¤.

ë‹¤ì–‘í•œ ì˜ˆì œ ì„ íƒê¸°ì˜ ìœ í˜•ì„ [ì—¬ê¸°](https://python.langchain.com/docs/modules/model_io/prompts/example_selectors/){:target="_blank"}ì—ì„œ í™•ì¸í•˜ì„¸ìš”.

ì˜ˆì œê°€ ì¤‘ìš”í•œ ì´ìœ (í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§)ì— ëŒ€í•œ ê°œìš”ë¥¼ ì›í•˜ì‹œë©´ [ì´ ë¹„ë””ì˜¤](https://www.youtube.com/watch?v=dOxUroR57xs){:target="_blank"}ë¥¼ í™•ì¸í•˜ì„¸ìš”.


```python
from langchain.prompts.example_selector import SemanticSimilarityExampleSelector
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.prompts import FewShotPromptTemplate, PromptTemplate
from langchain.llms import OpenAI

llm = OpenAI(model_name="gpt-3.5-turbo", openai_api_key=openai_api_key)

example_prompt = PromptTemplate(
    input_variables=["input", "output"],
    template="ìƒ˜í”Œ ì…ë ¥: {input}\nìƒ˜í”Œ ì¶œë ¥: {output}",
)

# ì…ì¶œë ¥ ì˜ˆì‹œ
examples = [
    {"input": "ì„ ì›", "output": "ë°°"},
    {"input": "íŒŒì¼ëŸ¿", "output": "ë¹„í–‰ê¸°"},
    {"input": "ìš´ì „ìˆ˜", "output": "ìë™ì°¨"},
    {"input": "ë‚˜ë¬´", "output": "ë•…"},
    {"input": "ìƒˆ", "output": "ë‘¥ì§€"},
]
```


```python
# SemanticSimilarityExampleSelectorëŠ” ì˜ë¯¸ë¡ ì  ì˜ë¯¸ë¡œ ì…ë ¥ê³¼ ìœ ì‚¬í•œ ì˜ˆì‹œë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
example_selector = SemanticSimilarityExampleSelector.from_examples(
    # ì„ íƒí•  ìˆ˜ ìˆëŠ” ì˜ˆì‹œì˜ ëª©ë¡ì…ë‹ˆë‹¤.
    examples, 
    
   # ì˜ë¯¸ë¡ ì  ìœ ì‚¬ì„±ì„ ì¸¡ì •í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ëŠ” ì„ë² ë”©ì„ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ì„ë² ë”© í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    OpenAIEmbeddings(openai_api_key=openai_api_key), 
    
    # ì´ê²ƒì€ ì„ë² ë”©ì„ ì €ì¥í•˜ê³  ìœ ì‚¬ì„± ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” VectorStore í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    FAISS, 
    
    # ìƒì„±í•  ì˜ˆì‹œì˜ ìˆ˜ì…ë‹ˆë‹¤.
    k=2
)
```


```python
similar_prompt = FewShotPromptTemplate(
    # ì˜ˆì œë¥¼ ì„ íƒí•˜ëŠ” ë° ë„ì›€ì´ ë  ê°ì²´
    example_selector=example_selector,
    
    # í”„ë¡¬í”„íŠ¸
    example_prompt=example_prompt,
    
    # í”„ë¡¬í”„íŠ¸ì˜ ìƒë‹¨ê³¼ í•˜ë‹¨ì— ì¶”ê°€ë  ë§ì¶¤ ì„¤ì •
    prefix="ì•„ì´í…œì´ ë³´í†µ ì–´ë””ì—ì„œ ë°œê²¬ë˜ëŠ”ì§€ ì•Œë ¤ì£¼ì„¸ìš”.",
    suffix="Input: {noun}\nOutput:",
    
    # í”„ë¡¬í”„íŠ¸ê°€ ë°›ì„ ì…ë ¥ ë‚´ìš©
    input_variables=["noun"],
)
```


```python
# ëª…ì‚¬ ì…ë ¥!
my_noun = "í•™ìƒ"

print(similar_prompt.format(noun=my_noun))
```

    ì•„ì´í…œì´ ë³´í†µ ì–´ë””ì—ì„œ ë°œê²¬ë˜ëŠ”ì§€ ì•Œë ¤ì£¼ì„¸ìš”.
    
    ìƒ˜í”Œ ì…ë ¥: ë‚˜ë¬´
    ìƒ˜í”Œ ì¶œë ¥: ë•…
    
    ìƒ˜í”Œ ì…ë ¥: ìƒˆ
    ìƒ˜í”Œ ì¶œë ¥: ë‘¥ì§€
    
    Input: í•™ìƒ
    Output:



```python
llm(similar_prompt.format(noun=my_noun))
```




    'í•™êµ'



### 4) ì¶œë ¥ íŒŒì„œ(Output Parsers)
ëª¨ë¸ì˜ ì¶œë ¥ì„ í˜•ì‹í™”í•˜ëŠ” ìœ ìš©í•œ ë°©ë²•ì…ë‹ˆë‹¤. ì£¼ë¡œ êµ¬ì¡°í™”ëœ ì¶œë ¥ì— ì‚¬ìš©ë©ë‹ˆë‹¤.

ë‘ ê°€ì§€ ì£¼ìš” ê°œë…:

**A. í˜•ì‹ ì§€ì‹œë¬¸ (Format Instructions)** - ì›í•˜ëŠ” ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLMì—ê²Œ ì‘ë‹µì˜ í˜•ì‹ì„ ì–´ë–»ê²Œ í• ì§€ ì•Œë ¤ì£¼ëŠ” ìë™ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸

**B. íŒŒì„œ (Parser)** - ëª¨ë¸ì˜ í…ìŠ¤íŠ¸ ì¶œë ¥ì„ ì›í•˜ëŠ” êµ¬ì¡°(ë³´í†µ json)ë¡œ ì¶”ì¶œí•˜ëŠ” ë°©ë²•


```python
from langchain.output_parsers import StructuredOutputParser, ResponseSchema
from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate
from langchain.llms import OpenAI
```


```python
llm = OpenAI(model_name="gpt-3.5-turbo", openai_api_key=openai_api_key)
```


```python
# ì‘ë‹µì„ ì–´ë–»ê²Œ êµ¬ì¡°í™”í•˜ê¸¸ ì›í•˜ëŠ”ì§€ì— ëŒ€í•œ ê°€ë²¼ìš´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì…ë‹ˆë‹¤.
response_schemas = [
    ResponseSchema(name="bad_string", description="ì´ê²ƒì€ ì˜ëª» í¬ë§·ëœ ì‚¬ìš©ì ì…ë ¥ ë¬¸ìì—´ì…ë‹ˆë‹¤."),
    ResponseSchema(name="good_string", description="ì´ê²ƒì€ ë‹¹ì‹ ì˜ ì‘ë‹µ, ì¬êµ¬ì„±ëœ ì‘ë‹µì…ë‹ˆë‹¤.")
]

# ì¶œë ¥ì„ ì–´ë–»ê²Œ íŒŒì‹±í•˜ê¸¸ ì›í•˜ëŠ”ì§€.
output_parser = StructuredOutputParser.from_response_schemas(response_schemas)
```


```python
# ì¶œë ¥ íŒŒì„œ í”„ë¡¬í”„ë¡œ í…œí”Œë¦¿ í™•ì¸
format_instructions = output_parser.get_format_instructions()
print (format_instructions)
```

    The output should be a markdown code snippet formatted in the following schema, including the leading and trailing "```json" and "```":
    
    ```json
    {
    	"bad_string": string  // ì´ê²ƒì€ ì˜ëª» í¬ë§·ëœ ì‚¬ìš©ì ì…ë ¥ ë¬¸ìì—´ì…ë‹ˆë‹¤.
    	"good_string": string  // ì´ê²ƒì€ ë‹¹ì‹ ì˜ ì‘ë‹µ, ì¬êµ¬ì„±ëœ ì‘ë‹µì…ë‹ˆë‹¤.
    }
    ```



```python
template = """
ì‚¬ìš©ìë¡œë¶€í„° ì˜ëª» ì‘ì„±ëœ ë¬¸ìì—´ì„ ë°›ê²Œ ë  ê²ƒì…ë‹ˆë‹¤.
ë‹¤ì‹œ ì‘ì„±í•˜ê³  ëª¨ë“  ë‹¨ì–´ì˜ ì² ìê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.

{format_instructions}

% ì‚¬ìš©ì ì…ë ¥:
{user_input}

% ì‘ë‹µ:
"""

prompt = PromptTemplate(
    input_variables=["user_input"],
    partial_variables={"format_instructions": format_instructions},
    template=template
)

promptValue = prompt.format(user_input="í•œê·¹ì— ì˜¤ì‹ ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤.")

print(promptValue)
```

    
    ì‚¬ìš©ìë¡œë¶€í„° ì˜ëª» ì‘ì„±ëœ ë¬¸ìì—´ì„ ë°›ê²Œ ë  ê²ƒì…ë‹ˆë‹¤.
    ë‹¤ì‹œ ì‘ì„±í•˜ê³  ëª¨ë“  ë‹¨ì–´ì˜ ì² ìê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.
    
    The output should be a markdown code snippet formatted in the following schema, including the leading and trailing "```json" and "```":
    
    ```json
    {
    	"bad_string": string  // ì´ê²ƒì€ ì˜ëª» í¬ë§·ëœ ì‚¬ìš©ì ì…ë ¥ ë¬¸ìì—´ì…ë‹ˆë‹¤.
    	"good_string": string  // ì´ê²ƒì€ ë‹¹ì‹ ì˜ ì‘ë‹µ, ì¬êµ¬ì„±ëœ ì‘ë‹µì…ë‹ˆë‹¤.
    }
    ```
    
    % ì‚¬ìš©ì ì…ë ¥:
    í•œê·¹ì— ì˜¤ì‹ ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤.
    
    % ì‘ë‹µ:
    



```python
llm_output = llm(promptValue)
llm_output
```




    '```json\n{\n\t"bad_string": "í•œê·¹ì— ì˜¤ì‹ ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤.",\n\t"good_string": "í•œêµ­ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤."\n}\n```'




```python
output_parser.parse(llm_output)
```




    {'bad_string': 'í•œê·¹ì— ì˜¤ì‹ ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤.', 'good_string': 'í•œêµ­ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤.'}



## 4. ìƒ‰ì¸(Index) - LLMì´ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ë¬¸ì„œ êµ¬ì¡°í™”í•˜ê¸°
### 1) ë¬¸ì„œ ë¡œë”(Document Loaders)
ë‹¤ë¥¸ ì†ŒìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì‰¬ìš´ ë°©ë²•ë“¤ì…ë‹ˆë‹¤. [OpenAI í”ŒëŸ¬ê·¸ì¸](https://openai.com/blog/chatgpt-plugins){:target="_blank"} [íŠ¹íˆ ê²€ìƒ‰ í”ŒëŸ¬ê·¸ì¸](https://github.com/openai/chatgpt-retrieval-plugin){:target="_blank"}ê³¼ ê³µìœ  ê¸°ëŠ¥ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.

ì—¬ê¸°ì— ë¬¸ì„œ ë¡œë”ì˜ [í° ëª©ë¡](https://python.langchain.com/en/latest/modules/indexes/document_loaders.html){:target="_blank"}ì„ í™•ì¸í•˜ì„¸ìš”. [Llama Index](https://llamahub.ai/){:target="_blank"}ì—ë„ ë§ì€ ì •ë³´ê°€ ìˆìŠµë‹ˆë‹¤.


```python
from langchain.document_loaders import HNLoader
```


```python
loader = HNLoader("https://news.ycombinator.com/item?id=34422627")
```


```python
data = loader.load()
```


```python
print (f"{len(data)}ê°œì˜ ëŒ“ê¸€")
print (f"ìƒ˜í”Œ:\n\n{''.join([x.page_content[:150] for x in data[:2]])}")
```

    76ê°œì˜ ëŒ“ê¸€
    ìƒ˜í”Œ:
    
    Ozzie_osman 7 months ago  
                 | next [â€“] 
    
    LangChain is awesome. For people not sure what it's doing, large language models (LLMs) are very Ozzie_osman 7 months ago  
                 | parent | next [â€“] 
    
    Also, another library to check out is GPT Index (https://github.com/jerryjliu/gpt_index)


### 2) í…ìŠ¤íŠ¸ ë¶„í• ê¸°(Text Splitters)
ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ë¬¸ì„œê°€ LLMì—ê²Œ ë„ˆë¬´ ê¸¸ë‹¤ê³  ëŠê»´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤(ì˜ˆì»¨ëŒ€ ì±… ê°™ì€ ê²½ìš°). ì´ëŸ´ ë•Œ í…ìŠ¤íŠ¸ë¥¼ ì—¬ëŸ¬ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ ì•¼ í•©ë‹ˆë‹¤. ì´ë•Œ í…ìŠ¤íŠ¸ ë¶„í• ê¸°ê°€ ë„ì›€ì´ ë©ë‹ˆë‹¤.

í…ìŠ¤íŠ¸ë¥¼ ì—¬ëŸ¬ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ì—¬ëŸ¬ ê°€ì§€ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤. ì–´ë–¤ ê²ƒì´ ê°€ì¥ ì í•©í•œì§€ ì•Œì•„ë³´ê¸° ìœ„í•´ [ë‹¤ì–‘í•œ ë°©ë²•](https://python.langchain.com/en/latest/modules/indexes/text_splitters.html){:target="_blank"}ì„ ì‹¤í—˜í•´ë³´ì„¸ìš”.


```python
from langchain.text_splitter import RecursiveCharacterTextSplitter
```


```python
import requests
url = "https://raw.githubusercontent.com/hmkim312/datas/main/Langchain/worked.txt"
response = requests.get(url)
pg_work = response.text
print (f"{len([pg_work])}ê°œì˜ ë¬¸ì„œ")
```

    1ê°œì˜ ë¬¸ì„œ



```python
text_splitter = RecursiveCharacterTextSplitter(
    # ë³´ì—¬ì£¼ê¸° ìœ„í•´ ì‘ì€ í¬ê¸°ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
    chunk_size = 150,
    chunk_overlap  = 20,
)

texts = text_splitter.create_documents([pg_work])
```


```python
print (f"{len(texts)}ê°œì˜ ë¬¸ì„œ")
```

    614ê°œì˜ ë¬¸ì„œ



```python
print ("ë¯¸ë¦¬ë³´ê¸°:")
print (texts[0].page_content, "\n")
print (texts[1].page_content)
```

    ë¯¸ë¦¬ë³´ê¸°:
    February 2021Before college the two main things I worked on, outside of school,
    were writing and programming. I didn't write essays. I wrote what 
    
    beginning writers were supposed to write then, and probably still
    are: short stories. My stories were awful. They had hardly any plot,


### 3) ê²€ìƒ‰ê¸° (Retrievers)
ë¬¸ì„œë¥¼ ì–¸ì–´ ëª¨ë¸ê³¼ ì‰½ê²Œ ê²°í•©í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ê²€ìƒ‰ê¸°ì—ëŠ” ì—¬ëŸ¬ ì¢…ë¥˜ê°€ ìˆìœ¼ë©°, ê°€ì¥ ë„ë¦¬ ì§€ì›ë˜ëŠ” ê²ƒì€ VectoreStoreRetrieverì…ë‹ˆë‹¤.


```python
import requests

url = "https://raw.githubusercontent.com/hmkim312/datas/main/Langchain/disc.txt"
response = requests.get(url)

# íŒŒì¼ì„ ì €ì¥í•˜ê¸°
file_name = "disc.txt"
with open(file_name, 'w', encoding="utf-8") as f:
    f.write(response.text)
```


```python
from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings

loader = TextLoader(file_name)
documents = loader.load()
```


```python
# ë¶„í• ê¸° ì¤€ë¹„
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)

# ë¬¸ì„œ ë¶„í• 
texts = text_splitter.split_documents(documents)

# ì„ë² ë”© ì¤€ë¹„
embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)

# í…ìŠ¤íŠ¸ ì„ë² ë”©
db = FAISS.from_documents(texts, embeddings)
```


```python
# ê²€ìƒ‰ê¸°ë¥¼ ì´ˆê¸°í™”í•˜ì„¸ìš”. ë‹¨ì§€ 1ê°œì˜ ë¬¸ì„œë§Œ ë°˜í™˜í•˜ë„ë¡ ìš”ì²­í•˜ì„¸ìš”.
retriever = db.as_retriever()
```


```python
retriever
```




    VectorStoreRetriever(tags=['FAISS'], metadata=None, vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x7f2c31bf5b70>, search_type='similarity', search_kwargs={})




```python
docs = retriever.get_relevant_documents("ì €ìëŠ” ì–´ë–¤ ì¢…ë¥˜ì˜ ê²ƒë“¤ì„ ë§Œë“¤ê³  ì‹¶ì—ˆë‚˜ìš”?")
```


```python
print("\n\n".join([x.page_content[:200] for x in docs[:2]]))
```

    January 2017Because biographies of famous scientists tend to 
    edit out their mistakes, we underestimate the 
    degree of risk they were willing to take.
    And because anything a famous scientist did that
    
    
    seemed roughly equally promising. No one knew yet
    what the payoff would be for inventing what we
    now call physics; if they had, more people would 
    have been working on it. And alchemy and theology
    wer


### 4) VectorStores
ë²¡í„°ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤. ê°€ì¥ ì¸ê¸° ìˆëŠ” ê²ƒë“¤ì€ [Pinecone](https://www.pinecone.io/){:target="_blank"}ì™€ [Weaviate](https://weaviate.io/){:target="_blank"}ì…ë‹ˆë‹¤. OpenAIì˜ [ê²€ìƒ‰ê¸° ë¬¸ì„œ](https://github.com/openai/chatgpt-retrieval-plugin#choosing-a-vector-database){:target="_blank"}ì—ì„œ ë” ë§ì€ ì˜ˆì‹œë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. [Chroma](https://www.trychroma.com/){:target="_blank"}ì™€ [FAISS](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/){:target="_blank"}ëŠ” ë¡œì»¬ì—ì„œ ì‰½ê²Œ ì‘ì—…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ê°œë…ì ìœ¼ë¡œ, ì„ë² ë”©(ë²¡í„°)ì„ ìœ„í•œ ì—´ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ ìœ„í•œ ì—´ì´ ìˆëŠ” í…Œì´ë¸”ë¡œ ìƒê°í•˜ì‹­ì‹œì˜¤.

*ì˜ˆì‹œ*

| ì„ë² ë”©(Embedding)      | ë©”íƒ€ë°ì´í„°(Metadata) |
| ----------- | ----------- |
| [-0.00015641732898075134, -0.003165106289088726, ...]      | {'date' : '1/2/23}       |
| [-0.00035465431654651654, 1.4654131651654516546, ...]   | {'date' : '1/3/23}        |


```python
import requests

url = "https://github.com/hmkim312/datas/blob/main/Langchain/worked.txt"
response = requests.get(url)

# íŒŒì¼ì„ ì €ì¥í•˜ê¸°
file_name = "worked.txt"
with open(file_name, 'w', encoding="utf-8") as f:
    f.write(response.text)
```


```python
from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings

loader = TextLoader(file_name)
documents = loader.load()

# ë¶„í• ê¸° ì¤€ë¹„
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)

# í…ìŠ¤íŠ¸ ë¶„í• 
texts = text_splitter.split_documents(documents)

# ì„ë² ë”© ì¤€ë¹„
embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
```


```python
print (f"{len(texts)}ê°œì˜ ë¬¸ì„œ")
```

    98ê°œì˜ ë¬¸ì„œ



```python
embedding_list = embeddings.embed_documents([text.page_content for text in texts])
```


```python
print (f"{len(embedding_list)}ê°œì˜ ì„ë² ë”©")
print (f"ìƒ˜í”Œ: {embedding_list[0][:3]}...")
```

    98ê°œì˜ ì„ë² ë”©
    ìƒ˜í”Œ: [-0.01545365036202117, 0.012095730552875413, 0.0013115743425161806]...


ë²¡í„°ìŠ¤í† ì–´ëŠ” ì„ë² ë”©ì„ ì €ì¥í•˜ê³  ì‰½ê²Œ ê²€ìƒ‰í•  ìˆ˜ ìˆê²Œ ë§Œë“­ë‹ˆë‹¤.

## 5. ë©”ëª¨ë¦¬
LLMì— ì •ë³´ë¥¼ ê¸°ì–µí•˜ê²Œ ë„ì™€ì¤ë‹ˆë‹¤.

ë©”ëª¨ë¦¬ëŠ” ì•½ê°„ ëª¨í˜¸í•œ ìš©ì–´ì…ë‹ˆë‹¤. ê³¼ê±°ì— ëŒ€í™”í•œ ì •ë³´ë¥¼ ê°„ë‹¨í•˜ê²Œ ê¸°ì–µí•˜ëŠ” ê²ƒì—ì„œë¶€í„° ë” ë³µì¡í•œ ì •ë³´ ê²€ìƒ‰ê¹Œì§€ ë‹¤ì–‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì—¬ê¸°ì„œëŠ” ì±„íŒ… ë©”ì‹œì§€ ì‚¬ìš© ì‚¬ë¡€ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•˜ê² ìŠµë‹ˆë‹¤. ì´ê²ƒì€ ì±„íŒ… ë´‡ì— ì‚¬ìš©ë©ë‹ˆë‹¤.

ë§ì€ ì¢…ë¥˜ì˜ ë©”ëª¨ë¦¬ê°€ ìˆìŠµë‹ˆë‹¤. [ë¬¸ì„œ](https://python.langchain.com/en/latest/modules/memory/how_to_guides.html){:target="_blank"}ë¥¼ íƒìƒ‰í•˜ì—¬ ë‹¹ì‹ ì˜ ì‚¬ìš© ì‚¬ë¡€ì— ì–´ëŠ ê²ƒì´ ê°€ì¥ ì í•©í•œì§€ í™•ì¸í•´ ë³´ì„¸ìš”.

### 1) ì±„íŒ… ë©”ì„¸ì§€ ê¸°ë¡


```python
from langchain.memory import ChatMessageHistory
from langchain.chat_models import ChatOpenAI

chat = ChatOpenAI(temperature=0, openai_api_key=openai_api_key)

history = ChatMessageHistory()

history.add_ai_message("ì•ˆë…•!")

history.add_user_message("í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?")
```


```python
history.messages
```




    [AIMessage(content='ì•ˆë…•!', additional_kwargs={}, example=False),
     HumanMessage(content='í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?', additional_kwargs={}, example=False)]




```python
ai_response = chat(history.messages)
ai_response
```




    AIMessage(content='í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì´ì•¼.', additional_kwargs={}, example=False)




```python
history.add_ai_message(ai_response.content)
history.messages
```




    [AIMessage(content='ì•ˆë…•!', additional_kwargs={}, example=False),
     HumanMessage(content='í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?', additional_kwargs={}, example=False),
     AIMessage(content='í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì´ì•¼.', additional_kwargs={}, example=False)]



## 6. ì²´ì¸(Chains)
ë‹¤ì–‘í•œ LLM í˜¸ì¶œê³¼ ìë™ìœ¼ë¡œ ìˆ˜í–‰ë˜ëŠ” ë™ì‘ì„ ê²°í•©í•©ë‹ˆë‹¤.

ì˜ˆ: ìš”ì•½ #1, ìš”ì•½ #2, ìš”ì•½ #3 > ìµœì¢… ìš”ì•½

ë‹¤ì–‘í•œ ìš”ì•½ ì²´ì¸ ìœ í˜•ì— ëŒ€í•œ ì„¤ëª…ì„ ìœ„í•œ [ì´ ë¹„ë””ì˜¤](https://www.youtube.com/watch?v=f9_BWhCI4Zo&t=2s){:target="_blank"}ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.

ì²´ì¸ì˜ [ë§ì€ ì‘ìš© í”„ë¡œê·¸ë¨ë“¤](https://python.langchain.com/en/latest/modules/chains/how_to_guides.html){:target="_blank"}ì´ ìˆìœ¼ë¯€ë¡œ, ë‹¹ì‹ ì˜ ì‚¬ìš© ì‚¬ë¡€ì— ê°€ì¥ ì í•©í•œ ê²ƒì„ ì°¾ì•„ë³´ì„¸ìš”.

ìš°ë¦¬ëŠ” ê·¸ ì¤‘ ë‘ ê°€ì§€ë¥¼ ë‹¤ë£° ê²ƒì…ë‹ˆë‹¤:

### 1). ë‹¨ìˆœ ìˆœì°¨ ì²´ì¸ (Simple Sequential Chains)

LLMì˜ ì¶œë ¥ì„ ë‹¤ë¥¸ ê²ƒì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê°„ë‹¨í•œ ì²´ì¸ì…ë‹ˆë‹¤. ì‘ì—…ì„ ë‚˜ëˆ„ëŠ” ë° ìœ ìš©í•˜ë©°(ê·¸ë¦¬ê³  LLMì„ ì§‘ì¤‘ì‹œí‚¤ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤)


```python
from langchain.llms import OpenAI
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.chains import SimpleSequentialChain

llm = OpenAI(temperature=1, openai_api_key=openai_api_key, max_tokens=1048)
```


```python
template = """ë‹¹ì‹ ì€ ì‚¬ìš©ìê°€ ì œì•ˆí•˜ëŠ” ì§€ì—­ì˜ ì „í†µì ì¸ ìš”ë¦¬ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤..
% ì‚¬ìš©ì ìœ„ì¹˜
{user_location}

% ì‘ë‹µ:
"""
prompt_template = PromptTemplate(input_variables=["user_location"], template=template)

# ì§€ì—­
location_chain = LLMChain(llm=llm, prompt=prompt_template)
```


```python
template = """ìŒì‹ì„ ì£¼ë©´ ì§‘ì—ì„œ ì–´ë–»ê²Œ ë§Œë“œëŠ”ì§€ ê°„ë‹¨í•˜ê³  ì‰¬ìš´ ë ˆì‹œí”¼ë¥¼ ì œê³µí•˜ì„¸ìš”.
% ìŒì‹
{user_meal}

% ì‘ë‹µ:
"""
prompt_template = PromptTemplate(input_variables=["user_meal"], template=template)

# ìŒì‹
meal_chain = LLMChain(llm=llm, prompt=prompt_template)
```


```python
overall_chain = SimpleSequentialChain(chains=[location_chain, meal_chain], verbose=True)
```


```python
review = overall_chain.run("rome")
```

    
    
    [1m> Entering new SimpleSequentialChain chain...[0m
    [36;1m[1;3më¡œë§ˆì˜ ì „í†µì ì¸ ìš”ë¦¬ë¡œëŠ” í”¼ìê°€ ëŒ€í‘œì ìœ¼ë¡œ ìˆìŠµë‹ˆë‹¤. ë¡œë§ˆì˜ í”¼ìëŠ” "ë¡œë§ˆ í”¼ì"ë¼ê³ ë„ ë¶ˆë¦¬ë©°, í† ë§ˆí† í”¼í´, ëª¨ì§œë ë¼ ì¹˜ì¦ˆ, í—ˆë¸Œ, ì˜¤ì¼, ë¡œë©”ì¸ ì–‘ë… ê·¸ë¦¬ê³  ë¸”ë™ ì˜¬ë¦¬ë¸Œê°€ ì£¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤. ë˜í•œ "ê°íŠ€ê¹Œë¥´ë³´ë‚˜ë¼"(Gnocchi alla Romana)ë¼ê³  ë¶ˆë¦¬ëŠ” ì£¼ë°© ì¬ë£Œë¡œ ê°ìì™€ ê°™ì€ ì‹ë£Œí’ˆì„ ì‚¬ìš©í•˜ì—¬ ë§Œë“  ìš”ë¦¬ë„ ìœ ëª…í•©ë‹ˆë‹¤. ë˜í•œ "ê·¸ë¼íƒ•"(Carbonara)ê³¼ "ì¹´ë ˆë¼ ë¹„ëƒ"(Cacio e Pepe)ë„ ë¡œë§ˆì˜ íŠ¹ìƒ‰ ìˆëŠ” ìš”ë¦¬ì…ë‹ˆë‹¤.[0m
    [33;1m[1;3më¡œë§ˆì˜ í”¼ìë¥¼ ë§Œë“œëŠ” ë°©ë²•
    
    í•„ìš”í•œ ì¬ë£Œ: 
    - í¬ê¸° ì‘ì€ í”¼ì ë„ìš° 
    - í† ë§ˆí† í”¼í´
    - ë² ì´ì»¨ ì•Œê°±ì´
    - ëª¨ì§œë ë¼ ì¹˜ì¦ˆ
    - í—ˆë¸Œ
    - ì˜¬ë¦¬ë¸Œ
    - ì˜¤ì¼
    - ë¡œë©”ì¸ ì–‘ë…
    - ë¯¸ë¦¬ ê¹Œê¸°í•œ ë¸”ë™ ì˜¬ë¦¬ë¸Œ
    
    ë§Œë“œëŠ” ë°©ë²•:
    
    1. ë¨¼ì € í”¼ì ë„ìš°ë¥¼ ë¶ˆë¦¬ê³  ë‹¤ì–‘í•œ ì¬ë£Œë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.
    
    2. ë‹¤ì´ì–´íŠ¸ ì˜¤ì¼ë¡œ ë‚©ì‘í•˜ê²Œ ë°”í…€ì„ ëŒë ¤ ì˜¤ì¼ì„ ë¿Œë ¤ì£¼ê³  í† ë§ˆí†  í”¼í´ì„ ë¿Œë¦½ë‹ˆë‹¤.
    
    3. ë‹¤ì–‘í•œ ì¬ë£Œë¥¼ ë°°ì—´í•´ ì¤ë‹ˆë‹¤. ë¨¼ì € ë² ì´ì»¨ ì•Œê°±ì´ì´ë©° ê·¸ ë‹¤ìŒì— ëª¨ì§œë ë¼ ì¹˜ì¦ˆ, í—ˆë¸Œ, ì˜¬ë¦¬ë¸Œ, ë¡œë©”ì¸ ì–‘ë…ì„ ì˜¬ë ¤ì¤ë‹ˆë‹¤.
    
    4. ë§ˆì§€ë§‰ìœ¼ë¡œ ë¸”ë™ ì˜¬ë¦¬ë¸Œë¥¼ ìƒë‹¨ì— ê°€ë³ê²Œ ë¿Œë ¤ ì¤ë‹ˆë‹¤.
    
    5. ê·¸ë¦¬ê³  êµ¬ìš´ë‹¤ê³  ë”°ë¡œ ì„¤ì •í•´ ë†“ì€ ì˜¤ë¸ì— ë„£ì–´ ì¶©ë¶„íˆ êµ¬ì›Œ ë‚´ì¤ë‹ˆë‹¤. 
    
    6. ì—´ëŒ€ ëª¨ë“  ì¬ë£Œê°€ ìƒí˜¸ ì‘ìš©í•˜ì—¬ ë§›ìˆê²Œ êµ¬ì›Œì§€ë©´ ë¡œë§ˆ í”¼ìê°€ ë§Œë“¤ì–´ì§‘ë‹ˆë‹¤.[0m
    
    [1m> Finished chain.[0m


### 2) ìš”ì•½ ì²´ì¸ (Summarization Chain)

ê¸´ ì—¬ëŸ¬ ë¬¸ì„œë¥¼ ì‰½ê²Œ í›‘ì–´ë³¼ ìˆ˜ ìˆê³  ìš”ì•½ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§µ-ë¦¬ë“€ìŠ¤ ì™¸ì˜ ë‹¤ë¥¸ ì²´ì¸ ìœ í˜•ì— ëŒ€í•´ì„œëŠ” [ì´ ë¹„ë””ì˜¤](https://www.youtube.com/watch?v=f9_BWhCI4Zo){:target="_blank"}ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.


```python
import requests

url = "https://raw.githubusercontent.com/hmkim312/datas/main/Langchain/disc_ko.txt"
response = requests.get(url)

# íŒŒì¼ì„ ì €ì¥í•˜ê¸°
file_name = "disc_ko.txt"
with open(file_name, 'w', encoding="utf-8") as f:
    f.write(response.text)
```


```python
from langchain.chains.summarize import load_summarize_chain
from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

loader = TextLoader('disc_ko.txt')
documents = loader.load()

# ë¶„í• ê¸° ì¤€ë¹„
text_splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=50)

# ë¶„í• 
texts = text_splitter.split_documents(documents)

chain = load_summarize_chain(llm, chain_type="map_reduce", verbose=True)
chain.run(texts)
```

    
    
    [1m> Entering new MapReduceDocumentsChain chain...[0m
    
    
    [1m> Entering new LLMChain chain...[0m
    Prompt after formatting:
    [32;1m[1;3mWrite a concise summary of the following:
    
    
    "**ì¸ê³µì§€ëŠ¥ê³¼ ì¸ê°„ì˜ í¬ë§ì  ë™ë°˜**
    
    ìš°ë¦¬ ì‹œëŒ€ëŠ” ì¸ê³µì§€ëŠ¥(AI)ê³¼ ì¸ê°„ì´ í•¨ê»˜ ë°œì „í•˜ë©° ì„œë¡œ ë³´ì™„ì ì¸ ê´€ê³„ë¥¼ í˜•ì„±í•˜ëŠ” ì‹œëŒ€ë¡œ ë¶ˆë¦°ë‹¤. ê³¼ê±°ì—ëŠ” ê¸°ìˆ ì  ë°œì „ì´ ì‚¬ëŒì˜ ì¼ìë¦¬ë¥¼ ìœ„í˜‘í•˜ëŠ” ê²ƒìœ¼ë¡œë§Œ ì—¬ê²¨ì¡Œë‹¤. ê·¸ëŸ¬ë‚˜ ì§€ê¸ˆì€ AIê°€ ì¸ê°„ì˜ ì‚¶ì˜ ì§ˆì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ê¸°ì—¬í•˜ë©°, ìš°ë¦¬ì˜ ì¼ìƒìƒí™œì—ì„œ ë§ì€ ë„ì›€ì„ ì£¼ê³  ìˆë‹¤. 
    
    ë¬´ì—‡ë³´ë‹¤, AIëŠ” ìš°ë¦¬ê°€ ì ‘ê·¼í•˜ê¸° ì–´ë ¤ì› ë˜ ë§ì€ ì§€ì‹ê³¼ ì •ë³´ë¥¼ ìš°ë¦¬ ì†ì•ˆì— ê°€ì ¸ë‹¤ì¤€ë‹¤. ì˜ë£Œ, êµìœ¡, ì—°êµ¬ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ AIëŠ” ë§ì¶¤í™”ëœ ì •ë³´ì™€ ì†”ë£¨ì…˜ì„ ì œê³µí•˜ë©°, ì´ë¥¼ í†µí•´ ì‚¬ëŒë“¤ì€ ë” ë‚˜ì€ ê²°ì •ì„ ë‚´ë¦¬ê³  íš¨ìœ¨ì ì¸ ìƒí™œì„ ì´ëŒì–´ ë‚¸ë‹¤. ìš°ë¦¬ì˜ ì§€ëŠ¥ê³¼ AIì˜ ëŠ¥ë ¥ì´ ìœµí•©ë¨ìœ¼ë¡œì¨, ì¸ë¥˜ëŠ” ì „ë¡€ ì—†ëŠ” í˜ì‹ ì ì¸ ë°œê²¬ê³¼ ë³€í™”ì˜ ì‹œëŒ€ë¥¼ ë§ì´í•˜ê²Œ ëœë‹¤.
    
    ë”ë¶ˆì–´, ì¸ê³µì§€ëŠ¥ì€ ì¸ê°„ì˜ ì°½ì¡°ë ¥ê³¼ ê°ì„±, ê·¸ë¦¬ê³  ê²½í—˜ì„ ê°•ì¡°í•˜ê²Œ ë§Œë“ ë‹¤. AIê°€ ë‹¨ìˆœ ë°˜ë³µì ì¸ ì—…ë¬´ë‚˜ ë°ì´í„° ë¶„ì„ ë“±ì˜ ì‘ì—…ì„ ë‹´ë‹¹í•¨ìœ¼ë¡œì¨, ì¸ê°„ì€ ë” ê¹Šì´ ìˆëŠ” ì°½ì¡°ì ì¸ í™œë™ì— ëª°ë‘í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤. ì´ëŸ° ê´€ê³„ ì†ì—ì„œ ì¸ê°„ê³¼ ê¸°ìˆ ì€ ë”ìš± ê°€ê¹Œì›Œì§€ë©°, ê·¸ ê²°ê³¼ë¡œ ë” í’ìš”ë¡œìš´ ë¯¸ë˜ë¥¼ ìƒìƒí•˜ê²Œ ëœë‹¤."
    
    
    CONCISE SUMMARY:[0m
    
    [1m> Finished chain.[0m
    
    
    [1m> Entering new LLMChain chain...[0m
    Prompt after formatting:
    [32;1m[1;3mWrite a concise summary of the following:
    
    
    " ìš°ë¦¬ ì‹œëŒ€ëŠ” ì¸ê³µì§€ëŠ¥ê³¼ ì¸ê°„ì´ ì„œë¡œ ë³´ì™„í•˜ë©° í•¨ê»˜ ë°œì „í•˜ëŠ” ê´€ê³„ë¡œ ë°œì „í•˜ê³  ìˆìœ¼ë©°, AIê°€ ì¸ê°„ë“¤ì˜ ì¼ìƒ ìƒí™œì„ í–¥ìƒì‹œí‚¤ê³  ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ ì˜ì—­ì—ì„œ ë§ì¶¤í™”ëœ ì •ë³´ì™€ ì†”ë£¨ì…˜ì„ ì œê³µí•˜ê³  ìˆë‹¤. AIëŠ” ë˜í•œ ì°½ì¡°ì ì¸ í™œë™ì„ ì¦ì§„ì‹œí‚¤ë©°, ì „ë¡€ ì—†ëŠ” í˜ì‹ ì  ë³€í™”ë¡œ í¬ë§ì ì¸ ë¯¸ë˜ë¥¼ ì—´ê³  ìˆë‹¤."
    
    
    CONCISE SUMMARY:[0m
    
    [1m> Finished chain.[0m
    
    [1m> Finished chain.[0m





    ' ì¸ê³µì§€ëŠ¥ê³¼ ì¸ê°„ì´ ì„œë¡œ ë³´ì™„í•˜ë©° í•¨ê»˜ ë°œì „í•˜ëŠ” ê´€ê³„ë¡œ ë°œì „í•˜ê³  ìˆëŠ” ìš°ë¦¬ ì‹œëŒ€ì—ì„œ AIëŠ” ì¸ê°„ë“¤ì˜ ìƒí™œì„ ê°œì„ í•˜ê³  ë§ì¶¤í™”ëœ ì •ë³´ì™€ ì†”ë£¨ì…˜ì„ ì œê³µí•˜ë©°, ì°½ì¡°ì ì¸ í™œë™ì„ ë³´ì¥í•˜ê³  ìˆìœ¼ë©°, í˜ì‹ ì  ë³€í™”ë¡œ í¬ë§ì ì¸ ë¯¸ë˜ë¥¼ ì—´ê³  ìˆë‹¤.'



## 7. ì—ì´ì „íŠ¸ ğŸ¤–ğŸ¤–

ê³µì‹ LangChain ë¬¸ì„œì—ì„œëŠ” ì—ì´ì „íŠ¸ë¥¼ ì™„ë²½í•˜ê²Œ ì„¤ëª…í•˜ê³  ìˆìŠµë‹ˆë‹¤:
> ì–´ë–¤ ì‘ìš© í”„ë¡œê·¸ë¨ì€ LLMs/ë‹¤ë¥¸ ë„êµ¬ì— ëŒ€í•œ ì‚¬ì „ì— ì •í•´ì§„ ì—°ì‡„ í˜¸ì¶œë§Œì„ í•„ìš”ë¡œ í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë©°, ì‚¬ìš©ìì˜ ì…ë ¥ì— ë”°ë¼ **ì•Œ ìˆ˜ ì—†ëŠ” ì—°ì‡„**ê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ìœ í˜•ì˜ ì—°ì‡„ì—ì„œëŠ” ì—¬ëŸ¬ ë„êµ¬ì— ì•¡ì„¸ìŠ¤í•  ìˆ˜ ìˆëŠ” "ì—ì´ì „íŠ¸"ê°€ ìˆìŠµë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì…ë ¥ì— ë”°ë¼ ì—ì´ì „íŠ¸ëŠ” ì´ëŸ¬í•œ ë„êµ¬ ì¤‘ ì–´ë–¤ ê²ƒì„ **í˜¸ì¶œí• ì§€ ê²°ì •**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ê¸°ë³¸ì ìœ¼ë¡œ LLMì„ í…ìŠ¤íŠ¸ ì¶œë ¥ë¿ë§Œ ì•„ë‹ˆë¼ ì˜ì‚¬ ê²°ì •ì„ ìœ„í•´ ì‚¬ìš©í•©ë‹ˆë‹¤.

Sam Altmanì€ LLMì´ ì¢‹ì€ '[ì¶”ë¡  ì—”ì§„](https://www.youtube.com/watch?v=L_Guz73e6fw&t=867s){:target="_blank"}'ì´ë¼ê³  ê°•ì¡°í•©ë‹ˆë‹¤. ì—ì´ì „íŠ¸ëŠ” ì´ë¥¼ í™œìš©í•©ë‹ˆë‹¤.

### 1) ì—ì´ì „íŠ¸

ì˜ì‚¬ ê²°ì •ì„ ì£¼ë„í•˜ëŠ” ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤.

ë” êµ¬ì²´ì ìœ¼ë¡œ, ì—ì´ì „íŠ¸ëŠ” ì…ë ¥ì„ ë°›ì•„ë“¤ì´ê³  í–‰ë™ ì…ë ¥ê³¼ í•¨ê»˜ ì·¨í•  í–‰ë™ì— ëŒ€í•œ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì—ì´ì „íŠ¸ë“¤ (ë‹¤ë¥¸ ì‚¬ìš© ì‚¬ë¡€ì— ë” ì í•©í•œ)ì„ [ì—¬ê¸°](https://python.langchain.com/en/latest/modules/agents/agent_types.html){:target="_blank"}ì—ì„œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 2) ë„êµ¬

ì—ì´ì „íŠ¸ì˜ 'ëŠ¥ë ¥'ì…ë‹ˆë‹¤. ì´ê²ƒì€ LLMs (ê·¸ë¦¬ê³  ì—ì´ì „íŠ¸)ê°€ ì‰½ê²Œ ìƒí˜¸ ì‘ìš©í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” í•¨ìˆ˜ ìœ„ì˜ ì¶”ìƒí™”ì…ë‹ˆë‹¤. ì˜ˆ: êµ¬ê¸€ ê²€ìƒ‰.

ì´ ì˜ì—­ì€ [OpenAI í”ŒëŸ¬ê·¸ì¸](https://platform.openai.com/docs/plugins/introduction){:target="_blank"}ê³¼ ê³µí†µì ì„ ê³µìœ í•©ë‹ˆë‹¤.

### 3) íˆ´í‚·

ë‹¹ì‹ ì˜ ì—ì´ì „íŠ¸ê°€ ì„ íƒí•  ìˆ˜ ìˆëŠ” ë„êµ¬ ê·¸ë£¹ì…ë‹ˆë‹¤.

ì´ì œ ëª¨ë“  ê²ƒì„ í•¨ê»˜ ê°€ì ¸ì™€ ë´…ì‹œë‹¤:


```python
from langchain.agents import load_tools
from langchain.agents import initialize_agent
from langchain.llms import OpenAI
import json

llm = OpenAI(temperature=0, openai_api_key=openai_api_key)
```


```python
# SerpApiëŠ” "Search Engine Results Page API"ì˜ ì•½ì–´ë¡œ, ê²€ìƒ‰ ì—”ì§„ ê²°ê³¼ í˜ì´ì§€ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•œ ì„œë¹„ìŠ¤ë‚˜ ë„êµ¬ì…ë‹ˆë‹¤
serpapi_api_key="YOUR SERPAPI API KEY"
```


```python
toolkit = load_tools(["serpapi"], llm=llm, serpapi_api_key=serpapi_api_key)
```


```python
agent = initialize_agent(toolkit, llm, agent="zero-shot-react-description", verbose=True, return_intermediate_steps=True)
```


```python
response = agent({"input":"creepì€ ëˆ„êµ¬ì˜ ë…¸ë˜ì¸ê°€ìš”?"})
```

    
    
    [1m> Entering new AgentExecutor chain...[0m
    [32;1m[1;3m ë…¸ë˜ë¥¼ ì°¾ì•„ë³´ëŠ” ê²ƒì´ ì¢‹ì„ ê²ƒ ê°™ë‹¤.
    Action: Search
    Action Input: "creep" song[0m
    Observation: [36;1m[1;3m"Creep" is the debut single by the English rock band Radiohead, released on 21 September 1992. It appeared on their debut studio album, Pablo Honey (1993).[0m
    Thought:[32;1m[1;3m ë¼ë””ì˜¤í—¤ë“œì˜ ë…¸ë˜ë¼ëŠ” ê²ƒì„ ì•Œì•˜ë‹¤.
    Final Answer: "Creep"ì€ ë¼ë””ì˜¤í—¤ë“œì˜ ë…¸ë˜ì…ë‹ˆë‹¤.[0m
    
    [1m> Finished chain.[0m



```python
print(response["intermediate_steps"])
```

    [(AgentAction(tool='Search', tool_input='creep" song', log=' ë…¸ë˜ë¥¼ ì°¾ì•„ë³´ëŠ” ê²ƒì´ ì¢‹ì„ ê²ƒ ê°™ë‹¤.\nAction: Search\nAction Input: "creep" song'), '"Creep" is the debut single by the English rock band Radiohead, released on 21 September 1992. It appeared on their debut studio album, Pablo Honey (1993).')]



```python
# í•˜ì…ë³´ì´ê°€ ì›¨ì´í¬ì› ë…¸ë˜ë¼ëŠ”ê±¸ ë³´ë©´, ì„±ëŠ¥ì€ ê·¸ë‹¥ì¸ê±¸ë¡œ..
response = agent({"input":"í•˜ì…ë³´ì´ëŠ” ëˆ„êµ¬ì˜ ë…¸ë˜ì¸ê°€ìš”?"})
```

    
    
    [1m> Entering new AgentExecutor chain...[0m
    [32;1m[1;3m I should try to find out who sings this song.
    Action: Search
    Action Input: í•˜ì…ë³´ì´ ë…¸ë˜[0m
    Observation: [36;1m[1;3më³´ì´ì¦ˆí”Œë˜ë‹› Kê·¸ë£¹ ì›¨ì´í¬ì› íŒ€ì˜ ë¬´ëŒ€ì—ì„œ í•˜ì…ë³´ì´ì˜ í•˜ì´ë¼ì´íŠ¸ ì•ˆë¬´ê°€ ìˆë‹¤. ë°œë§¤í›„ 6ê°œì›” 10ì¼ì´ ì§€ë‚œ 2023ë…„ 2ì›” 12ì¼, ì¸ê¸°ê°€ìš”ì— 1ìœ„ í›„ë³´ë¡œ ...[0m
    Thought:[32;1m[1;3m It looks like the song is by Wakeon, a K-pop group.
    Final Answer: í•˜ì…ë³´ì´ëŠ” ë³´ì´ì¦ˆí”Œë˜ë‹› Kê·¸ë£¹ ì›¨ì´í¬ì› íŒ€ì˜ ë…¸ë˜ì…ë‹ˆë‹¤.[0m
    
    [1m> Finished chain.[0m



```python
print(response["intermediate_steps"])
```

    [(AgentAction(tool='Search', tool_input='í•˜ì…ë³´ì´ ë…¸ë˜', log=' I should try to find out who sings this song.\nAction: Search\nAction Input: í•˜ì…ë³´ì´ ë…¸ë˜'), 'ë³´ì´ì¦ˆí”Œë˜ë‹› Kê·¸ë£¹ ì›¨ì´í¬ì› íŒ€ì˜ ë¬´ëŒ€ì—ì„œ í•˜ì…ë³´ì´ì˜ í•˜ì´ë¼ì´íŠ¸ ì•ˆë¬´ê°€ ìˆë‹¤. ë°œë§¤í›„ 6ê°œì›” 10ì¼ì´ ì§€ë‚œ 2023ë…„ 2ì›” 12ì¼, ì¸ê¸°ê°€ìš”ì— 1ìœ„ í›„ë³´ë¡œ ...')]

